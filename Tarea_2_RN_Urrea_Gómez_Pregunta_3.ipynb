{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tarea 2 RN Urrea Gómez Pregunta 3-checkpoint (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iY6ZVRnDbnxh"
      },
      "source": [
        "<hr style=\"height:2px;border:none\"/>\n",
        "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales I-2018 </h1>\n",
        "\n",
        "<H3 align='center'> Tarea 2 - Aplicaciones Recientes de Redes Neuronales </H3>\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "<H3 align='center'> Fernanda Urrea, ROL: 201551522-0</H3>\n",
        "<H3 align='center'>Matías Gómez, ROL: 201460501-3</H3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cc4w8elebn8e"
      },
      "source": [
        "## 3. *Encoder-Decoder* sobre Texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T73mPdWLboDE"
      },
      "source": [
        "Trabajos recientes en redes neuronales han demostrado que se puede aplicar a problemas bastante complejos gracias a la flexibilidad la definición de las redes, además de que se pueden adaptar a distintos tipos de datos brutos (dominios). Con el objetivo de explorar el enfoque anterior de *traducción* de algun tipo de dato, en esta sección deberá realizarlo con texto para traducción de un lenguaje humano a otro (e.g. inglés a alemán, chino a ruso).\n",
        "\n",
        "<img src=\"https://www.panoramaila.cz/images/preklady.jpg\" width=\"35%\" />\n",
        "\n",
        "\n",
        "Trabajaremos con el dataset de pares de sentencias bilingues entre distintos idiomas del proyecto __[Tatoeba](http://www.manythings.org/anki/)__. El objetivo entonces consta de tomar un texto en lenguaje natural de algún idioma (*source*) y traducirlo a otro texto en lenguaje natural de otro idioma (*target*), donde cada texto tendrá un largo variable. Lo cual se empleará a través de extraer información del texto *source* (*encoder*) para luego generar el texto *target* (*decoder*) en base a esta información extraída.\n",
        "\n",
        "\n",
        "Deberá seleccionar el *dataset* que guste para trabajar con la tarea de traducción, comente sobre su decisión. Luego cárgelo con *pandas*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSKw7XPYYArD",
        "colab_type": "code",
        "outputId": "0f8e31e1-d8a6-496b-e002-77389aa41fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, GRU, CuDNNGRU, RepeatVector, TimeDistributed, Dense, Flatten, Reshape, LSTM, Conv1D,MaxPool1D,GlobalMaxPooling1D,GlobalAveragePooling1D,BatchNormalization, InputLayer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRsOwwZpYArI",
        "colab_type": "text"
      },
      "source": [
        "De todos los dataset disponibles, como la finalidad es trabajar con redes neuronales, consideramos aquellos que tienen mayor cantidad de sentencias y dentro de esos, algunos en los que se trabaja con idiomas que consideramos no tan \"extraños\" o dentro de nuestro conocimiento.  \n",
        "\n",
        "•\tGerman - English deu-eng.zip (194408)  \n",
        "•\tFrench - English fra-eng.zip (168980)  \n",
        "•\tPortuguese - English por-eng.zip (143700)  \n",
        "•\tSpanish - English spa-eng.zip (121817)   \n",
        "\n",
        "Para esta pregunta, trabajaremos con Portugues porque notamos que tenia mayor similitud de estructura que los otros lenguajes. A diferencia de el portugues, español o frances, el alemán tiene la misma raíz que el inglés pero notamos que habian muchas palabras compuestas que su correspondiente traducción en ingles era un conjunto de palabras como por ejemplo gespenstergesicht que significa cara de fantasma. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbWBjcdyvdz4",
        "colab_type": "code",
        "outputId": "c40c04a0-7cbe-49b8-a68a-f4963a901e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UJHUVrxYArK",
        "colab_type": "code",
        "outputId": "6b83fc4d-7f79-41ac-c52c-0e4e3b396f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/por.txt\", sep=\"\\t\", names=[\"Source\",\"Target\"])\n",
        "df.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vai.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vá.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Oi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corre!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Source  Target\n",
              "0    Go.    Vai.\n",
              "1    Go.     Vá.\n",
              "2    Hi.     Oi.\n",
              "3   Run!  Corre!\n",
              "4   Run!  Corra!"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VbnQlbgJb2FV"
      },
      "source": [
        "### a) Visualice los datos ¿Qué es la entrada y qué es la salida? Comente sobre los múltiples significados/sinónimos que puede tener una palabra al ser traducida y cómo propondría arreglar eso. *se espera que pueda implementarlo*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7RmoxihJb40_",
        "outputId": "619310f9-6a7d-4ba8-ad13-3fcf9a844893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 145693 entries, 0 to 145692\n",
            "Data columns (total 2 columns):\n",
            "Source    145693 non-null object\n",
            "Target    145693 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 2.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDd8n9vvYArZ",
        "colab_type": "code",
        "outputId": "11b1de4a-cbdb-4a4a-cfa0-5e210ffa1ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vai.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vá.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Oi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corre!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corram!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Run.</td>\n",
              "      <td>Corre!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Run.</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Run.</td>\n",
              "      <td>Corram!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Quem?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Uau!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Nossa!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Wow!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Fire!</td>\n",
              "      <td>Fogo!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Ajuda!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Socorro!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Jump!</td>\n",
              "      <td>Pule!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>Pulem.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>Pule.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>Pare!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>Parem!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Wait!</td>\n",
              "      <td>Espere!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Wait.</td>\n",
              "      <td>Espere!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Wait.</td>\n",
              "      <td>Esperem.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Go on.</td>\n",
              "      <td>Vá!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>Oi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>Alô.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>Olá!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>Alô!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>I ran.</td>\n",
              "      <td>Eu corri.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145663</th>\n",
              "      <td>Mary earns ten times as much as I do, complain...</td>\n",
              "      <td>Maria ganha dez vezes mais dinheiro do que eu,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145664</th>\n",
              "      <td>The room didn't look very good after Tom paint...</td>\n",
              "      <td>O quarto não ficou muito bom depois de o Tom o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145665</th>\n",
              "      <td>I've opened many Facebook and Twitter accounts...</td>\n",
              "      <td>Eu tenho aberto muitas contas no Facebook e no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145666</th>\n",
              "      <td>Latin Americans know very little about the his...</td>\n",
              "      <td>Os latino-americanos sabem muito pouco sobre a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145667</th>\n",
              "      <td>We should spend our time creating content for ...</td>\n",
              "      <td>Nós deveríamos passar a maior parte do nosso t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145668</th>\n",
              "      <td>It's very easy to sound natural in your own na...</td>\n",
              "      <td>É muito fácil soar natural no próprio idioma n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145669</th>\n",
              "      <td>I have Japanese and Chinese friends who speak ...</td>\n",
              "      <td>Eu tenho um amigo japonês e um chinês que fala...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145670</th>\n",
              "      <td>I wanted to visit Tom next Monday, but he said...</td>\n",
              "      <td>Eu queria visitar o Tom na próxima segunda, ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145671</th>\n",
              "      <td>When I was 17, I injured myself playing footba...</td>\n",
              "      <td>Quando tinha 17 anos, eu me machuquei jogando ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145672</th>\n",
              "      <td>All the doctors say that I shouldn't drink cof...</td>\n",
              "      <td>Todos os médicos dizem que eu não deveria toma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145673</th>\n",
              "      <td>I thought I had paid the monthly fee, but I re...</td>\n",
              "      <td>Eu pensava que já tinha pagado a mensalidade, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145674</th>\n",
              "      <td>If one has the right to live, then one should ...</td>\n",
              "      <td>Se temos o direito de viver, então deveríamos ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145675</th>\n",
              "      <td>No matter what your profession, or how happy y...</td>\n",
              "      <td>Não importa qual a sua profissão, ou o quão fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145676</th>\n",
              "      <td>In an effort to declutter his apartment, Tom i...</td>\n",
              "      <td>Num esforço de pôr seu apartamento em ordem, T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145677</th>\n",
              "      <td>It was bad enough that he usually came to work...</td>\n",
              "      <td>Já era ruim o bastante que ele normalmente che...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145678</th>\n",
              "      <td>You dislike Tom, don't you? \"It's not that I d...</td>\n",
              "      <td>Você não gosta de Tom? — \"Não é que eu não gos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145679</th>\n",
              "      <td>A man who has never gone to school may steal f...</td>\n",
              "      <td>Um homem que nunca foi à escola pode roubar de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145680</th>\n",
              "      <td>One way to lower the number of errors in the T...</td>\n",
              "      <td>Uma maneira de diminuir o número de erros no C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145681</th>\n",
              "      <td>I think it's a shame that some foreign languag...</td>\n",
              "      <td>Eu acho vergonhoso que alguns professores de l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145682</th>\n",
              "      <td>When Tom showed up late for work for the third...</td>\n",
              "      <td>Quando Tom chegou atrasado ao trabalho pela te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145683</th>\n",
              "      <td>You can fool some of the people all of the tim...</td>\n",
              "      <td>Pode-se enganar todas as pessoas por algum tem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145684</th>\n",
              "      <td>You can fool some of the people all of the tim...</td>\n",
              "      <td>Pode-se enganar algumas pessoas durante todo o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145685</th>\n",
              "      <td>If you translate from your second language int...</td>\n",
              "      <td>Ao traduzir de um segundo idioma para o própri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145686</th>\n",
              "      <td>Words must be arranged in the proper sequence ...</td>\n",
              "      <td>As palavras devem ser postas em sequência adeq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145687</th>\n",
              "      <td>The Indonesian government is very unhappy at r...</td>\n",
              "      <td>O governo indonésio está muito insatisfeito co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145688</th>\n",
              "      <td>The people here are particular about what they...</td>\n",
              "      <td>As pessoas aqui são particulares sobre o que e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145689</th>\n",
              "      <td>No matter how much you try to convince people ...</td>\n",
              "      <td>Não importa o quanto você tenta convencer os o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145690</th>\n",
              "      <td>Some movies make such an impact that one never...</td>\n",
              "      <td>Alguns filmes são tão marcantes que jamais nos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145691</th>\n",
              "      <td>A child who is a native speaker usually knows ...</td>\n",
              "      <td>Uma criança que é falante nativa geralmente sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145692</th>\n",
              "      <td>We recommend adding sentences and translations...</td>\n",
              "      <td>Recomendamos acrescentar frases e traduções na...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>145693 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Source                                             Target\n",
              "0                                                     Go.                                               Vai.\n",
              "1                                                     Go.                                                Vá.\n",
              "2                                                     Hi.                                                Oi.\n",
              "3                                                    Run!                                             Corre!\n",
              "4                                                    Run!                                             Corra!\n",
              "5                                                    Run!                                            Corram!\n",
              "6                                                    Run.                                             Corre!\n",
              "7                                                    Run.                                             Corra!\n",
              "8                                                    Run.                                            Corram!\n",
              "9                                                    Who?                                              Quem?\n",
              "10                                                   Wow!                                               Uau!\n",
              "11                                                   Wow!                                             Nossa!\n",
              "12                                                   Wow!                                               Wow!\n",
              "13                                                  Fire!                                              Fogo!\n",
              "14                                                  Help!                                             Ajuda!\n",
              "15                                                  Help!                                           Socorro!\n",
              "16                                                  Jump!                                              Pule!\n",
              "17                                                  Jump.                                             Pulem.\n",
              "18                                                  Jump.                                              Pule.\n",
              "19                                                  Stop!                                              Pare!\n",
              "20                                                  Stop!                                             Parem!\n",
              "21                                                  Wait!                                            Espere!\n",
              "22                                                  Wait.                                            Espere!\n",
              "23                                                  Wait.                                           Esperem.\n",
              "24                                                 Go on.                                                Vá!\n",
              "25                                                 Hello!                                                Oi.\n",
              "26                                                 Hello!                                               Alô.\n",
              "27                                                 Hello!                                               Olá!\n",
              "28                                                 Hello!                                               Alô!\n",
              "29                                                 I ran.                                          Eu corri.\n",
              "...                                                   ...                                                ...\n",
              "145663  Mary earns ten times as much as I do, complain...  Maria ganha dez vezes mais dinheiro do que eu,...\n",
              "145664  The room didn't look very good after Tom paint...  O quarto não ficou muito bom depois de o Tom o...\n",
              "145665  I've opened many Facebook and Twitter accounts...  Eu tenho aberto muitas contas no Facebook e no...\n",
              "145666  Latin Americans know very little about the his...  Os latino-americanos sabem muito pouco sobre a...\n",
              "145667  We should spend our time creating content for ...  Nós deveríamos passar a maior parte do nosso t...\n",
              "145668  It's very easy to sound natural in your own na...  É muito fácil soar natural no próprio idioma n...\n",
              "145669  I have Japanese and Chinese friends who speak ...  Eu tenho um amigo japonês e um chinês que fala...\n",
              "145670  I wanted to visit Tom next Monday, but he said...  Eu queria visitar o Tom na próxima segunda, ma...\n",
              "145671  When I was 17, I injured myself playing footba...  Quando tinha 17 anos, eu me machuquei jogando ...\n",
              "145672  All the doctors say that I shouldn't drink cof...  Todos os médicos dizem que eu não deveria toma...\n",
              "145673  I thought I had paid the monthly fee, but I re...  Eu pensava que já tinha pagado a mensalidade, ...\n",
              "145674  If one has the right to live, then one should ...  Se temos o direito de viver, então deveríamos ...\n",
              "145675  No matter what your profession, or how happy y...  Não importa qual a sua profissão, ou o quão fe...\n",
              "145676  In an effort to declutter his apartment, Tom i...  Num esforço de pôr seu apartamento em ordem, T...\n",
              "145677  It was bad enough that he usually came to work...  Já era ruim o bastante que ele normalmente che...\n",
              "145678  You dislike Tom, don't you? \"It's not that I d...  Você não gosta de Tom? — \"Não é que eu não gos...\n",
              "145679  A man who has never gone to school may steal f...  Um homem que nunca foi à escola pode roubar de...\n",
              "145680  One way to lower the number of errors in the T...  Uma maneira de diminuir o número de erros no C...\n",
              "145681  I think it's a shame that some foreign languag...  Eu acho vergonhoso que alguns professores de l...\n",
              "145682  When Tom showed up late for work for the third...  Quando Tom chegou atrasado ao trabalho pela te...\n",
              "145683  You can fool some of the people all of the tim...  Pode-se enganar todas as pessoas por algum tem...\n",
              "145684  You can fool some of the people all of the tim...  Pode-se enganar algumas pessoas durante todo o...\n",
              "145685  If you translate from your second language int...  Ao traduzir de um segundo idioma para o própri...\n",
              "145686  Words must be arranged in the proper sequence ...  As palavras devem ser postas em sequência adeq...\n",
              "145687  The Indonesian government is very unhappy at r...  O governo indonésio está muito insatisfeito co...\n",
              "145688  The people here are particular about what they...  As pessoas aqui são particulares sobre o que e...\n",
              "145689  No matter how much you try to convince people ...  Não importa o quanto você tenta convencer os o...\n",
              "145690  Some movies make such an impact that one never...  Alguns filmes são tão marcantes que jamais nos...\n",
              "145691  A child who is a native speaker usually knows ...  Uma criança que é falante nativa geralmente sa...\n",
              "145692  We recommend adding sentences and translations...  Recomendamos acrescentar frases e traduções na...\n",
              "\n",
              "[145693 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUhsDqwqYArf",
        "colab_type": "text"
      },
      "source": [
        "La entrada (Soruce en el DataFrame) corresponde a una palabra u oración en inglés y la salida (Target en el DataFrame) corresponde a la palabra u oración traducida al portugues.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3ygDM92YArg",
        "colab_type": "code",
        "outputId": "c7bf74b7-ba8b-41ed-fdc2-d8ecff7e2eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df[0:100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vai.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vá.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Oi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corre!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corram!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Run.</td>\n",
              "      <td>Corre!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Run.</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Run.</td>\n",
              "      <td>Corram!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Quem?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Uau!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Nossa!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Wow!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Fire!</td>\n",
              "      <td>Fogo!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Ajuda!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Socorro!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Jump!</td>\n",
              "      <td>Pule!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>Pulem.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>Pule.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>Pare!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>Parem!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Wait!</td>\n",
              "      <td>Espere!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Wait.</td>\n",
              "      <td>Espere!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Wait.</td>\n",
              "      <td>Esperem.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Go on.</td>\n",
              "      <td>Vá!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>Oi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>Alô.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>Olá!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>Alô!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>I ran.</td>\n",
              "      <td>Eu corri.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>I'm up.</td>\n",
              "      <td>Estou acordado.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Listen.</td>\n",
              "      <td>Escute!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Listen.</td>\n",
              "      <td>Ouça-me!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>Listen.</td>\n",
              "      <td>Escuta!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>Listen.</td>\n",
              "      <td>Escutem!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>Listen.</td>\n",
              "      <td>Ouça isso!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>Listen.</td>\n",
              "      <td>Escutem-me!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Listen.</td>\n",
              "      <td>Escute.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>Listen.</td>\n",
              "      <td>Escuta.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Listen.</td>\n",
              "      <td>Escutem.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>Listen.</td>\n",
              "      <td>Escutai.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>No way!</td>\n",
              "      <td>De jeito nenhum!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>No way!</td>\n",
              "      <td>Impossível!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>No way!</td>\n",
              "      <td>De maneira alguma!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>No way!</td>\n",
              "      <td>De modo algum!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>No way!</td>\n",
              "      <td>Sem chance!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>Really?</td>\n",
              "      <td>Sério?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>Really?</td>\n",
              "      <td>É mesmo?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>Really?</td>\n",
              "      <td>Mesmo?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>Really?</td>\n",
              "      <td>É sério?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>Thanks.</td>\n",
              "      <td>Obrigado!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>Thanks.</td>\n",
              "      <td>Obrigada!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>Thanks.</td>\n",
              "      <td>Obrigado.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>Try it.</td>\n",
              "      <td>Tenta-o.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Try it.</td>\n",
              "      <td>Prove-o.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Try it.</td>\n",
              "      <td>Prove-a.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>We try.</td>\n",
              "      <td>Tentamos.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>We try.</td>\n",
              "      <td>Nós tentamos.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>We won.</td>\n",
              "      <td>Vencemos.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>We won.</td>\n",
              "      <td>Nós vencemos.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Source              Target\n",
              "0       Go.                Vai.\n",
              "1       Go.                 Vá.\n",
              "2       Hi.                 Oi.\n",
              "3      Run!              Corre!\n",
              "4      Run!              Corra!\n",
              "5      Run!             Corram!\n",
              "6      Run.              Corre!\n",
              "7      Run.              Corra!\n",
              "8      Run.             Corram!\n",
              "9      Who?               Quem?\n",
              "10     Wow!                Uau!\n",
              "11     Wow!              Nossa!\n",
              "12     Wow!                Wow!\n",
              "13    Fire!               Fogo!\n",
              "14    Help!              Ajuda!\n",
              "15    Help!            Socorro!\n",
              "16    Jump!               Pule!\n",
              "17    Jump.              Pulem.\n",
              "18    Jump.               Pule.\n",
              "19    Stop!               Pare!\n",
              "20    Stop!              Parem!\n",
              "21    Wait!             Espere!\n",
              "22    Wait.             Espere!\n",
              "23    Wait.            Esperem.\n",
              "24   Go on.                 Vá!\n",
              "25   Hello!                 Oi.\n",
              "26   Hello!                Alô.\n",
              "27   Hello!                Olá!\n",
              "28   Hello!                Alô!\n",
              "29   I ran.           Eu corri.\n",
              "..      ...                 ...\n",
              "70  I'm up.     Estou acordado.\n",
              "71  Listen.             Escute!\n",
              "72  Listen.            Ouça-me!\n",
              "73  Listen.             Escuta!\n",
              "74  Listen.            Escutem!\n",
              "75  Listen.          Ouça isso!\n",
              "76  Listen.         Escutem-me!\n",
              "77  Listen.             Escute.\n",
              "78  Listen.             Escuta.\n",
              "79  Listen.            Escutem.\n",
              "80  Listen.            Escutai.\n",
              "81  No way!    De jeito nenhum!\n",
              "82  No way!         Impossível!\n",
              "83  No way!  De maneira alguma!\n",
              "84  No way!      De modo algum!\n",
              "85  No way!         Sem chance!\n",
              "86  Really?              Sério?\n",
              "87  Really?            É mesmo?\n",
              "88  Really?              Mesmo?\n",
              "89  Really?            É sério?\n",
              "90  Thanks.           Obrigado!\n",
              "91  Thanks.           Obrigada!\n",
              "92  Thanks.           Obrigado.\n",
              "93  Try it.            Tenta-o.\n",
              "94  Try it.            Prove-o.\n",
              "95  Try it.            Prove-a.\n",
              "96  We try.           Tentamos.\n",
              "97  We try.       Nós tentamos.\n",
              "98  We won.           Vencemos.\n",
              "99  We won.       Nós vencemos.\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMe_w9HkYArm",
        "colab_type": "code",
        "outputId": "4d2bdcd7-af4b-46bc-b329-52005550466c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print('Para la palabra Run! :')\n",
        "for i in range(135671):\n",
        "    if df['Source'][i]== 'Run!':\n",
        "        print(df['Target'][i])\n",
        "\n",
        "print('\\nPara la palabra Hello! :')\n",
        "for i in range(135671):\n",
        "    if df['Source'][i]== 'Hello!':\n",
        "        print(df['Target'][i])\n",
        "        \n",
        "print('\\nPara la palabra Wow! :')\n",
        "for i in range(135671 ):\n",
        "    if df['Source'][i]== 'Wow!':\n",
        "        print(df['Target'][i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Para la palabra Run! :\n",
            "Corre!\n",
            "Corra!\n",
            "Corram!\n",
            "\n",
            "Para la palabra Hello! :\n",
            "Oi.\n",
            "Alô.\n",
            "Olá!\n",
            "Alô!\n",
            "\n",
            "Para la palabra Wow! :\n",
            "Uau!\n",
            "Nossa!\n",
            "Wow!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "418Zc_EfYArr",
        "colab_type": "text"
      },
      "source": [
        "En los ejemplos anteriores se ve que para una misma palabra en inglés, existen diferentes traducciones al portugues. En el caso de  $Run!$, de $Hello!$ y de $Wow!$ no se observa un problema muy grande debido a que los outputs correspondientes vienen de una misma raiz y solo cambian las conjugaciones y tiempos verbales. Por ende, para estos casos se propone mantener solo la raíz de las palabras.  \n",
        "En los ejemplos que revisamos anteriormente no encontramos palabras que tengan múltiples significados. Sin embargo, puede que existan casos en los que si ocurra. Si la ocurrencia de esto fuera alta, se debería deducir el significado válido de la palabra según el contexto de la oración en la que aparece."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jS0ouB02b6Wc"
      },
      "source": [
        "### b) Realice un pre-procesamiento a los textos como se acostumbra para eliminar símbolos inecesarios u otras cosas que estime conveniente, comente sobre la importancia de éste paso. Además de ésto deberá agregar un símbolo al final de la sentencia *target* para indicar un \"alto\" cuando la red neuronal necesite aprender a generar una sentencia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Q4D00zNb8pH",
        "colab": {}
      },
      "source": [
        "table = str.maketrans('', '', string.punctuation) \n",
        "def clean_text(text, where=None):\n",
        "    \"\"\" OJO: Sin eliminar el significado de las palabras.\"\"\"\n",
        "    text = text.lower()\n",
        "    tokenize_text = text.split()\n",
        "    tokenize_text = [word.translate(table) for word in tokenize_text]#eliminar puntuacion\n",
        "    tokenize_text = [word for word in tokenize_text if word.isalpha()] #remove numbers\n",
        "    if where ==\"target\":\n",
        "        tokenize_text = tokenize_text + [\"#end\"]  #Se agrega el símbolo que indica el \"alto\" para que la red pueda aprender la sentencia\n",
        "    return tokenize_text\n",
        "texts_input = list(df['Source'].apply(clean_text))\n",
        "texts_output = list(df['Target'].apply(clean_text, where='target'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5jNy3-xe_An",
        "colab_type": "text"
      },
      "source": [
        "Se muestran los resultados del preprocesamiento del texto, para los input y los output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAtzvDLtYAry",
        "colab_type": "code",
        "outputId": "2dcd7aad-f132-4986-a36e-d5f53989f106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "texts_input"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['go'],\n",
              " ['go'],\n",
              " ['hi'],\n",
              " ['run'],\n",
              " ['run'],\n",
              " ['run'],\n",
              " ['run'],\n",
              " ['run'],\n",
              " ['run'],\n",
              " ['who'],\n",
              " ['wow'],\n",
              " ['wow'],\n",
              " ['wow'],\n",
              " ['fire'],\n",
              " ['help'],\n",
              " ['help'],\n",
              " ['jump'],\n",
              " ['jump'],\n",
              " ['jump'],\n",
              " ['stop'],\n",
              " ['stop'],\n",
              " ['wait'],\n",
              " ['wait'],\n",
              " ['wait'],\n",
              " ['go', 'on'],\n",
              " ['hello'],\n",
              " ['hello'],\n",
              " ['hello'],\n",
              " ['hello'],\n",
              " ['i', 'ran'],\n",
              " ['i', 'see'],\n",
              " ['i', 'try'],\n",
              " ['i', 'try'],\n",
              " ['i', 'won'],\n",
              " ['i', 'won'],\n",
              " ['oh', 'no'],\n",
              " ['relax'],\n",
              " ['relax'],\n",
              " ['shoot'],\n",
              " ['smile'],\n",
              " ['smile'],\n",
              " ['attack'],\n",
              " ['attack'],\n",
              " ['attack'],\n",
              " ['cheers'],\n",
              " ['freeze'],\n",
              " ['get', 'up'],\n",
              " ['get', 'up'],\n",
              " ['get', 'up'],\n",
              " ['get', 'up'],\n",
              " ['get', 'up'],\n",
              " ['go', 'now'],\n",
              " ['got', 'it'],\n",
              " ['got', 'it'],\n",
              " ['got', 'it'],\n",
              " ['got', 'it'],\n",
              " ['he', 'ran'],\n",
              " ['he', 'ran'],\n",
              " ['hop', 'in'],\n",
              " ['hop', 'in'],\n",
              " ['hug', 'me'],\n",
              " ['i', 'fell'],\n",
              " ['i', 'know'],\n",
              " ['i', 'know'],\n",
              " ['i', 'left'],\n",
              " ['i', 'paid'],\n",
              " ['i', 'quit'],\n",
              " ['i', 'work'],\n",
              " ['im', 'ok'],\n",
              " ['im', 'ok'],\n",
              " ['im', 'up'],\n",
              " ['listen'],\n",
              " ['listen'],\n",
              " ['listen'],\n",
              " ['listen'],\n",
              " ['listen'],\n",
              " ['listen'],\n",
              " ['listen'],\n",
              " ['listen'],\n",
              " ['listen'],\n",
              " ['listen'],\n",
              " ['no', 'way'],\n",
              " ['no', 'way'],\n",
              " ['no', 'way'],\n",
              " ['no', 'way'],\n",
              " ['no', 'way'],\n",
              " ['really'],\n",
              " ['really'],\n",
              " ['really'],\n",
              " ['really'],\n",
              " ['thanks'],\n",
              " ['thanks'],\n",
              " ['thanks'],\n",
              " ['try', 'it'],\n",
              " ['try', 'it'],\n",
              " ['try', 'it'],\n",
              " ['we', 'try'],\n",
              " ['we', 'try'],\n",
              " ['we', 'won'],\n",
              " ['we', 'won'],\n",
              " ['why', 'me'],\n",
              " ['ask', 'tom'],\n",
              " ['ask', 'tom'],\n",
              " ['ask', 'tom'],\n",
              " ['ask', 'tom'],\n",
              " ['ask', 'tom'],\n",
              " ['ask', 'tom'],\n",
              " ['be', 'calm'],\n",
              " ['be', 'cool'],\n",
              " ['be', 'fair'],\n",
              " ['be', 'fair'],\n",
              " ['be', 'fair'],\n",
              " ['be', 'fair'],\n",
              " ['be', 'fair'],\n",
              " ['be', 'fair'],\n",
              " ['be', 'fair'],\n",
              " ['be', 'fair'],\n",
              " ['be', 'good'],\n",
              " ['be', 'good'],\n",
              " ['be', 'good'],\n",
              " ['be', 'good'],\n",
              " ['be', 'good'],\n",
              " ['be', 'good'],\n",
              " ['be', 'good'],\n",
              " ['be', 'good'],\n",
              " ['be', 'kind'],\n",
              " ['be', 'kind'],\n",
              " ['be', 'kind'],\n",
              " ['be', 'kind'],\n",
              " ['be', 'nice'],\n",
              " ['be', 'nice'],\n",
              " ['beat', 'it'],\n",
              " ['beat', 'it'],\n",
              " ['call', 'me'],\n",
              " ['call', 'us'],\n",
              " ['come', 'in'],\n",
              " ['come', 'in'],\n",
              " ['come', 'in'],\n",
              " ['come', 'in'],\n",
              " ['come', 'on'],\n",
              " ['come', 'on'],\n",
              " ['come', 'on'],\n",
              " ['come', 'on'],\n",
              " ['drop', 'it'],\n",
              " ['drop', 'it'],\n",
              " ['get', 'tom'],\n",
              " ['get', 'out'],\n",
              " ['get', 'out'],\n",
              " ['get', 'out'],\n",
              " ['get', 'out'],\n",
              " ['get', 'out'],\n",
              " ['get', 'out'],\n",
              " ['get', 'out'],\n",
              " ['go', 'away'],\n",
              " ['go', 'away'],\n",
              " ['go', 'away'],\n",
              " ['go', 'away'],\n",
              " ['go', 'away'],\n",
              " ['go', 'away'],\n",
              " ['go', 'away'],\n",
              " ['go', 'away'],\n",
              " ['go', 'home'],\n",
              " ['go', 'home'],\n",
              " ['goodbye'],\n",
              " ['goodbye'],\n",
              " ['goodbye'],\n",
              " ['goodbye'],\n",
              " ['goodbye'],\n",
              " ['goodbye'],\n",
              " ['hang', 'on'],\n",
              " ['hang', 'on'],\n",
              " ['hang', 'on'],\n",
              " ['hang', 'on'],\n",
              " ['he', 'came'],\n",
              " ['he', 'runs'],\n",
              " ['help', 'me'],\n",
              " ['help', 'me'],\n",
              " ['help', 'me'],\n",
              " ['help', 'me'],\n",
              " ['help', 'me'],\n",
              " ['help', 'me'],\n",
              " ['help', 'me'],\n",
              " ['help', 'me'],\n",
              " ['help', 'me'],\n",
              " ['help', 'me'],\n",
              " ['help', 'us'],\n",
              " ['help', 'us'],\n",
              " ['help', 'us'],\n",
              " ['help', 'us'],\n",
              " ['hi', 'tom'],\n",
              " ['hit', 'tom'],\n",
              " ['hold', 'it'],\n",
              " ['hold', 'it'],\n",
              " ['hold', 'on'],\n",
              " ['hold', 'on'],\n",
              " ['hug', 'tom'],\n",
              " ['hug', 'tom'],\n",
              " ['i', 'agree'],\n",
              " ['i', 'agree'],\n",
              " ['i', 'agree'],\n",
              " ['i', 'cried'],\n",
              " ['i', 'drove'],\n",
              " ['i', 'smoke'],\n",
              " ['i', 'snore'],\n",
              " ['i', 'stink'],\n",
              " ['i', 'tried'],\n",
              " ['i', 'tried'],\n",
              " ['i', 'waved'],\n",
              " ['ill', 'go'],\n",
              " ['ill', 'go'],\n",
              " ['im', 'fat'],\n",
              " ['im', 'fat'],\n",
              " ['im', 'fat'],\n",
              " ['im', 'fat'],\n",
              " ['im', 'fit'],\n",
              " ['im', 'fit'],\n",
              " ['im', 'hot'],\n",
              " ['im', 'hot'],\n",
              " ['im', 'mad'],\n",
              " ['im', 'old'],\n",
              " ['im', 'old'],\n",
              " ['im', 'old'],\n",
              " ['im', 'old'],\n",
              " ['im', 'sad'],\n",
              " ['im', 'sad'],\n",
              " ['im', 'sad'],\n",
              " ['im', 'shy'],\n",
              " ['im', 'wet'],\n",
              " ['im', 'wet'],\n",
              " ['its', 'ok'],\n",
              " ['its', 'ok'],\n",
              " ['its', 'ok'],\n",
              " ['its', 'ok'],\n",
              " ['its', 'me'],\n",
              " ['its', 'me'],\n",
              " ['join', 'us'],\n",
              " ['join', 'us'],\n",
              " ['keep', 'it'],\n",
              " ['keep', 'it'],\n",
              " ['keep', 'it'],\n",
              " ['keep', 'it'],\n",
              " ['keep', 'it'],\n",
              " ['keep', 'it'],\n",
              " ['kiss', 'me'],\n",
              " ['kiss', 'me'],\n",
              " ['kiss', 'me'],\n",
              " ['kiss', 'me'],\n",
              " ['look', 'up'],\n",
              " ['look', 'up'],\n",
              " ['look', 'up'],\n",
              " ['look', 'up'],\n",
              " ['me', 'too'],\n",
              " ['open', 'up'],\n",
              " ['perfect'],\n",
              " ['see', 'you'],\n",
              " ['see', 'you'],\n",
              " ['see', 'you'],\n",
              " ['see', 'you'],\n",
              " ['see', 'you'],\n",
              " ['show', 'me'],\n",
              " ['show', 'me'],\n",
              " ['show', 'me'],\n",
              " ['shut', 'up'],\n",
              " ['shut', 'up'],\n",
              " ['shut', 'up'],\n",
              " ['shut', 'up'],\n",
              " ['shut', 'up'],\n",
              " ['shut', 'up'],\n",
              " ['stop', 'it'],\n",
              " ['stop', 'it'],\n",
              " ['stop', 'it'],\n",
              " ['take', 'it'],\n",
              " ['take', 'it'],\n",
              " ['take', 'it'],\n",
              " ['take', 'it'],\n",
              " ['take', 'it'],\n",
              " ['take', 'it'],\n",
              " ['take', 'it'],\n",
              " ['take', 'it'],\n",
              " ['tell', 'me'],\n",
              " ['tell', 'me'],\n",
              " ['tell', 'me'],\n",
              " ['tom', 'ate'],\n",
              " ['tom', 'ate'],\n",
              " ['tom', 'ran'],\n",
              " ['tom', 'ran'],\n",
              " ['tom', 'won'],\n",
              " ['wait', 'up'],\n",
              " ['wait', 'up'],\n",
              " ['wake', 'up'],\n",
              " ['wake', 'up'],\n",
              " ['wake', 'up'],\n",
              " ['wake', 'up'],\n",
              " ['wake', 'up'],\n",
              " ['wash', 'up'],\n",
              " ['wash', 'up'],\n",
              " ['wash', 'up'],\n",
              " ['wash', 'up'],\n",
              " ['wash', 'up'],\n",
              " ['we', 'care'],\n",
              " ['we', 'know'],\n",
              " ['we', 'lost'],\n",
              " ['we', 'lost'],\n",
              " ['welcome'],\n",
              " ['welcome'],\n",
              " ['welcome'],\n",
              " ['welcome'],\n",
              " ['who', 'ate'],\n",
              " ['who', 'ran'],\n",
              " ['who', 'won'],\n",
              " ['why', 'not'],\n",
              " ['you', 'run'],\n",
              " ['you', 'run'],\n",
              " ['you', 'won'],\n",
              " ['you', 'won'],\n",
              " ['you', 'won'],\n",
              " ['am', 'i', 'fat'],\n",
              " ['am', 'i', 'fat'],\n",
              " ['ask', 'them'],\n",
              " ['ask', 'them'],\n",
              " ['back', 'off'],\n",
              " ['back', 'off'],\n",
              " ['back', 'off'],\n",
              " ['back', 'off'],\n",
              " ['be', 'brave'],\n",
              " ['be', 'brave'],\n",
              " ['be', 'brief'],\n",
              " ['be', 'quiet'],\n",
              " ['be', 'quiet'],\n",
              " ['be', 'still'],\n",
              " ['beats', 'me'],\n",
              " ['call', 'tom'],\n",
              " ['can', 'i', 'go'],\n",
              " ['cheer', 'up'],\n",
              " ['cool', 'off'],\n",
              " ['cool', 'off'],\n",
              " ['cuff', 'him'],\n",
              " ['dont', 'go'],\n",
              " ['drive', 'on'],\n",
              " ['find', 'tom'],\n",
              " ['find', 'tom'],\n",
              " ['fix', 'this'],\n",
              " ['get', 'away'],\n",
              " ['get', 'away'],\n",
              " ['get', 'away'],\n",
              " ['get', 'down'],\n",
              " ['get', 'down'],\n",
              " ['get', 'down'],\n",
              " ['get', 'down'],\n",
              " ['get', 'down'],\n",
              " ['get', 'lost'],\n",
              " ['get', 'lost'],\n",
              " ['get', 'lost'],\n",
              " ['get', 'lost'],\n",
              " ['get', 'real'],\n",
              " ['get', 'real'],\n",
              " ['get', 'real'],\n",
              " ['get', 'real'],\n",
              " ['go', 'ahead'],\n",
              " ['go', 'ahead'],\n",
              " ['go', 'ahead'],\n",
              " ['go', 'ahead'],\n",
              " ['go', 'ahead'],\n",
              " ['go', 'ahead'],\n",
              " ['good', 'job'],\n",
              " ['grab', 'tom'],\n",
              " ['grab', 'him'],\n",
              " ['grab', 'him'],\n",
              " ['have', 'fun'],\n",
              " ['have', 'fun'],\n",
              " ['have', 'fun'],\n",
              " ['he', 'spoke'],\n",
              " ['he', 'tries'],\n",
              " ['hes', 'wet'],\n",
              " ['help', 'tom'],\n",
              " ['help', 'tom'],\n",
              " ['help', 'tom'],\n",
              " ['hi', 'guys'],\n",
              " ['how', 'cute'],\n",
              " ['how', 'cute'],\n",
              " ['how', 'cute'],\n",
              " ['how', 'cute'],\n",
              " ['how', 'deep'],\n",
              " ['how', 'deep'],\n",
              " ['how', 'deep'],\n",
              " ['how', 'nice'],\n",
              " ['hurry', 'up'],\n",
              " ['hurry', 'up'],\n",
              " ['hurry', 'up'],\n",
              " ['hurry', 'up'],\n",
              " ['i', 'agreed'],\n",
              " ['i', 'am', 'fat'],\n",
              " ['i', 'am', 'fat'],\n",
              " ['i', 'am', 'fat'],\n",
              " ['i', 'am', 'fat'],\n",
              " ['i', 'am', 'hot'],\n",
              " ['i', 'am', 'hot'],\n",
              " ['i', 'burped'],\n",
              " ['i', 'can', 'go'],\n",
              " ['i', 'can', 'go'],\n",
              " ['i', 'danced'],\n",
              " ['i', 'failed'],\n",
              " ['i', 'forgot'],\n",
              " ['i', 'forgot'],\n",
              " ['i', 'forgot'],\n",
              " ['i', 'forgot'],\n",
              " ['i', 'get', 'it'],\n",
              " ['i', 'got', 'it'],\n",
              " ['i', 'got', 'it'],\n",
              " ['i', 'got', 'up'],\n",
              " ['i', 'helped'],\n",
              " ['i', 'jumped'],\n",
              " ['i', 'looked'],\n",
              " ['i', 'nodded'],\n",
              " ['i', 'nodded'],\n",
              " ['i', 'phoned'],\n",
              " ['i', 'prayed'],\n",
              " ['i', 'prayed'],\n",
              " ['i', 'resign'],\n",
              " ['i', 'rested'],\n",
              " ['i', 'saw', 'it'],\n",
              " ['i', 'smiled'],\n",
              " ['i', 'smiled'],\n",
              " ['i', 'stayed'],\n",
              " ['i', 'talked'],\n",
              " ['i', 'waited'],\n",
              " ['i', 'winked'],\n",
              " ['i', 'yawned'],\n",
              " ['ill', 'pay'],\n",
              " ['ill', 'try'],\n",
              " ['ill', 'win'],\n",
              " ['im', 'back'],\n",
              " ['im', 'bald'],\n",
              " ['im', 'bald'],\n",
              " ['im', 'bald'],\n",
              " ['im', 'busy'],\n",
              " ['im', 'busy'],\n",
              " ['im', 'cold'],\n",
              " ['im', 'cool'],\n",
              " ['im', 'deaf'],\n",
              " ['im', 'done'],\n",
              " ['im', 'fair'],\n",
              " ['im', 'fast'],\n",
              " ['im', 'fine'],\n",
              " ['im', 'fine'],\n",
              " ['im', 'fine'],\n",
              " ['im', 'free'],\n",
              " ['im', 'free'],\n",
              " ['im', 'full'],\n",
              " ['im', 'full'],\n",
              " ['im', 'glad'],\n",
              " ['im', 'good'],\n",
              " ['im', 'here'],\n",
              " ['im', 'here'],\n",
              " ['im', 'home'],\n",
              " ['im', 'hurt'],\n",
              " ['im', 'hurt'],\n",
              " ['im', 'lost'],\n",
              " ['im', 'next'],\n",
              " ['im', 'next'],\n",
              " ['im', 'okay'],\n",
              " ['im', 'okay'],\n",
              " ['im', 'poor'],\n",
              " ['im', 'rich'],\n",
              " ['im', 'rich'],\n",
              " ['im', 'safe'],\n",
              " ['im', 'sick'],\n",
              " ['im', 'sick'],\n",
              " ['im', 'sick'],\n",
              " ['im', 'sick'],\n",
              " ['im', 'sick'],\n",
              " ['im', 'sure'],\n",
              " ['im', 'tall'],\n",
              " ['im', 'thin'],\n",
              " ['im', 'thin'],\n",
              " ['im', 'tidy'],\n",
              " ['im', 'tidy'],\n",
              " ['im', 'ugly'],\n",
              " ['im', 'ugly'],\n",
              " ['im', 'ugly'],\n",
              " ['im', 'ugly'],\n",
              " ['im', 'well'],\n",
              " ['im', 'wise'],\n",
              " ['ive', 'won'],\n",
              " ['it', 'helps'],\n",
              " ['it', 'hurts'],\n",
              " ['it', 'works'],\n",
              " ['its', 'tom'],\n",
              " ['its', 'fun'],\n",
              " ['its', 'his'],\n",
              " ['its', 'hot'],\n",
              " ['its', 'new'],\n",
              " ['its', 'new'],\n",
              " ['its', 'old'],\n",
              " ['its', 'red'],\n",
              " ['its', 'red'],\n",
              " ['its', 'red'],\n",
              " ['its', 'sad'],\n",
              " ['keep', 'out'],\n",
              " ['keep', 'out'],\n",
              " ['keep', 'out'],\n",
              " ['keep', 'out'],\n",
              " ['kiss', 'tom'],\n",
              " ['leave', 'it'],\n",
              " ['leave', 'me'],\n",
              " ['leave', 'me'],\n",
              " ['leave', 'me'],\n",
              " ['leave', 'us'],\n",
              " ['leave', 'us'],\n",
              " ['lets', 'go'],\n",
              " ['lets', 'go'],\n",
              " ['look', 'out'],\n",
              " ['look', 'out'],\n",
              " ['look', 'out'],\n",
              " ['marry', 'me'],\n",
              " ['may', 'i', 'go'],\n",
              " ['save', 'tom'],\n",
              " ['save', 'tom'],\n",
              " ['she', 'came'],\n",
              " ['she', 'died'],\n",
              " ['she', 'runs'],\n",
              " ['sit', 'down'],\n",
              " ['sit', 'down'],\n",
              " ['sit', 'here'],\n",
              " ['sit', 'here'],\n",
              " ['speak', 'up'],\n",
              " ['speak', 'up'],\n",
              " ['speak', 'up'],\n",
              " ['stand', 'by'],\n",
              " ['stand', 'by'],\n",
              " ['stand', 'up'],\n",
              " ['stand', 'up'],\n",
              " ['stand', 'up'],\n",
              " ['stand', 'up'],\n",
              " ['stop', 'tom'],\n",
              " ['stop', 'tom'],\n",
              " ['stop', 'tom'],\n",
              " ['stop', 'tom'],\n",
              " ['stop', 'tom'],\n",
              " ['stop', 'tom'],\n",
              " ['take', 'tom'],\n",
              " ['take', 'tom'],\n",
              " ['tell', 'tom'],\n",
              " ['tell', 'tom'],\n",
              " ['tell', 'tom'],\n",
              " ['terrific'],\n",
              " ['terrific'],\n",
              " ['terrific'],\n",
              " ['terrific'],\n",
              " ['they', 'won'],\n",
              " ['they', 'won'],\n",
              " ['they', 'won'],\n",
              " ['they', 'won'],\n",
              " ['tom', 'came'],\n",
              " ['tom', 'died'],\n",
              " ['tom', 'died'],\n",
              " ['tom', 'fell'],\n",
              " ['tom', 'knew'],\n",
              " ['tom', 'lied'],\n",
              " ['tom', 'lies'],\n",
              " ['tom', 'lost'],\n",
              " ['tom', 'paid'],\n",
              " ['tom', 'quit'],\n",
              " ['tom', 'swam'],\n",
              " ['tom', 'swam'],\n",
              " ['too', 'late'],\n",
              " ['trust', 'me'],\n",
              " ['try', 'hard'],\n",
              " ['try', 'hard'],\n",
              " ['try', 'some'],\n",
              " ['try', 'some'],\n",
              " ['try', 'some'],\n",
              " ['try', 'this'],\n",
              " ['try', 'this'],\n",
              " ['try', 'this'],\n",
              " ['use', 'this'],\n",
              " ['warn', 'tom'],\n",
              " ['warn', 'tom'],\n",
              " ['warn', 'tom'],\n",
              " ['warn', 'tom'],\n",
              " ['watch', 'me'],\n",
              " ['we', 'agree'],\n",
              " ['we', 'agree'],\n",
              " ['we', 'tried'],\n",
              " ['well', 'go'],\n",
              " ['were', 'ok'],\n",
              " ['what', 'for'],\n",
              " ['what', 'fun'],\n",
              " ['who', 'am', 'i'],\n",
              " ['who', 'came'],\n",
              " ['who', 'died'],\n",
              " ['who', 'fell'],\n",
              " ['who', 'quit'],\n",
              " ['who', 'swam'],\n",
              " ['write', 'me'],\n",
              " ['after', 'you'],\n",
              " ['aim', 'fire'],\n",
              " ['am', 'i', 'late'],\n",
              " ['answer', 'me'],\n",
              " ['answer', 'me'],\n",
              " ['answer', 'me'],\n",
              " ['answer', 'me'],\n",
              " ['answer', 'me'],\n",
              " ['answer', 'me'],\n",
              " ['be', 'seated'],\n",
              " ['birds', 'fly'],\n",
              " ['birds', 'fly'],\n",
              " ['bless', 'you'],\n",
              " ['call', 'home'],\n",
              " ['calm', 'down'],\n",
              " ['calm', 'down'],\n",
              " ['calm', 'down'],\n",
              " ['calm', 'down'],\n",
              " ['calm', 'down'],\n",
              " ['calm', 'down'],\n",
              " ['calm', 'down'],\n",
              " ['can', 'i', 'eat'],\n",
              " ['catch', 'tom'],\n",
              " ['catch', 'tom'],\n",
              " ['catch', 'him'],\n",
              " ['come', 'back'],\n",
              " ['come', 'back'],\n",
              " ['come', 'here'],\n",
              " ['come', 'here'],\n",
              " ['come', 'home'],\n",
              " ['come', 'over'],\n",
              " ['come', 'over'],\n",
              " ['come', 'over'],\n",
              " ['come', 'over'],\n",
              " ['come', 'soon'],\n",
              " ['cool', 'down'],\n",
              " ['cool', 'down'],\n",
              " ['cool', 'down'],\n",
              " ['cool', 'down'],\n",
              " ['did', 'i', 'win'],\n",
              " ['dogs', 'bark'],\n",
              " ['dogs', 'bark'],\n",
              " ['dont', 'ask'],\n",
              " ['dont', 'ask'],\n",
              " ['dont', 'ask'],\n",
              " ['dont', 'cry'],\n",
              " ['dont', 'cry'],\n",
              " ['dont', 'die'],\n",
              " ['dont', 'die'],\n",
              " ['dont', 'lie'],\n",
              " ['dont', 'run'],\n",
              " ['dont', 'run'],\n",
              " ['dont', 'run'],\n",
              " ['excuse', 'me'],\n",
              " ['excuse', 'me'],\n",
              " ['excuse', 'me'],\n",
              " ['excuse', 'me'],\n",
              " ['excuse', 'me'],\n",
              " ['excuse', 'me'],\n",
              " ['excuse', 'me'],\n",
              " ['fantastic'],\n",
              " ['feel', 'this'],\n",
              " ['follow', 'me'],\n",
              " ['follow', 'me'],\n",
              " ['follow', 'me'],\n",
              " ['follow', 'me'],\n",
              " ['follow', 'us'],\n",
              " ['follow', 'us'],\n",
              " ['forget', 'it'],\n",
              " ['forget', 'it'],\n",
              " ['forget', 'it'],\n",
              " ['forget', 'it'],\n",
              " ['forget', 'it'],\n",
              " ['forget', 'it'],\n",
              " ['forget', 'it'],\n",
              " ['forget', 'it'],\n",
              " ['forget', 'me'],\n",
              " ['get', 'a', 'job'],\n",
              " ['go', 'for', 'it'],\n",
              " ['go', 'inside'],\n",
              " ['go', 'inside'],\n",
              " ['go', 'inside'],\n",
              " ['go', 'inside'],\n",
              " ['goodnight'],\n",
              " ['hands', 'off'],\n",
              " ['hands', 'off'],\n",
              " ['hands', 'off'],\n",
              " ['have', 'some'],\n",
              " ['have', 'some'],\n",
              " ['have', 'some'],\n",
              " ['he', 'is', 'ill'],\n",
              " ['he', 'is', 'old'],\n",
              " ['he', 'shaved'],\n",
              " ['he', 'shaved'],\n",
              " ['he', 'smiled'],\n",
              " ['hes', 'a', 'dj'],\n",
              " ['hes', 'rich'],\n",
              " ['here', 'i', 'am'],\n",
              " ['heres'],\n",
              " ['hold', 'this'],\n",
              " ['how', 'awful'],\n",
              " ['how', 'awful'],\n",
              " ['how', 'awful'],\n",
              " ['how', 'is', 'it'],\n",
              " ['how', 'is', 'it'],\n",
              " ['hows', 'tom'],\n",
              " ['hows', 'tom'],\n",
              " ['hows', 'tom'],\n",
              " ['i', 'am', 'thai'],\n",
              " ['i', 'am', 'thai'],\n",
              " ['i', 'am', 'busy'],\n",
              " ['i', 'am', 'busy'],\n",
              " ['i', 'am', 'fine'],\n",
              " ['i', 'am', 'full'],\n",
              " ['i', 'am', 'full'],\n",
              " ['i', 'am', 'here'],\n",
              " ['i', 'am', 'here'],\n",
              " ['i', 'am', 'lost'],\n",
              " ['i', 'am', 'okay'],\n",
              " ['i', 'am', 'okay'],\n",
              " ['i', 'am', 'okay'],\n",
              " ['i', 'am', 'sick'],\n",
              " ['i', 'am', 'sick'],\n",
              " ['i', 'am', 'sure'],\n",
              " ['i', 'am', 'tall'],\n",
              " ['i', 'am', 'tall'],\n",
              " ['i', 'am', 'weak'],\n",
              " ['i', 'am', 'weak'],\n",
              " ['i', 'ate', 'out'],\n",
              " ['i', 'blinked'],\n",
              " ['i', 'can', 'fly'],\n",
              " ['i', 'can', 'run'],\n",
              " ['i', 'can', 'run'],\n",
              " ['i', 'can', 'ski'],\n",
              " ['i', 'can', 'win'],\n",
              " ['i', 'cheated'],\n",
              " ['i', 'coughed'],\n",
              " ['i', 'escaped'],\n",
              " ['i', 'fainted'],\n",
              " ['i', 'fainted'],\n",
              " ['i', 'fear', 'so'],\n",
              " ['i', 'get', 'you'],\n",
              " ['i', 'get', 'you'],\n",
              " ['i', 'get', 'you'],\n",
              " ['i', 'give', 'in'],\n",
              " ['i', 'give', 'up'],\n",
              " ['i', 'got', 'hit'],\n",
              " ['i', 'got', 'mad'],\n",
              " ['i', 'got', 'mad'],\n",
              " ['i', 'grunted'],\n",
              " ['i', 'had', 'fun'],\n",
              " ['i', 'hope', 'so'],\n",
              " ['i', 'hope', 'so'],\n",
              " ['i', 'knew', 'it'],\n",
              " ['i', 'laughed'],\n",
              " ['i', 'laughed'],\n",
              " ['i', 'like', 'it'],\n",
              " ['i', 'lost', 'it'],\n",
              " ['i', 'love', 'it'],\n",
              " ['i', 'may', 'win'],\n",
              " ['i', 'mean', 'it'],\n",
              " ['i', 'mean', 'it'],\n",
              " ['i', 'miss', 'it'],\n",
              " ['i', 'miss', 'it'],\n",
              " ['i', 'need', 'it'],\n",
              " ['i', 'need', 'it'],\n",
              " ['i', 'need', 'it'],\n",
              " ['i', 'need', 'it'],\n",
              " ['i', 'noticed'],\n",
              " ['i', 'noticed'],\n",
              " ['i', 'promise'],\n",
              " ['i', 'said', 'no'],\n",
              " ['i', 'said', 'no'],\n",
              " ['i', 'saw', 'tom'],\n",
              " ['i', 'saw', 'tom'],\n",
              " ['i', 'saw', 'him'],\n",
              " ['i', 'saw', 'one'],\n",
              " ['i', 'saw', 'one'],\n",
              " ['i', 'see', 'tom'],\n",
              " ['i', 'shouted'],\n",
              " ['i', 'slipped'],\n",
              " ['i', 'sneezed'],\n",
              " ['i', 'stopped'],\n",
              " ['i', 'studied'],\n",
              " ['i', 'tripped'],\n",
              " ['i', 'tripped'],\n",
              " ['i', 'want', 'it'],\n",
              " ['i', 'want', 'it'],\n",
              " ['i', 'want', 'it'],\n",
              " ['i', 'was', 'sad'],\n",
              " ['i', 'was', 'sad'],\n",
              " ['i', 'was', 'wet'],\n",
              " ['i', 'was', 'wet'],\n",
              " ['i', 'will', 'go'],\n",
              " ['i', 'woke', 'up'],\n",
              " ['id', 'do', 'it'],\n",
              " ['ill', 'call'],\n",
              " ['ill', 'cook'],\n",
              " ['ill', 'live'],\n",
              " ['ill', 'lose'],\n",
              " ['ill', 'sing'],\n",
              " ['ill', 'stay'],\n",
              " ['ill', 'stay'],\n",
              " ['ill', 'stop'],\n",
              " ['ill', 'wait'],\n",
              " ['ill', 'walk'],\n",
              " ['ill', 'work'],\n",
              " ['im', 'a', 'man'],\n",
              " ['im', 'a', 'man'],\n",
              " ['im', 'a', 'pro'],\n",
              " ['im', 'alive'],\n",
              " ['im', 'alive'],\n",
              " ['im', 'alone'],\n",
              " ['im', 'angry'],\n",
              " ['im', 'awake'],\n",
              " ['im', 'blind'],\n",
              " ['im', 'blind'],\n",
              " ['im', 'blind'],\n",
              " ['im', 'blind'],\n",
              " ['im', 'bored'],\n",
              " ['im', 'bored'],\n",
              " ['im', 'bossy'],\n",
              " ['im', 'bossy'],\n",
              " ['im', 'brave'],\n",
              " ['im', 'broke'],\n",
              " ['im', 'broke'],\n",
              " ['im', 'broke'],\n",
              " ['im', 'broke'],\n",
              " ['im', 'broke'],\n",
              " ['im', 'crazy'],\n",
              " ['im', 'drunk'],\n",
              " ['im', 'drunk'],\n",
              " ['im', 'drunk'],\n",
              " ['im', 'drunk'],\n",
              " ['im', 'early'],\n",
              " ['im', 'going'],\n",
              " ['im', 'going'],\n",
              " ['im', 'going'],\n",
              " ['im', 'happy'],\n",
              " ['im', 'happy'],\n",
              " ['im', 'happy'],\n",
              " ['im', 'happy'],\n",
              " ['im', 'loved'],\n",
              " ['im', 'loved'],\n",
              " ['im', 'loved'],\n",
              " ['im', 'loyal'],\n",
              " ['im', 'lucky'],\n",
              " ['im', 'lying'],\n",
              " ['im', 'naive'],\n",
              " ['im', 'naive'],\n",
              " ['im', 'naked'],\n",
              " ['im', 'naked'],\n",
              " ['im', 'obese'],\n",
              " ['im', 'picky'],\n",
              " ['im', 'ready'],\n",
              " ['im', 'ready'],\n",
              " ['im', 'ready'],\n",
              " ['im', 'right'],\n",
              " ['im', 'small'],\n",
              " ['im', 'small'],\n",
              " ['im', 'sober'],\n",
              " ['im', 'sorry'],\n",
              " ['im', 'sorry'],\n",
              " ['im', 'sorry'],\n",
              " ['im', 'sorry'],\n",
              " ['im', 'sorry'],\n",
              " ['im', 'stuck'],\n",
              " ['im', 'stuck'],\n",
              " ['im', 'stuck'],\n",
              " ['im', 'stuck'],\n",
              " ['im', 'timid'],\n",
              " ['im', 'tired'],\n",
              " ['im', 'tired'],\n",
              " ['im', 'tired'],\n",
              " ['im', 'upset'],\n",
              " ['im', 'upset'],\n",
              " ['im', 'upset'],\n",
              " ['im', 'wrong'],\n",
              " ['im', 'wrong'],\n",
              " ['im', 'young'],\n",
              " ['im', 'young'],\n",
              " ['im', 'yours'],\n",
              " ['im', 'yours'],\n",
              " ['im', 'yours'],\n",
              " ['im', 'yours'],\n",
              " ['is', 'tom', 'ok'],\n",
              " ['is', 'tom', 'in'],\n",
              " ['is', 'he', 'tom'],\n",
              " ['is', 'he', 'tom'],\n",
              " ['is', 'it', 'bad'],\n",
              " ['is', 'it', 'far'],\n",
              " ['is', 'it', 'hot'],\n",
              " ['is', 'it', 'you'],\n",
              " ['it', 'burned'],\n",
              " ['it', 'failed'],\n",
              " ['it', 'rained'],\n",
              " ['it', 'snowed'],\n",
              " ['it', 'stinks'],\n",
              " ['it', 'was', 'ok'],\n",
              " ['it', 'worked'],\n",
              " ['its'],\n",
              " ['its'],\n",
              " ['its'],\n",
              " ['its'],\n",
              " ['its', 'a', 'tv'],\n",
              " ['its', 'a', 'tv'],\n",
              " ['its', 'a', 'tv'],\n",
              " ['its', 'cool'],\n",
              " ['its', 'done'],\n",
              " ['its', 'done'],\n",
              " ['its', 'done'],\n",
              " ['its', 'done'],\n",
              " ['its', 'easy'],\n",
              " ['its', 'easy'],\n",
              " ['its', 'fair'],\n",
              " ['its', 'fine'],\n",
              " ['its', 'food'],\n",
              " ['its', 'free'],\n",
              " ['its', 'free'],\n",
              " ['its', 'here'],\n",
              " ['its', 'here'],\n",
              " ['its', 'hers'],\n",
              " ['its', 'hers'],\n",
              " ['its', 'huge'],\n",
              " ['its', 'late'],\n",
              " ['its', 'late'],\n",
              " ['its', 'mine'],\n",
              " ['its', 'mine'],\n",
              " ['its', 'okay'],\n",
              " ['its', 'open'],\n",
              " ['its', 'ours'],\n",
              " ['its', 'over'],\n",
              " ['its', 'time'],\n",
              " ['its', 'true'],\n",
              " ['its', 'true'],\n",
              " ['its', 'work'],\n",
              " ['keep', 'away'],\n",
              " ['keep', 'back'],\n",
              " ['keep', 'back'],\n",
              " ['keep', 'calm'],\n",
              " ['keep', 'cool'],\n",
              " ['keep', 'cool'],\n",
              " ['keep', 'down'],\n",
              " ['keep', 'down'],\n",
              " ['keep', 'that'],\n",
              " ['keep', 'them'],\n",
              " ['keep', 'them'],\n",
              " ['keep', 'this'],\n",
              " ['keep', 'warm'],\n",
              " ['leave', 'tom'],\n",
              " ['leave', 'now'],\n",
              " ['leave', 'now'],\n",
              " ['let', 'me', 'go'],\n",
              " ['let', 'me', 'in'],\n",
              " ['let', 'us', 'in'],\n",
              " ['lets', 'see'],\n",
              " ['listen', 'up'],\n",
              " ['listen', 'up'],\n",
              " ['look', 'back'],\n",
              " ['look', 'back'],\n",
              " ['look', 'back'],\n",
              " ['look', 'back'],\n",
              " ['look', 'back'],\n",
              " ['look', 'here'],\n",
              " ['look', 'here'],\n",
              " ['may', 'i', 'eat'],\n",
              " ['move', 'over'],\n",
              " ['move', 'over'],\n",
              " ['nice', 'shot'],\n",
              " ['of', 'course'],\n",
              " ['of', 'course'],\n",
              " ['of', 'course'],\n",
              " ['of', 'course'],\n",
              " ['of', 'course'],\n",
              " ['open', 'fire'],\n",
              " ['pardon', 'me'],\n",
              " ['pardon', 'me'],\n",
              " ['put', 'it', 'on'],\n",
              " ['read', 'this'],\n",
              " ['read', 'this'],\n",
              " ['say', 'hello'],\n",
              " ['say', 'hello'],\n",
              " ['see', 'above'],\n",
              " ['seize', 'him'],\n",
              " ['seriously'],\n",
              " ['seriously'],\n",
              " ['seriously'],\n",
              " ['seriously'],\n",
              " ['she', 'cried'],\n",
              " ['she', 'cried'],\n",
              " ['she', 'tried'],\n",
              " ['she', 'tried'],\n",
              " ['she', 'walks'],\n",
              " ['she', 'walks'],\n",
              " ['shes', 'hot'],\n",
              " ['shes', 'hot'],\n",
              " ['sign', 'here'],\n",
              " ['sign', 'here'],\n",
              " ['sign', 'this'],\n",
              " ['sign', 'this'],\n",
              " ['sign', 'this'],\n",
              " ['sit', 'still'],\n",
              " ['sit', 'still'],\n",
              " ['sit', 'there'],\n",
              " ['sit', 'there'],\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htuZ6Nc5YAr3",
        "colab_type": "code",
        "outputId": "1ac52bad-0e7d-43b4-9a5b-70d2f37f72b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "texts_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['vai', '#end'],\n",
              " ['vá', '#end'],\n",
              " ['oi', '#end'],\n",
              " ['corre', '#end'],\n",
              " ['corra', '#end'],\n",
              " ['corram', '#end'],\n",
              " ['corre', '#end'],\n",
              " ['corra', '#end'],\n",
              " ['corram', '#end'],\n",
              " ['quem', '#end'],\n",
              " ['uau', '#end'],\n",
              " ['nossa', '#end'],\n",
              " ['wow', '#end'],\n",
              " ['fogo', '#end'],\n",
              " ['ajuda', '#end'],\n",
              " ['socorro', '#end'],\n",
              " ['pule', '#end'],\n",
              " ['pulem', '#end'],\n",
              " ['pule', '#end'],\n",
              " ['pare', '#end'],\n",
              " ['parem', '#end'],\n",
              " ['espere', '#end'],\n",
              " ['espere', '#end'],\n",
              " ['esperem', '#end'],\n",
              " ['vá', '#end'],\n",
              " ['oi', '#end'],\n",
              " ['alô', '#end'],\n",
              " ['olá', '#end'],\n",
              " ['alô', '#end'],\n",
              " ['eu', 'corri', '#end'],\n",
              " ['estou', 'vendo', '#end'],\n",
              " ['eu', 'tento', '#end'],\n",
              " ['tento', '#end'],\n",
              " ['ganhei', '#end'],\n",
              " ['eu', 'venci', '#end'],\n",
              " ['ah', 'não', '#end'],\n",
              " ['relaxe', '#end'],\n",
              " ['relaxa', '#end'],\n",
              " ['tiro', '#end'],\n",
              " ['sorria', '#end'],\n",
              " ['sorriam', '#end'],\n",
              " ['atacar', '#end'],\n",
              " ['ataquem', '#end'],\n",
              " ['ataque', '#end'],\n",
              " ['saúde', '#end'],\n",
              " ['parado', '#end'],\n",
              " ['levantese', '#end'],\n",
              " ['levantemse', '#end'],\n",
              " ['levantate', '#end'],\n",
              " ['levantese', '#end'],\n",
              " ['levantate', '#end'],\n",
              " ['vá', 'agora', '#end'],\n",
              " ['entendi', '#end'],\n",
              " ['eu', 'entendi', '#end'],\n",
              " ['saquei', '#end'],\n",
              " ['entendeu', '#end'],\n",
              " ['ele', 'correu', '#end'],\n",
              " ['ele', 'corria', '#end'],\n",
              " ['sobe', 'aí', '#end'],\n",
              " ['entra', 'aí', '#end'],\n",
              " ['me', 'abrace', '#end'],\n",
              " ['eu', 'caí', '#end'],\n",
              " ['eu', 'sei', '#end'],\n",
              " ['sei', '#end'],\n",
              " ['eu', 'saí', '#end'],\n",
              " ['eu', 'paguei', '#end'],\n",
              " ['eu', 'me', 'demito', '#end'],\n",
              " ['eu', 'estou', 'trabalhando', '#end'],\n",
              " ['estou', 'bem', '#end'],\n",
              " ['eu', 'vou', 'bem', '#end'],\n",
              " ['estou', 'acordado', '#end'],\n",
              " ['escute', '#end'],\n",
              " ['ouçame', '#end'],\n",
              " ['escuta', '#end'],\n",
              " ['escutem', '#end'],\n",
              " ['ouça', 'isso', '#end'],\n",
              " ['escutemme', '#end'],\n",
              " ['escute', '#end'],\n",
              " ['escuta', '#end'],\n",
              " ['escutem', '#end'],\n",
              " ['escutai', '#end'],\n",
              " ['de', 'jeito', 'nenhum', '#end'],\n",
              " ['impossível', '#end'],\n",
              " ['de', 'maneira', 'alguma', '#end'],\n",
              " ['de', 'modo', 'algum', '#end'],\n",
              " ['sem', 'chance', '#end'],\n",
              " ['sério', '#end'],\n",
              " ['é', 'mesmo', '#end'],\n",
              " ['mesmo', '#end'],\n",
              " ['é', 'sério', '#end'],\n",
              " ['obrigado', '#end'],\n",
              " ['obrigada', '#end'],\n",
              " ['obrigado', '#end'],\n",
              " ['tentao', '#end'],\n",
              " ['proveo', '#end'],\n",
              " ['provea', '#end'],\n",
              " ['tentamos', '#end'],\n",
              " ['nós', 'tentamos', '#end'],\n",
              " ['vencemos', '#end'],\n",
              " ['nós', 'vencemos', '#end'],\n",
              " ['por', 'que', 'eu', '#end'],\n",
              " ['pergunte', 'a', 'tom', '#end'],\n",
              " ['peça', 'a', 'tom', '#end'],\n",
              " ['pergunta', 'para', 'o', 'tom', '#end'],\n",
              " ['peça', 'para', 'o', 'tom', '#end'],\n",
              " ['peça', 'ao', 'tom', '#end'],\n",
              " ['perguntem', 'ao', 'tom', '#end'],\n",
              " ['fique', 'calmo', '#end'],\n",
              " ['seja', 'legal', '#end'],\n",
              " ['sede', 'justos', '#end'],\n",
              " ['sede', 'justas', '#end'],\n",
              " ['sejam', 'justos', '#end'],\n",
              " ['sejam', 'justas', '#end'],\n",
              " ['seja', 'justo', '#end'],\n",
              " ['seja', 'justa', '#end'],\n",
              " ['sê', 'justo', '#end'],\n",
              " ['sê', 'justa', '#end'],\n",
              " ['seja', 'bom', '#end'],\n",
              " ['seja', 'boa', '#end'],\n",
              " ['sejam', 'bons', '#end'],\n",
              " ['sejam', 'boas', '#end'],\n",
              " ['sê', 'bom', '#end'],\n",
              " ['sê', 'boa', '#end'],\n",
              " ['sede', 'bons', '#end'],\n",
              " ['sede', 'boas', '#end'],\n",
              " ['seja', 'gentil', '#end'],\n",
              " ['sejam', 'gentis', '#end'],\n",
              " ['sede', 'gentis', '#end'],\n",
              " ['sê', 'gentil', '#end'],\n",
              " ['seja', 'legal', '#end'],\n",
              " ['sejam', 'legais', '#end'],\n",
              " ['se', 'manda', '#end'],\n",
              " ['vaza', '#end'],\n",
              " ['me', 'liga', '#end'],\n",
              " ['ligue', 'para', 'a', 'gente', '#end'],\n",
              " ['entre', '#end'],\n",
              " ['entre', '#end'],\n",
              " ['entrem', '#end'],\n",
              " ['entra', '#end'],\n",
              " ['vamos', '#end'],\n",
              " ['venha', '#end'],\n",
              " ['qual', 'é', '#end'],\n",
              " ['vamos', '#end'],\n",
              " ['solteo', '#end'],\n",
              " ['largue', 'isso', '#end'],\n",
              " ['pegue', 'tom', '#end'],\n",
              " ['saia', '#end'],\n",
              " ['saia', 'daqui', '#end'],\n",
              " ['fora', '#end'],\n",
              " ['sai', '#end'],\n",
              " ['saiam', '#end'],\n",
              " ['saia', '#end'],\n",
              " ['sai', '#end'],\n",
              " ['afastese', '#end'],\n",
              " ['cai', 'fora', '#end'],\n",
              " ['vá', 'embora', '#end'],\n",
              " ['fora', '#end'],\n",
              " ['se', 'manda', '#end'],\n",
              " ['vá', 'embora', '#end'],\n",
              " ['afastese', '#end'],\n",
              " ['cai', 'fora', 'daqui', '#end'],\n",
              " ['vão', 'para', 'casa', '#end'],\n",
              " ['vá', 'para', 'casa', '#end'],\n",
              " ['tchau', '#end'],\n",
              " ['até', 'mais', '#end'],\n",
              " ['até', 'a', 'vista', '#end'],\n",
              " ['até', 'logo', '#end'],\n",
              " ['até', 'mais', 'ver', '#end'],\n",
              " ['até', 'o', 'rever', '#end'],\n",
              " ['aguarde', '#end'],\n",
              " ['aguardem', '#end'],\n",
              " ['aguarde', '#end'],\n",
              " ['aguardem', '#end'],\n",
              " ['ele', 'veio', '#end'],\n",
              " ['ele', 'corre', '#end'],\n",
              " ['me', 'ajuda', '#end'],\n",
              " ['ajudeme', '#end'],\n",
              " ['ajudemme', '#end'],\n",
              " ['me', 'ajude', '#end'],\n",
              " ['ajudeme', '#end'],\n",
              " ['ajudame', '#end'],\n",
              " ['ajudemme', '#end'],\n",
              " ['me', 'ajuda', '#end'],\n",
              " ['ajudeme', '#end'],\n",
              " ['ajudemme', '#end'],\n",
              " ['ajudemnos', '#end'],\n",
              " ['nos', 'ajude', '#end'],\n",
              " ['ajude', 'a', 'gente', '#end'],\n",
              " ['ajudenos', '#end'],\n",
              " ['oi', 'tom', '#end'],\n",
              " ['acerta', 'o', 'tom', '#end'],\n",
              " ['segure', 'isso', '#end'],\n",
              " ['segura', 'isso', '#end'],\n",
              " ['espere', '#end'],\n",
              " ['espera', '#end'],\n",
              " ['abrace', 'o', 'tom', '#end'],\n",
              " ['abracem', 'o', 'tom', '#end'],\n",
              " ['eu', 'concordo', '#end'],\n",
              " ['estou', 'de', 'acordo', '#end'],\n",
              " ['eu', 'estou', 'de', 'acordo', '#end'],\n",
              " ['eu', 'chorei', '#end'],\n",
              " ['eu', 'dirigi', '#end'],\n",
              " ['eu', 'fumo', '#end'],\n",
              " ['eu', 'ronco', '#end'],\n",
              " ['eu', 'cheiro', 'mal', '#end'],\n",
              " ['eu', 'tentei', '#end'],\n",
              " ['tentei', '#end'],\n",
              " ['eu', 'acenei', '#end'],\n",
              " ['eu', 'vou', '#end'],\n",
              " ['eu', 'vou', '#end'],\n",
              " ['estou', 'gordo', '#end'],\n",
              " ['sou', 'gordo', '#end'],\n",
              " ['eu', 'sou', 'gorda', '#end'],\n",
              " ['eu', 'estou', 'gorda', '#end'],\n",
              " ['eu', 'estou', 'em', 'forma', '#end'],\n",
              " ['estou', 'em', 'forma', '#end'],\n",
              " ['tenho', 'calor', '#end'],\n",
              " ['estou', 'com', 'calor', '#end'],\n",
              " ['estou', 'bravo', '#end'],\n",
              " ['eu', 'sou', 'velho', '#end'],\n",
              " ['eu', 'sou', 'velha', '#end'],\n",
              " ['eu', 'estou', 'velho', '#end'],\n",
              " ['eu', 'estou', 'velha', '#end'],\n",
              " ['estou', 'triste', '#end'],\n",
              " ['eu', 'sou', 'triste', '#end'],\n",
              " ['eu', 'estou', 'triste', '#end'],\n",
              " ['eu', 'sou', 'tímido', '#end'],\n",
              " ['estou', 'molhado', '#end'],\n",
              " ['estou', 'molhada', '#end'],\n",
              " ['está', 'tudo', 'bem', '#end'],\n",
              " ['tudo', 'bem', '#end'],\n",
              " ['está', 'bem', '#end'],\n",
              " ['tá', 'bom', '#end'],\n",
              " ['sou', 'eu', '#end'],\n",
              " ['sou', 'eu', '#end'],\n",
              " ['juntese', '#end'],\n",
              " ['juntese', 'a', 'nós', '#end'],\n",
              " ['fique', 'com', 'ele', '#end'],\n",
              " ['fica', 'com', 'ele', '#end'],\n",
              " ['fiquem', 'com', 'ele', '#end'],\n",
              " ['fique', 'com', 'ela', '#end'],\n",
              " ['fica', 'com', 'ela', '#end'],\n",
              " ['fiquem', 'com', 'ela', '#end'],\n",
              " ['me', 'beija', '#end'],\n",
              " ['dême', 'um', 'beijo', '#end'],\n",
              " ['beijeme', '#end'],\n",
              " ['me', 'beije', '#end'],\n",
              " ['olhe', 'para', 'cima', '#end'],\n",
              " ['olha', 'pra', 'cima', '#end'],\n",
              " ['olhe', 'pra', 'cima', '#end'],\n",
              " ['olha', 'para', 'cima', '#end'],\n",
              " ['eu', 'também', '#end'],\n",
              " ['abra', '#end'],\n",
              " ['perfeito', '#end'],\n",
              " ['nos', 'vemos', '#end'],\n",
              " ['até', 'mais', '#end'],\n",
              " ['até', 'logo', '#end'],\n",
              " ['nos', 'vemos', '#end'],\n",
              " ['a', 'gente', 'se', 'vê', '#end'],\n",
              " ['mostreme', '#end'],\n",
              " ['me', 'mostre', '#end'],\n",
              " ['me', 'mostra', '#end'],\n",
              " ['cale', 'a', 'boca', '#end'],\n",
              " ['cala', 'a', 'boca', '#end'],\n",
              " ['calate', '#end'],\n",
              " ['calese', '#end'],\n",
              " ['calem', 'a', 'boca', '#end'],\n",
              " ['calemse', '#end'],\n",
              " ['pare', 'com', 'isso', '#end'],\n",
              " ['pare', '#end'],\n",
              " ['para', 'com', 'isso', '#end'],\n",
              " ['pegueo', '#end'],\n",
              " ['peguemno', '#end'],\n",
              " ['pegueo', '#end'],\n",
              " ['pegao', '#end'],\n",
              " ['peguemno', '#end'],\n",
              " ['peguea', '#end'],\n",
              " ['pegaa', '#end'],\n",
              " ['peguemna', '#end'],\n",
              " ['digame', '#end'],\n",
              " ['digamme', '#end'],\n",
              " ['dizme', '#end'],\n",
              " ['o', 'tom', 'comeu', '#end'],\n",
              " ['tom', 'comeu', '#end'],\n",
              " ['tom', 'correu', '#end'],\n",
              " ['o', 'tom', 'correu', '#end'],\n",
              " ['tom', 'ganhou', '#end'],\n",
              " ['esperem', '#end'],\n",
              " ['espere', '#end'],\n",
              " ['acorda', '#end'],\n",
              " ['acorde', '#end'],\n",
              " ['acordem', '#end'],\n",
              " ['acorde', '#end'],\n",
              " ['acordem', '#end'],\n",
              " ['lavate', '#end'],\n",
              " ['lavese', '#end'],\n",
              " ['lavemse', '#end'],\n",
              " ['lave', 'as', 'mãos', '#end'],\n",
              " ['lave', 'o', 'rosto', '#end'],\n",
              " ['nós', 'nos', 'importamos', '#end'],\n",
              " ['nós', 'sabemos', '#end'],\n",
              " ['perdemos', '#end'],\n",
              " ['nós', 'perdemos', '#end'],\n",
              " ['seja', 'bemvindo', '#end'],\n",
              " ['bemvindo', '#end'],\n",
              " ['seja', 'bemvinda', '#end'],\n",
              " ['bemvinda', '#end'],\n",
              " ['quem', 'comeu', '#end'],\n",
              " ['quem', 'correu', '#end'],\n",
              " ['quem', 'ganhou', '#end'],\n",
              " ['por', 'que', 'não', '#end'],\n",
              " ['você', 'corre', '#end'],\n",
              " ['corra', '#end'],\n",
              " ['você', 'ganhou', '#end'],\n",
              " ['você', 'venceu', '#end'],\n",
              " ['vocês', 'venceram', '#end'],\n",
              " ['estou', 'gordo', '#end'],\n",
              " ['estou', 'gorda', '#end'],\n",
              " ['pergunte', 'para', 'eles', '#end'],\n",
              " ['pergunte', 'para', 'elas', '#end'],\n",
              " ['para', 'trás', '#end'],\n",
              " ['recue', '#end'],\n",
              " ['recuem', '#end'],\n",
              " ['recua', '#end'],\n",
              " ['seja', 'corajoso', '#end'],\n",
              " ['seja', 'valente', '#end'],\n",
              " ['seja', 'breve', '#end'],\n",
              " ['fique', 'quieta', '#end'],\n",
              " ['fique', 'quieto', '#end'],\n",
              " ['acalmese', '#end'],\n",
              " ['não', 'faço', 'ideia', '#end'],\n",
              " ['ligue', 'para', 'o', 'tom', '#end'],\n",
              " ['posso', 'ir', '#end'],\n",
              " ['ânimo', '#end'],\n",
              " ['acalmese', '#end'],\n",
              " ['acalmese', '#end'],\n",
              " ['algemeo', '#end'],\n",
              " ['não', 'vá', '#end'],\n",
              " ['dirija', '#end'],\n",
              " ['encontre', 'o', 'tom', '#end'],\n",
              " ['encontrem', 'o', 'tom', '#end'],\n",
              " ['conserta', 'isto', '#end'],\n",
              " ['cai', 'fora', '#end'],\n",
              " ['fora', '#end'],\n",
              " ['se', 'manda', '#end'],\n",
              " ['abaixese', '#end'],\n",
              " ['desça', '#end'],\n",
              " ['escreva', '#end'],\n",
              " ['abaixese', '#end'],\n",
              " ['deitemse', '#end'],\n",
              " ['se', 'manda', '#end'],\n",
              " ['vaite', 'embora', '#end'],\n",
              " ['váse', 'embora', '#end'],\n",
              " ['se', 'manda', '#end'],\n",
              " ['acorda', '#end'],\n",
              " ['cai', 'na', 'real', '#end'],\n",
              " ['acorda', '#end'],\n",
              " ['cai', 'na', 'real', '#end'],\n",
              " ['vá', 'em', 'frente', '#end'],\n",
              " ['continue', '#end'],\n",
              " ['continua', '#end'],\n",
              " ['vá', 'em', 'frente', '#end'],\n",
              " ['continue', '#end'],\n",
              " ['continuem', '#end'],\n",
              " ['bom', 'trabalho', '#end'],\n",
              " ['pegue', 'o', 'tom', '#end'],\n",
              " ['agarreo', '#end'],\n",
              " ['agarremno', '#end'],\n",
              " ['divertete', '#end'],\n",
              " ['divirtamse', '#end'],\n",
              " ['divirtase', '#end'],\n",
              " ['ele', 'falou', '#end'],\n",
              " ['ele', 'tenta', '#end'],\n",
              " ['ele', 'está', 'molhado', '#end'],\n",
              " ['ajude', 'o', 'tom', '#end'],\n",
              " ['ajuda', 'o', 'tom', '#end'],\n",
              " ['ajudem', 'o', 'tom', '#end'],\n",
              " ['olá', 'pessoal', '#end'],\n",
              " ['que', 'bonitinho', '#end'],\n",
              " ['que', 'fofinho', '#end'],\n",
              " ['que', 'fofinha', '#end'],\n",
              " ['que', 'bonitinha', '#end'],\n",
              " ['quão', 'fundo', '#end'],\n",
              " ['qual', 'a', 'profundidade', '#end'],\n",
              " ['qual', 'é', 'a', 'profundidade', '#end'],\n",
              " ['que', 'legal', '#end'],\n",
              " ['apressese', '#end'],\n",
              " ['depressa', '#end'],\n",
              " ['apressate', '#end'],\n",
              " ['se', 'apressa', '#end'],\n",
              " ['eu', 'concordo', '#end'],\n",
              " ['estou', 'gordo', '#end'],\n",
              " ['sou', 'gordo', '#end'],\n",
              " ['eu', 'sou', 'gorda', '#end'],\n",
              " ['eu', 'estou', 'gorda', '#end'],\n",
              " ['tenho', 'calor', '#end'],\n",
              " ['estou', 'com', 'calor', '#end'],\n",
              " ['eu', 'arrotei', '#end'],\n",
              " ['eu', 'posso', 'ir', '#end'],\n",
              " ['eu', 'consigo', 'ir', '#end'],\n",
              " ['eu', 'dancei', '#end'],\n",
              " ['eu', 'fracassei', '#end'],\n",
              " ['eu', 'me', 'esqueci', '#end'],\n",
              " ['eu', 'esqueci', '#end'],\n",
              " ['esqueci', '#end'],\n",
              " ['me', 'esqueci', '#end'],\n",
              " ['eu', 'entendo', '#end'],\n",
              " ['entendi', '#end'],\n",
              " ['eu', 'entendi', '#end'],\n",
              " ['eu', 'me', 'levantei', '#end'],\n",
              " ['eu', 'ajudei', '#end'],\n",
              " ['eu', 'pulei', '#end'],\n",
              " ['eu', 'olhei', '#end'],\n",
              " ['balancei', 'a', 'cabeça', '#end'],\n",
              " ['eu', 'balancei', 'a', 'cabeça', '#end'],\n",
              " ['eu', 'telefonei', '#end'],\n",
              " ['eu', 'orei', '#end'],\n",
              " ['eu', 'rezei', '#end'],\n",
              " ['eu', 'me', 'demito', '#end'],\n",
              " ['eu', 'descansei', '#end'],\n",
              " ['eu', 'o', 'vi', '#end'],\n",
              " ['eu', 'sorri', '#end'],\n",
              " ['dei', 'um', 'sorriso', '#end'],\n",
              " ['eu', 'fiquei', '#end'],\n",
              " ['eu', 'falei', '#end'],\n",
              " ['eu', 'esperei', '#end'],\n",
              " ['eu', 'pisquei', '#end'],\n",
              " ['eu', 'bocejei', '#end'],\n",
              " ['eu', 'pagarei', '#end'],\n",
              " ['tentarei', '#end'],\n",
              " ['vou', 'vencer', '#end'],\n",
              " ['voltei', '#end'],\n",
              " ['sou', 'careca', '#end'],\n",
              " ['eu', 'sou', 'careca', '#end'],\n",
              " ['estou', 'careca', '#end'],\n",
              " ['estou', 'ocupado', '#end'],\n",
              " ['estou', 'ocupada', '#end'],\n",
              " ['estou', 'com', 'frio', '#end'],\n",
              " ['sou', 'legal', '#end'],\n",
              " ['sou', 'surdo', '#end'],\n",
              " ['já', 'terminei', '#end'],\n",
              " ['eu', 'sou', 'justo', '#end'],\n",
              " ['sou', 'rápido', '#end'],\n",
              " ['estou', 'bem', '#end'],\n",
              " ['eu', 'vou', 'bem', '#end'],\n",
              " ['eu', 'estou', 'bem', '#end'],\n",
              " ['eu', 'sou', 'livre', '#end'],\n",
              " ['estou', 'livre', '#end'],\n",
              " ['estou', 'cheio', '#end'],\n",
              " ['estou', 'cheia', '#end'],\n",
              " ['estou', 'contente', '#end'],\n",
              " ['eu', 'vou', 'bem', '#end'],\n",
              " ['estou', 'aqui', '#end'],\n",
              " ['eu', 'estou', 'aqui', '#end'],\n",
              " ['cheguei', '#end'],\n",
              " ['estou', 'machucado', '#end'],\n",
              " ['estou', 'ferido', '#end'],\n",
              " ['estou', 'perdido', '#end'],\n",
              " ['sou', 'o', 'próximo', '#end'],\n",
              " ['sou', 'a', 'próxima', '#end'],\n",
              " ['estou', 'bem', '#end'],\n",
              " ['eu', 'estou', 'bem', '#end'],\n",
              " ['sou', 'pobre', '#end'],\n",
              " ['eu', 'sou', 'rico', '#end'],\n",
              " ['eu', 'sou', 'rica', '#end'],\n",
              " ['eu', 'estou', 'seguro', '#end'],\n",
              " ['estou', 'doente', '#end'],\n",
              " ['estou', 'doente', '#end'],\n",
              " ['estou', 'enfermo', '#end'],\n",
              " ['estou', 'enferma', '#end'],\n",
              " ['eu', 'estou', 'enfermo', '#end'],\n",
              " ['tenho', 'certeza', '#end'],\n",
              " ['eu', 'sou', 'alto', '#end'],\n",
              " ['eu', 'sou', 'magro', '#end'],\n",
              " ['sou', 'magro', '#end'],\n",
              " ['estou', 'arrumado', '#end'],\n",
              " ['eu', 'estou', 'arrumado', '#end'],\n",
              " ['sou', 'feio', '#end'],\n",
              " ['estou', 'feio', '#end'],\n",
              " ['sou', 'feia', '#end'],\n",
              " ['estou', 'feia', '#end'],\n",
              " ['estou', 'bem', '#end'],\n",
              " ['eu', 'sou', 'sábio', '#end'],\n",
              " ['eu', 'venci', '#end'],\n",
              " ['isso', 'ajuda', '#end'],\n",
              " ['isso', 'machuca', '#end'],\n",
              " ['funciona', '#end'],\n",
              " ['é', 'o', 'tom', '#end'],\n",
              " ['é', 'divertido', '#end'],\n",
              " ['é', 'dele', '#end'],\n",
              " ['está', 'quente', '#end'],\n",
              " ['isso', 'é', 'novo', '#end'],\n",
              " ['isso', 'está', 'novo', '#end'],\n",
              " ['é', 'velho', '#end'],\n",
              " ['é', 'vermelho', '#end'],\n",
              " ['isso', 'é', 'vermelho', '#end'],\n",
              " ['é', 'vermelha', '#end'],\n",
              " ['é', 'triste', '#end'],\n",
              " ['não', 'entre', '#end'],\n",
              " ['afastese', '#end'],\n",
              " ['não', 'entre', '#end'],\n",
              " ['afastese', '#end'],\n",
              " ['beije', 'tom', '#end'],\n",
              " ['deixe', 'para', 'lá', '#end'],\n",
              " ['me', 'deixe', '#end'],\n",
              " ['deixeme', '#end'],\n",
              " ['me', 'deixa', '#end'],\n",
              " ['deixenos', '#end'],\n",
              " ['nos', 'deixe', '#end'],\n",
              " ['vamos', '#end'],\n",
              " ['vamos', '#end'],\n",
              " ['preste', 'atenção', '#end'],\n",
              " ['atenção', '#end'],\n",
              " ['cuidado', '#end'],\n",
              " ['case', 'comigo', '#end'],\n",
              " ['posso', 'ir', '#end'],\n",
              " ['salve', 'o', 'tom', '#end'],\n",
              " ['salve', 'a', 'tom', '#end'],\n",
              " ['ela', 'veio', '#end'],\n",
              " ['ela', 'morreu', '#end'],\n",
              " ['ela', 'corre', '#end'],\n",
              " ['assentese', '#end'],\n",
              " ['sentese', '#end'],\n",
              " ['senta', 'aqui', '#end'],\n",
              " ['sentese', 'aqui', '#end'],\n",
              " ['fale', 'mais', 'alto', '#end'],\n",
              " ['falem', 'mais', 'alto', '#end'],\n",
              " ['fala', 'mais', 'alto', '#end'],\n",
              " ['aguarde', '#end'],\n",
              " ['aguardem', '#end'],\n",
              " ['levantese', '#end'],\n",
              " ['de', 'pé', '#end'],\n",
              " ['levantese', '#end'],\n",
              " ['levantemse', '#end'],\n",
              " ['pare', 'o', 'tom', '#end'],\n",
              " ['parem', 'o', 'tom', '#end'],\n",
              " ['impeça', 'o', 'tom', '#end'],\n",
              " ['impeçam', 'o', 'tom', '#end'],\n",
              " ['interrompa', 'o', 'tom', '#end'],\n",
              " ['interrompam', 'o', 'tom', '#end'],\n",
              " ['leve', 'o', 'tom', '#end'],\n",
              " ['leva', 'o', 'tom', '#end'],\n",
              " ['conte', 'ao', 'tom', '#end'],\n",
              " ['contem', 'ao', 'tom', '#end'],\n",
              " ['conta', 'para', 'o', 'tom', '#end'],\n",
              " ['fantástico', '#end'],\n",
              " ['genial', '#end'],\n",
              " ['excelente', '#end'],\n",
              " ['magnífico', '#end'],\n",
              " ['eles', 'ganharam', '#end'],\n",
              " ['elas', 'ganharam', '#end'],\n",
              " ['elas', 'venceram', '#end'],\n",
              " ['eles', 'venceram', '#end'],\n",
              " ['tom', 'veio', '#end'],\n",
              " ['tom', 'morreu', '#end'],\n",
              " ['o', 'tom', 'morreu', '#end'],\n",
              " ['tom', 'caiu', '#end'],\n",
              " ['tom', 'sabia', '#end'],\n",
              " ['tom', 'mentiu', '#end'],\n",
              " ['tom', 'mente', '#end'],\n",
              " ['o', 'tom', 'perdeu', '#end'],\n",
              " ['o', 'tom', 'pagou', '#end'],\n",
              " ['tom', 'desistiu', '#end'],\n",
              " ['o', 'tom', 'nadou', '#end'],\n",
              " ['tom', 'nadou', '#end'],\n",
              " ['tarde', 'demais', '#end'],\n",
              " ['confie', 'em', 'mim', '#end'],\n",
              " ['esforcese', '#end'],\n",
              " ['se', 'esforça', '#end'],\n",
              " ['experimenta', '#end'],\n",
              " ['experimente', '#end'],\n",
              " ['experimentem', '#end'],\n",
              " ['experimenta', 'isto', '#end'],\n",
              " ['experimente', 'isto', '#end'],\n",
              " ['experimentem', 'isto', '#end'],\n",
              " ['use', 'isso', '#end'],\n",
              " ['avise', 'ao', 'tom', '#end'],\n",
              " ['avisem', 'ao', 'tom', '#end'],\n",
              " ['alerte', 'o', 'tom', '#end'],\n",
              " ['fale', 'para', 'o', 'tom', '#end'],\n",
              " ['observeme', '#end'],\n",
              " ['concordamos', '#end'],\n",
              " ['nós', 'concordamos', '#end'],\n",
              " ['nós', 'tentamos', '#end'],\n",
              " ['nós', 'iremos', '#end'],\n",
              " ['estamos', 'bem', '#end'],\n",
              " ['para', 'quê', '#end'],\n",
              " ['que', 'divertido', '#end'],\n",
              " ['quem', 'sou', 'eu', '#end'],\n",
              " ['quem', 'veio', '#end'],\n",
              " ['quem', 'morreu', '#end'],\n",
              " ['quem', 'caiu', '#end'],\n",
              " ['quem', 'desistiu', '#end'],\n",
              " ['quem', 'nadou', '#end'],\n",
              " ['escrevame', '#end'],\n",
              " ['você', 'primeiro', '#end'],\n",
              " ['preparar', 'apontar', 'fogo', '#end'],\n",
              " ['estou', 'atrasado', '#end'],\n",
              " ['respondame', '#end'],\n",
              " ['respondamme', '#end'],\n",
              " ['respondame', '#end'],\n",
              " ['respondamme', '#end'],\n",
              " ['me', 'responde', '#end'],\n",
              " ['me', 'responda', '#end'],\n",
              " ['sentaivos', '#end'],\n",
              " ['pássaros', 'voam', '#end'],\n",
              " ['os', 'pássaros', 'voam', '#end'],\n",
              " ['saúde', '#end'],\n",
              " ['ligue', 'para', 'casa', '#end'],\n",
              " ['acalmese', '#end'],\n",
              " ['acalmese', '#end'],\n",
              " ['acalmese', '#end'],\n",
              " ['acalmate', '#end'],\n",
              " ['acalmemse', '#end'],\n",
              " ['te', 'acalma', '#end'],\n",
              " ['aquieta', 'o', 'facho', '#end'],\n",
              " ['posso', 'comer', '#end'],\n",
              " ['pegue', 'o', 'tom', '#end'],\n",
              " ['peguem', 'o', 'tom', '#end'],\n",
              " ['pegueo', '#end'],\n",
              " ['volte', '#end'],\n",
              " ['voltem', '#end'],\n",
              " ['venha', 'aqui', '#end'],\n",
              " ['vem', 'cá', '#end'],\n",
              " ['venha', 'para', 'casa', '#end'],\n",
              " ['vem', '#end'],\n",
              " ['venham', '#end'],\n",
              " ['venha', '#end'],\n",
              " ['venha', '#end'],\n",
              " ['venha', 'logo', '#end'],\n",
              " ['acalmese', '#end'],\n",
              " ['acalmese', '#end'],\n",
              " ['acalmemse', '#end'],\n",
              " ['se', 'acalme', '#end'],\n",
              " ['eu', 'ganhei', '#end'],\n",
              " ['cães', 'latem', '#end'],\n",
              " ['cachorros', 'latem', '#end'],\n",
              " ['não', 'faça', 'perguntas', '#end'],\n",
              " ['não', 'pergunte', '#end'],\n",
              " ['não', 'pergunte', '#end'],\n",
              " ['não', 'chore', '#end'],\n",
              " ['não', 'chorem', '#end'],\n",
              " ['não', 'morra', '#end'],\n",
              " ['não', 'morram', '#end'],\n",
              " ['não', 'minta', '#end'],\n",
              " ['não', 'corra', '#end'],\n",
              " ['não', 'corram', '#end'],\n",
              " ['não', 'corras', '#end'],\n",
              " ['perdão', '#end'],\n",
              " ['com', 'licença', '#end'],\n",
              " ['desculpa', '#end'],\n",
              " ['desculpe', '#end'],\n",
              " ['o', 'quê', '#end'],\n",
              " ['o', 'que', 'você', 'disse', '#end'],\n",
              " ['perdão', '#end'],\n",
              " ['fantástico', '#end'],\n",
              " ['sinta', 'isso', '#end'],\n",
              " ['sigame', '#end'],\n",
              " ['sigamme', '#end'],\n",
              " ['me', 'siga', '#end'],\n",
              " ['me', 'sigam', '#end'],\n",
              " ['siganos', '#end'],\n",
              " ['sigamnos', '#end'],\n",
              " ['esqueça', '#end'],\n",
              " ['esquece', '#end'],\n",
              " ['esqueça', '#end'],\n",
              " ['esquece', '#end'],\n",
              " ['esqueçam', '#end'],\n",
              " ['esqueça', '#end'],\n",
              " ['esquece', '#end'],\n",
              " ['deixa', '#end'],\n",
              " ['esqueçame', '#end'],\n",
              " ['arrume', 'um', 'emprego', '#end'],\n",
              " ['vá', 'em', 'frente', '#end'],\n",
              " ['entre', '#end'],\n",
              " ['entra', '#end'],\n",
              " ['vá', 'para', 'dentro', '#end'],\n",
              " ['vai', 'para', 'dentro', '#end'],\n",
              " ['boa', 'noite', '#end'],\n",
              " ['tira', 'as', 'mãos', '#end'],\n",
              " ['tire', 'as', 'mãos', '#end'],\n",
              " ['tirem', 'as', 'mãos', '#end'],\n",
              " ['pega', 'um', 'pouco', '#end'],\n",
              " ['pegue', 'um', 'pouco', '#end'],\n",
              " ['peguem', 'um', 'pouco', '#end'],\n",
              " ['ele', 'está', 'doente', '#end'],\n",
              " ['ele', 'é', 'velho', '#end'],\n",
              " ['ele', 'se', 'barbeou', '#end'],\n",
              " ['se', 'barbeou', '#end'],\n",
              " ['ele', 'sorriu', '#end'],\n",
              " ['ele', 'é', 'dj', '#end'],\n",
              " ['ele', 'é', 'rico', '#end'],\n",
              " ['aqui', 'estou', '#end'],\n",
              " ['aqui', 'estão', 'dólares', '#end'],\n",
              " ['segure', 'isto', '#end'],\n",
              " ['que', 'horror', '#end'],\n",
              " ['que', 'terrível', '#end'],\n",
              " ['que', 'ridículo', '#end'],\n",
              " ['como', 'é', 'isso', '#end'],\n",
              " ['como', 'isso', 'é', '#end'],\n",
              " ['como', 'tom', 'está', '#end'],\n",
              " ['como', 'está', 'o', 'tom', '#end'],\n",
              " ['como', 'vai', 'o', 'tom', '#end'],\n",
              " ['sou', 'tailandês', '#end'],\n",
              " ['eu', 'sou', 'tailandês', '#end'],\n",
              " ['estou', 'ocupado', '#end'],\n",
              " ['estou', 'ocupada', '#end'],\n",
              " ['eu', 'vou', 'bem', '#end'],\n",
              " ['estou', 'cheio', '#end'],\n",
              " ['estou', 'cheia', '#end'],\n",
              " ['estou', 'aqui', '#end'],\n",
              " ['eu', 'estou', 'aqui', '#end'],\n",
              " ['estou', 'perdido', '#end'],\n",
              " ['estou', 'bem', '#end'],\n",
              " ['eu', 'vou', 'bem', '#end'],\n",
              " ['eu', 'estou', 'bem', '#end'],\n",
              " ['estou', 'doente', '#end'],\n",
              " ['sou', 'doente', '#end'],\n",
              " ['tenho', 'certeza', '#end'],\n",
              " ['eu', 'sou', 'alto', '#end'],\n",
              " ['sou', 'alto', '#end'],\n",
              " ['eu', 'sou', 'fraco', '#end'],\n",
              " ['eu', 'estou', 'fraco', '#end'],\n",
              " ['eu', 'comi', 'fora', '#end'],\n",
              " ['eu', 'pisquei', '#end'],\n",
              " ['eu', 'sei', 'voar', '#end'],\n",
              " ['eu', 'posso', 'correr', '#end'],\n",
              " ['eu', 'sei', 'correr', '#end'],\n",
              " ['eu', 'sei', 'esquiar', '#end'],\n",
              " ['eu', 'posso', 'ganhar', '#end'],\n",
              " ['eu', 'trapaceei', '#end'],\n",
              " ['eu', 'tossi', '#end'],\n",
              " ['eu', 'escapei', '#end'],\n",
              " ['eu', 'desmaiei', '#end'],\n",
              " ['desmaiei', '#end'],\n",
              " ['eu', 'temo', 'que', 'sim', '#end'],\n",
              " ['eu', 'te', 'entendo', '#end'],\n",
              " ['te', 'entendo', '#end'],\n",
              " ['eu', 'entendo', 'você', '#end'],\n",
              " ['eu', 'me', 'rendo', '#end'],\n",
              " ['eu', 'desisto', '#end'],\n",
              " ['fui', 'atingido', '#end'],\n",
              " ['fiquei', 'furioso', '#end'],\n",
              " ['eu', 'fiquei', 'furioso', '#end'],\n",
              " ['eu', 'resmunguei', '#end'],\n",
              " ['eu', 'me', 'diverti', '#end'],\n",
              " ['assim', 'espero', '#end'],\n",
              " ['espero', 'que', 'sim', '#end'],\n",
              " ['eu', 'sabia', '#end'],\n",
              " ['eu', 'ri', '#end'],\n",
              " ['ri', '#end'],\n",
              " ['eu', 'gosto', 'dele', '#end'],\n",
              " ['eu', 'o', 'perdi', '#end'],\n",
              " ['eu', 'amo', 'isso', '#end'],\n",
              " ['eu', 'posso', 'ganhar', '#end'],\n",
              " ['estou', 'falando', 'sério', '#end'],\n",
              " ['eu', 'estou', 'falando', 'sério', '#end'],\n",
              " ['saudades', '#end'],\n",
              " ['saudades', 'disso', '#end'],\n",
              " ['eu', 'preciso', 'disso', '#end'],\n",
              " ['preciso', 'disso', '#end'],\n",
              " ['eu', 'preciso', '#end'],\n",
              " ['preciso', '#end'],\n",
              " ['eu', 'notei', '#end'],\n",
              " ['notei', '#end'],\n",
              " ['eu', 'prometo', '#end'],\n",
              " ['eu', 'disse', 'que', 'não', '#end'],\n",
              " ['disse', 'que', 'não', '#end'],\n",
              " ['eu', 'vi', 'o', 'tom', '#end'],\n",
              " ['vi', 'o', 'tom', '#end'],\n",
              " ['eu', 'o', 'vi', '#end'],\n",
              " ['eu', 'vi', 'um', '#end'],\n",
              " ['eu', 'vi', 'uma', '#end'],\n",
              " ['eu', 'vejo', 'o', 'tom', '#end'],\n",
              " ['eu', 'gritei', '#end'],\n",
              " ['eu', 'escorreguei', '#end'],\n",
              " ['eu', 'espirrei', '#end'],\n",
              " ['eu', 'parei', '#end'],\n",
              " ['eu', 'estudei', '#end'],\n",
              " ['eu', 'tropecei', '#end'],\n",
              " ['tropecei', '#end'],\n",
              " ['quero', '#end'],\n",
              " ['eu', 'quero', 'isso', '#end'],\n",
              " ['quero', 'isso', '#end'],\n",
              " ['eu', 'estava', 'triste', '#end'],\n",
              " ['eu', 'fiquei', 'triste', '#end'],\n",
              " ['eu', 'estava', 'molhado', '#end'],\n",
              " ['eu', 'estava', 'molhada', '#end'],\n",
              " ['eu', 'vou', '#end'],\n",
              " ['eu', 'acordei', '#end'],\n",
              " ['eu', 'faria', 'isso', '#end'],\n",
              " ['ligarei', '#end'],\n",
              " ['cozinharei', '#end'],\n",
              " ['eu', 'vou', 'viver', '#end'],\n",
              " ['vou', 'perder', '#end'],\n",
              " ['cantarei', '#end'],\n",
              " ['ficarei', '#end'],\n",
              " ['eu', 'vou', 'ficar', '#end'],\n",
              " ['eu', 'vou', 'parar', '#end'],\n",
              " ['esperarei', '#end'],\n",
              " ['andarei', '#end'],\n",
              " ['eu', 'vou', 'trabalhar', '#end'],\n",
              " ['eu', 'sou', 'homem', '#end'],\n",
              " ['sou', 'um', 'homem', '#end'],\n",
              " ['sou', 'um', 'profissional', '#end'],\n",
              " ['estou', 'vivo', '#end'],\n",
              " ['estou', 'viva', '#end'],\n",
              " ['estou', 'sozinho', '#end'],\n",
              " ['estou', 'com', 'raiva', '#end'],\n",
              " ['estou', 'acordado', '#end'],\n",
              " ['sou', 'cega', '#end'],\n",
              " ['sou', 'cego', '#end'],\n",
              " ['eu', 'sou', 'cega', '#end'],\n",
              " ['eu', 'sou', 'cego', '#end'],\n",
              " ['estou', 'chateado', '#end'],\n",
              " ['eu', 'estou', 'entediado', '#end'],\n",
              " ['eu', 'sou', 'mandona', '#end'],\n",
              " ['eu', 'sou', 'mandão', '#end'],\n",
              " ['eu', 'sou', 'corajoso', '#end'],\n",
              " ['estou', 'sem', 'dinheiro', '#end'],\n",
              " ['eu', 'estou', 'duro', '#end'],\n",
              " ['estou', 'duro', '#end'],\n",
              " ['estou', 'falido', '#end'],\n",
              " ['estou', 'quebrado', '#end'],\n",
              " ['estou', 'bravo', '#end'],\n",
              " ['estou', 'bêbado', '#end'],\n",
              " ['estou', 'embriagado', '#end'],\n",
              " ['eu', 'estou', 'embriagado', '#end'],\n",
              " ['estou', 'bêbada', '#end'],\n",
              " ['estou', 'adiantado', '#end'],\n",
              " ['eu', 'vou', '#end'],\n",
              " ['estou', 'indo', '#end'],\n",
              " ['já', 'vou', '#end'],\n",
              " ['eu', 'sou', 'feliz', '#end'],\n",
              " ['eu', 'estou', 'feliz', '#end'],\n",
              " ['sou', 'feliz', '#end'],\n",
              " ['estou', 'feliz', '#end'],\n",
              " ['eu', 'sou', 'amado', '#end'],\n",
              " ['eu', 'sou', 'amada', '#end'],\n",
              " ['sou', 'amado', '#end'],\n",
              " ['eu', 'sou', 'leal', '#end'],\n",
              " ['eu', 'sou', 'sortudo', '#end'],\n",
              " ['estou', 'mentindo', '#end'],\n",
              " ['eu', 'sou', 'ingênua', '#end'],\n",
              " ['eu', 'sou', 'ingênuo', '#end'],\n",
              " ['estou', 'pelado', '#end'],\n",
              " ['estou', 'pelada', '#end'],\n",
              " ['estou', 'obeso', '#end'],\n",
              " ['sou', 'exigente', '#end'],\n",
              " ['estou', 'pronto', '#end'],\n",
              " ['estou', 'pronta', '#end'],\n",
              " ['estou', 'pronto', '#end'],\n",
              " ['eu', 'estou', 'certo', '#end'],\n",
              " ['eu', 'sou', 'pequena', '#end'],\n",
              " ['eu', 'sou', 'pequeno', '#end'],\n",
              " ['estou', 'sóbrio', '#end'],\n",
              " ['desculpa', '#end'],\n",
              " ['desculpe', '#end'],\n",
              " ['lamento', '#end'],\n",
              " ['me', 'desculpe', '#end'],\n",
              " ['sinto', 'muito', '#end'],\n",
              " ['estou', 'preso', '#end'],\n",
              " ['eu', 'estou', 'presa', '#end'],\n",
              " ['eu', 'estou', 'preso', '#end'],\n",
              " ['estou', 'presa', '#end'],\n",
              " ['eu', 'sou', 'tímido', '#end'],\n",
              " ['estou', 'cansado', '#end'],\n",
              " ['eu', 'estou', 'cansado', '#end'],\n",
              " ['estou', 'cansado', '#end'],\n",
              " ['estou', 'chateado', '#end'],\n",
              " ['estou', 'chateada', '#end'],\n",
              " ['eu', 'estou', 'chateado', '#end'],\n",
              " ['estou', 'errado', '#end'],\n",
              " ['estou', 'errada', '#end'],\n",
              " ['eu', 'sou', 'jovem', '#end'],\n",
              " ['sou', 'jovem', '#end'],\n",
              " ['sou', 'seu', '#end'],\n",
              " ['eu', 'sou', 'seu', '#end'],\n",
              " ['eu', 'sou', 'sua', '#end'],\n",
              " ['sou', 'sua', '#end'],\n",
              " ['o', 'tom', 'está', 'bem', '#end'],\n",
              " ['o', 'tom', 'está', 'dentro', '#end'],\n",
              " ['ele', 'é', 'o', 'tom', '#end'],\n",
              " ['é', 'ele', 'o', 'tom', '#end'],\n",
              " ['é', 'grave', '#end'],\n",
              " ['é', 'longe', '#end'],\n",
              " ['está', 'calor', '#end'],\n",
              " ['é', 'você', '#end'],\n",
              " ['queimou', '#end'],\n",
              " ['falhou', '#end'],\n",
              " ['estava', 'chovendo', '#end'],\n",
              " ['nevou', '#end'],\n",
              " ['isso', 'fede', '#end'],\n",
              " ['foi', 'bonzinho', '#end'],\n",
              " ['funcionou', '#end'],\n",
              " ['são', '#end'],\n",
              " ['são', '#end'],\n",
              " ['são', '#end'],\n",
              " ['são', '#end'],\n",
              " ['é', 'uma', 'tv', '#end'],\n",
              " ['isso', 'é', 'uma', 'tv', '#end'],\n",
              " ['isto', 'é', 'uma', 'tv', '#end'],\n",
              " ['é', 'legal', '#end'],\n",
              " ['pronto', 'já', 'está', '#end'],\n",
              " ['está', 'pronto', '#end'],\n",
              " ['está', 'pronto', '#end'],\n",
              " ['está', 'pronta', '#end'],\n",
              " ['isso', 'é', 'fácil', '#end'],\n",
              " ['é', 'fácil', '#end'],\n",
              " ['é', 'justo', '#end'],\n",
              " ['está', 'bem', '#end'],\n",
              " ['é', 'comida', '#end'],\n",
              " ['é', 'de', 'graça', '#end'],\n",
              " ['é', 'gratuito', '#end'],\n",
              " ['está', 'aqui', '#end'],\n",
              " ['é', 'aqui', '#end'],\n",
              " ['é', 'dela', '#end'],\n",
              " ['isso', 'é', 'dela', '#end'],\n",
              " ['é', 'enorme', '#end'],\n",
              " ['está', 'tarde', '#end'],\n",
              " ['é', 'tarde', '#end'],\n",
              " ['é', 'meu', '#end'],\n",
              " ['é', 'minha', '#end'],\n",
              " ['está', 'bem', '#end'],\n",
              " ['está', 'aberto', '#end'],\n",
              " ['é', 'nosso', '#end'],\n",
              " ['acabou', '#end'],\n",
              " ['está', 'na', 'hora', '#end'],\n",
              " ['é', 'verdade', '#end'],\n",
              " ['é', 'verdade', '#end'],\n",
              " ['é', 'trabalho', '#end'],\n",
              " ['mantenhase', 'afastado', '#end'],\n",
              " ['afastese', '#end'],\n",
              " ['fique', 'afastado', '#end'],\n",
              " ['acalmese', '#end'],\n",
              " ['mantenha', 'a', 'calma', '#end'],\n",
              " ['te', 'acalma', '#end'],\n",
              " ['fique', 'abaixado', '#end'],\n",
              " ['fique', 'abaixada', '#end'],\n",
              " ['fique', 'com', 'isso', '#end'],\n",
              " ['fique', 'com', 'eles', '#end'],\n",
              " ['fique', 'com', 'elas', '#end'],\n",
              " ['fique', 'com', 'isto', '#end'],\n",
              " ['mantenha', 'aquecido', '#end'],\n",
              " ['deixe', 'o', 'tom', '#end'],\n",
              " ['saia', 'agora', '#end'],\n",
              " ['vá', 'embora', 'agora', '#end'],\n",
              " ['deixeme', 'ir', 'embora', '#end'],\n",
              " ['deixeme', 'entrar', '#end'],\n",
              " ['deixenos', 'entrar', '#end'],\n",
              " ['vejamos', '#end'],\n",
              " ['escute', '#end'],\n",
              " ['escutem', '#end'],\n",
              " ['olhe', 'para', 'trás', '#end'],\n",
              " ['olhem', 'para', 'trás', '#end'],\n",
              " ['olha', 'pra', 'trás', '#end'],\n",
              " ['olhe', 'para', 'trás', '#end'],\n",
              " ['olhem', 'para', 'trás', '#end'],\n",
              " ['olhe', 'aqui', '#end'],\n",
              " ['olha', 'aqui', '#end'],\n",
              " ['posso', 'comer', '#end'],\n",
              " ['chegue', 'para', 'frente', '#end'],\n",
              " ['chega', 'para', 'frente', '#end'],\n",
              " ['belo', 'tiro', '#end'],\n",
              " ['claro', '#end'],\n",
              " ['claro', 'que', 'sim', '#end'],\n",
              " ['é', 'claro', '#end'],\n",
              " ['é', 'claro', '#end'],\n",
              " ['pois', 'sim', '#end'],\n",
              " ['abrir', 'fogo', '#end'],\n",
              " ['o', 'que', 'você', 'disse', '#end'],\n",
              " ['perdão', '#end'],\n",
              " ['coloqueo', '#end'],\n",
              " ['leia', 'isso', '#end'],\n",
              " ['leiam', 'isso', '#end'],\n",
              " ['diga', 'olá', '#end'],\n",
              " ['cumprimenta', '#end'],\n",
              " ['vejam', 'acima', '#end'],\n",
              " ['agarreo', '#end'],\n",
              " ['sério', '#end'],\n",
              " ['é', 'mesmo', '#end'],\n",
              " ['mesmo', '#end'],\n",
              " ['é', 'sério', '#end'],\n",
              " ['ela', 'chorou', '#end'],\n",
              " ['ela', 'chorava', '#end'],\n",
              " ['ela', 'tentou', '#end'],\n",
              " ['ela', 'tentava', '#end'],\n",
              " ['ela', 'anda', '#end'],\n",
              " ['ela', 'caminha', '#end'],\n",
              " ['ela', 'é', 'gata', '#end'],\n",
              " ['ela', 'está', 'com', 'calor', '#end'],\n",
              " ['assine', 'aqui', '#end'],\n",
              " ['assina', 'aqui', '#end'],\n",
              " ['assine', 'isso', '#end'],\n",
              " ['assinem', 'isso', '#end'],\n",
              " ['assine', '#end'],\n",
              " ['fique', 'parado', '#end'],\n",
              " ['fique', 'parada', '#end'],\n",
              " ['senta', 'aí', '#end'],\n",
              " ['sentese', 'aí', '#end'],\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D8YE1JIYAr9",
        "colab_type": "text"
      },
      "source": [
        "La importancia de este paso es muy alta ya que un símbolo de diferencia al inicio o al final de una palabra podria hacer que la red neuronal reconozca a como dos palabras diferentes a una misma palabra acompañada o no por un símbolo  (como por ejemplo en español \"\"¡Hola!\"\" con \"Hola\", o en inglés \"How are you?\" con \"How are you\").  \n",
        "Por otra parte, el símbolo de término (#end en este caso) debe ser un string que no esté presente en las palabras del texto para no producir errores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFoxBI_Vb_mM"
      },
      "source": [
        "### Cree un conjunto de validación y de pruebas fijos de $N_{exp} = 10000$ datos ¿Cuántos datos quedan para entrenar? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hqsMBp19cB_Y",
        "colab": {}
      },
      "source": [
        "N_exp=10000\n",
        "X_train_l, X_test_l, Y_train_l, Y_test_l = train_test_split(texts_input, texts_output, test_size=N_exp, random_state=22)\n",
        "X_train_l, X_val_l, Y_train_l, Y_val_l = train_test_split(X_train_l, Y_train_l,test_size=N_exp, random_state=22)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTdVugFXYAsJ",
        "colab_type": "code",
        "outputId": "00d6c0f7-4eb3-4d1f-85e8-f21dfdde9808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('X_train_l tiene', len(X_train_l), 'elementos.')\n",
        "print('Y_train_l tiene', len(Y_train_l), 'elementos.')\n",
        "print('X_val_l tiene', len(X_val_l), 'elementos.')\n",
        "print('Y_val_l tiene', len(Y_val_l), 'elementos.')\n",
        "print('X_test_l tiene', len(X_test_l), 'elementos.')\n",
        "print('Y_test_l tiene', len(Y_test_l), 'elementos.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_l tiene 125693 elementos.\n",
            "Y_train_l tiene 125693 elementos.\n",
            "X_val_l tiene 10000 elementos.\n",
            "Y_val_l tiene 10000 elementos.\n",
            "X_test_l tiene 10000 elementos.\n",
            "Y_test_l tiene 10000 elementos.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4dujW3GYAsP",
        "colab_type": "text"
      },
      "source": [
        "Debido a que el idioma que se eligió (portugues) contiene muchas sentencias, la cantidad de datos disponibles para entrenar es de $115.671$ ejemplos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ankaX2IZcIv5"
      },
      "source": [
        "### c) Genere un vocabulario, **desde el conjunto de entrenamiento**, sobre las palabras a recibir y generar en la traducción, esto es codificarlas a un valor entero que servirá para que la red las vea en una representación útil a procesar, *comience desde el 1 debido a que el cero será utilizado más adelante*. Para reducir el vocabulario considere las palabras que aparecen un mínimo de *min_count* veces en todo los datos, se aconseja un valor de 3. Comente sobre la importancia de ésto al reducir el vocabulario ¿De qué tamaño es el vocabulario de entrada y salida? ¿La diferencia de ésto podría ser un factor importante?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN5vUp3EYAsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_vocab(texts, min_count=1):\n",
        "    count_vocab = {}\n",
        "    for sentence in texts:\n",
        "        for word in sentence:\n",
        "            if word not in count_vocab:\n",
        "                count_vocab[word] = 1\n",
        "            else:\n",
        "                count_vocab[word] += 1\n",
        "    return [word for word,count in count_vocab.items() if count >= min_count]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6U51Gvh_cK9w",
        "colab": {}
      },
      "source": [
        "vocab_source = create_vocab(X_train_l, min_count=3)\n",
        "word2idx_s = {w: i+1 for i, w in enumerate(vocab_source)} #index (i+1) start from 1,2,3,...\n",
        "idx2word_s = {i+1: w for i, w in enumerate(vocab_source)}\n",
        "n_words_s = len(vocab_source)\n",
        "\n",
        "vocab_target = create_vocab(Y_train_l, min_count=3)\n",
        "word2idx_t = {w: i+1 for i, w in enumerate(vocab_target)} #Converting text to numbers\n",
        "idx2word_t = {i+1: w for i, w in enumerate(vocab_target)}#Converting number to text\n",
        "n_words_t = len(vocab_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xMKElFYYAsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"El largo del vocabulario source es de\",n_words_s,\"palabras.\")\n",
        "print(\"El largo del vocabulario target es de\",n_words_t,\"palabras.\")\n",
        "print(\"Por lo que la diferencia es de\",str(int(n_words_t)-int(n_words_s)), \"palabras.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lTDr2v5YAsy",
        "colab_type": "text"
      },
      "source": [
        "En el preprocesamiento, es muy importante reducir la cantidad de palabras y no considerar las que salen pocas veces, con esto se ayuda a que el modelo evite el overfitting que pueda existir al aprender palabras con muy baja ocurrencia \"de memoria\".    \n",
        "\n",
        "La diferencia del tamaño de los vocabularios es, efectivamente, un factor a considerar porque si la cantidad de palabras del vocabulario inicial es más grande, puede que muchas palabras del vocabulario de entrada tengan como significado una palabra del vocabulario de salida. En el caso contrario, podria resultar perjudicial para el aprendizaje que una sola palabra en el vocabulario de inicio tenga múltiples significados o correspondencias en el vocabulario de salida.    \n",
        "\n",
        "En particular, en nuestro caso, la diferencia es de $2.806$ palabras; un valor alto para las cantidades de palabras que estamos tratando en nuestros vocabularios, con una mayor cantidad de palabras en el vocabulario de salida.  Cabe señalar que el método de aprendizaje a considerar no traducirá palabra a palabra si no que considerará, mediante herramientas de recurrencia, el contexto de una oración. De ahí  que el problema que se mencionó anteriormente, deja de influir tanto en el aprendizaje.  (No se trata como un problema de clases desbalanceadas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ncaY5H5ScOQS"
      },
      "source": [
        "### Ahora codifique las palabras a los números indexados con el vocabulario. Recuerde que si una palabra en los otros conjuntos, o en el mismo de entrenamiento, no aparece en el vocabulario no se podrá generar una codificación, por lo que será **ignorada** ¿Cómo se podría evitar ésto?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EJiwtbvOcQco",
        "colab": {}
      },
      "source": [
        "\"\"\" Source/input data \"\"\"\n",
        "dataX_train = [[word2idx_s[word] for word in sent if word in word2idx_s] for sent in X_train_l]\n",
        "dataX_valid = [[word2idx_s[word] for word in sent if word in word2idx_s] for sent in X_val_l]\n",
        "dataX_test = [[word2idx_s[word] for word in sent if word in word2idx_s] for sent in X_test_l]\n",
        "\n",
        "\"\"\" Target/output data \"\"\"\n",
        "dataY_train = [[word2idx_t[word] for word in sent if word in word2idx_t] for sent in Y_train_l]\n",
        "dataY_valid = [[word2idx_t[word] for word in sent if word in word2idx_t] for sent in Y_val_l] \n",
        "dataY_test = [[word2idx_t[word] for word in sent if word in word2idx_t] for sent in Y_test_l] \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnDDZ9ADYAs7",
        "colab_type": "code",
        "outputId": "8cff9230-5e60-4cc3-97cb-ec9992e87bb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dataX_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
              " [10, 11, 12],\n",
              " [13, 14, 15, 16],\n",
              " [17, 18, 5, 19, 20, 21],\n",
              " [22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
              " [32, 14, 33, 34, 35, 36],\n",
              " [37, 38, 28, 39, 35, 40, 41],\n",
              " [42, 43, 44, 45],\n",
              " [46, 47],\n",
              " [48, 49, 50, 51],\n",
              " [52, 2, 53, 54],\n",
              " [55, 40, 56],\n",
              " [57, 58, 59],\n",
              " [48, 60, 50, 35, 40, 61, 62],\n",
              " [10, 63, 64, 65],\n",
              " [66, 67, 51, 68, 69, 70, 14, 71],\n",
              " [72, 14, 73, 74, 75, 76, 77],\n",
              " [42, 2, 40, 26, 78, 79],\n",
              " [17, 80, 18, 81, 23, 14, 82, 42, 83, 84],\n",
              " [17, 85, 86, 87, 10],\n",
              " [88, 67, 5, 89, 90, 91, 92],\n",
              " [17, 18, 5, 93, 94],\n",
              " [70, 95, 96, 76, 97, 98],\n",
              " [17, 63, 29, 99, 100],\n",
              " [93, 101, 102, 10, 103, 40, 65, 104],\n",
              " [105, 10, 19, 106, 107],\n",
              " [17, 108, 109, 14, 110],\n",
              " [111, 2, 58, 112, 113, 114],\n",
              " [115, 110, 2, 116, 117, 35, 84],\n",
              " [42, 118, 14, 119, 120, 121],\n",
              " [37, 122, 123, 124, 23, 125, 126],\n",
              " [42, 127, 128, 23, 10],\n",
              " [129, 130, 131],\n",
              " [17, 18, 5, 132, 133],\n",
              " [14, 134, 135, 136, 137],\n",
              " [138, 139, 58, 140, 141, 17, 142, 1],\n",
              " [105, 10, 122, 143],\n",
              " [14, 144, 145, 146, 147, 148, 149, 91, 150, 40, 151, 152, 35, 153, 154, 155],\n",
              " [63, 10, 156, 157, 42, 158],\n",
              " [17, 80, 18, 5, 19, 159],\n",
              " [160, 105, 10, 38, 42, 161, 162],\n",
              " [42, 163, 40, 164, 165],\n",
              " [42, 2, 166],\n",
              " [66, 63, 167, 23, 168, 5, 169],\n",
              " [170, 84, 171, 172, 23, 39],\n",
              " [173, 162, 160, 14, 174, 175, 84],\n",
              " [17, 176, 111, 42, 2, 177],\n",
              " [178, 108, 179, 51, 141, 24],\n",
              " [180, 2, 40, 181],\n",
              " [48, 120, 14, 33, 182, 17, 150, 183, 5, 184, 75],\n",
              " [185, 186, 2, 187, 188],\n",
              " [66, 176, 32, 75],\n",
              " [189, 190, 2, 39],\n",
              " [75, 191, 93, 40, 192, 193],\n",
              " [162, 10, 194, 195],\n",
              " [196, 197, 198, 14, 199, 14, 200, 201, 202, 203, 14, 204, 201],\n",
              " [80, 205, 39, 66, 63, 206],\n",
              " [115, 2, 14, 207, 17, 208, 209],\n",
              " [210, 211, 212],\n",
              " [213, 214, 215, 23, 131],\n",
              " [17, 216, 18, 5, 217, 5, 218],\n",
              " [76, 10, 219, 5, 84],\n",
              " [17, 120, 87, 42, 33, 220],\n",
              " [10, 105, 39, 209, 108, 10],\n",
              " [173, 93, 75, 70, 40, 221, 222],\n",
              " [223, 2, 211, 224, 23, 225],\n",
              " [42, 2, 226],\n",
              " [76, 10, 227],\n",
              " [17, 85, 228, 229, 230],\n",
              " [42, 2, 14, 231, 232, 233, 52],\n",
              " [17, 108, 176, 160, 5, 38],\n",
              " [14, 234, 70, 115, 235, 2, 236, 237],\n",
              " [238, 239, 240, 63, 10, 150],\n",
              " [241, 242, 243, 244, 233, 245, 233, 186],\n",
              " [17, 246, 247, 5, 248],\n",
              " [29, 249, 250, 2, 251],\n",
              " [17, 38, 42, 85, 162, 39],\n",
              " [179, 7, 68, 14, 252, 253],\n",
              " [66, 63, 254, 23, 255, 70, 14, 256],\n",
              " [17, 184, 40, 257],\n",
              " [241, 258, 2, 259, 260, 40, 261, 168],\n",
              " [262, 51, 14, 263, 70, 58, 264],\n",
              " [17, 265, 115, 110, 26, 266],\n",
              " [29, 267, 268, 23, 29, 269, 52],\n",
              " [17, 80, 176, 160, 5, 59],\n",
              " [178, 270, 84, 39, 17, 271, 93, 44, 272],\n",
              " [273, 274, 275, 276],\n",
              " [17, 176, 39, 42, 2, 40, 221, 27],\n",
              " [115, 2, 29, 61, 277],\n",
              " [107, 278, 29, 279],\n",
              " [57, 14, 280],\n",
              " [66, 281, 136, 282, 91, 40, 112],\n",
              " [89, 283, 51, 42, 91, 6, 50, 39, 106, 2, 284],\n",
              " [17, 80, 285, 5, 286, 287],\n",
              " [66, 76, 216, 28, 14, 231, 232],\n",
              " [17, 288, 160, 17, 289, 107, 5, 29, 267],\n",
              " [42, 163, 211, 290, 291],\n",
              " [42, 292, 70, 293, 24, 33, 220],\n",
              " [66, 271, 294],\n",
              " [2, 42, 295, 75],\n",
              " [17, 63, 40, 296],\n",
              " [24, 297, 76, 298, 299, 115, 147],\n",
              " [17, 216, 34, 42, 300, 301, 302, 52, 303, 304],\n",
              " [305, 306, 307],\n",
              " [185, 308, 2, 309, 29],\n",
              " [189, 310, 2, 1],\n",
              " [42, 295, 311, 305, 40, 188, 312],\n",
              " [313, 314, 315, 66, 197, 162, 316],\n",
              " [10, 197, 317, 318, 10, 18],\n",
              " [319, 10, 320, 84, 77],\n",
              " [238, 321, 322, 10, 102, 10, 22, 130, 323],\n",
              " [40, 324, 163, 325, 326, 91, 40, 327, 328],\n",
              " [80, 320, 51],\n",
              " [14, 119, 329, 2, 330],\n",
              " [331, 17, 332, 50],\n",
              " [42, 108, 33, 325],\n",
              " [17, 333, 29, 334, 72, 14, 335],\n",
              " [173, 93, 26, 336, 318, 17, 197, 337, 10],\n",
              " [160, 319, 338, 5, 42],\n",
              " [339, 340, 163, 305, 341],\n",
              " [25, 259, 5, 93, 70, 293, 24, 220],\n",
              " [17, 80, 18, 5, 342, 5, 58, 343],\n",
              " [17, 344, 10, 161, 345, 1, 266],\n",
              " [17, 346, 260, 39, 347, 348, 349],\n",
              " [160, 162, 10, 63, 350, 35, 21],\n",
              " [115, 351, 120, 352, 353, 70, 244],\n",
              " [17, 289, 316, 72, 354],\n",
              " [42, 278, 355, 159],\n",
              " [17, 356, 26, 357],\n",
              " [42, 358, 359, 14, 104],\n",
              " [42, 360, 176, 52],\n",
              " [361, 362, 363, 364, 322, 365],\n",
              " [342, 5, 14, 366],\n",
              " [42, 367, 336],\n",
              " [223, 2, 368, 5, 369],\n",
              " [162, 10, 38, 42, 370, 52],\n",
              " [42, 371, 185, 372, 23, 373, 87, 52],\n",
              " [178, 83, 40, 374, 23, 375],\n",
              " [80, 376, 159, 72, 14, 377],\n",
              " [42, 2, 259, 5, 378, 361],\n",
              " [25, 379, 23, 10],\n",
              " [66, 271, 380, 293, 252, 381],\n",
              " [17, 80, 382],\n",
              " [76, 10, 383, 25, 14, 384, 385, 316],\n",
              " [42, 386, 387, 388, 389],\n",
              " [17, 390, 391, 40, 307, 70, 14, 256],\n",
              " [162, 10, 176, 238, 5, 162, 115],\n",
              " [173, 392, 1, 51, 5, 10],\n",
              " [393, 65],\n",
              " [88, 67, 40, 310],\n",
              " [196, 394, 39],\n",
              " [42, 395, 102, 178, 396, 52],\n",
              " [42, 295, 397, 398, 51],\n",
              " [42, 399, 301, 35, 40, 325, 168, 400, 28, 160, 178, 271, 162],\n",
              " [401, 67, 402],\n",
              " [173, 390, 403, 70, 10],\n",
              " [25, 259, 5, 404, 405],\n",
              " [406, 6, 42, 52, 407],\n",
              " [162, 10, 285, 408],\n",
              " [17, 409, 410, 87, 10],\n",
              " [17, 411, 5, 19, 412],\n",
              " [42, 270, 84, 39, 178, 413, 306, 194],\n",
              " [178, 2, 211, 414, 415],\n",
              " [17, 416, 58, 417],\n",
              " [262, 68, 241, 418],\n",
              " [160, 162, 17, 419, 5, 162],\n",
              " [10, 419, 5, 6, 84, 160, 420],\n",
              " [160, 421, 23, 422, 162, 10, 285],\n",
              " [162, 10, 86, 5, 241, 423],\n",
              " [424, 29, 425],\n",
              " [17, 426, 318, 42, 163, 427, 39, 428],\n",
              " [111, 161, 129, 382],\n",
              " [66, 80, 18, 10, 5, 162, 39],\n",
              " [111, 76, 10, 429, 316],\n",
              " [25, 216, 40, 242],\n",
              " [17, 421, 23, 285, 1, 316],\n",
              " [17, 80, 430, 159],\n",
              " [66, 150, 5, 431, 432],\n",
              " [76, 10, 433, 84],\n",
              " [42, 2, 40],\n",
              " [17, 426, 434, 42, 197, 435, 233, 245, 233, 52, 197],\n",
              " [42, 436, 14, 437, 5, 52],\n",
              " [42, 438, 14, 439],\n",
              " [42, 163, 254, 23, 440],\n",
              " [52, 2, 40],\n",
              " [160, 76, 10, 259, 5, 162, 5, 84],\n",
              " [53, 441, 2, 442, 443],\n",
              " [17, 18, 5, 444, 53, 445],\n",
              " [129, 76, 410, 28, 160, 129, 319, 446],\n",
              " [17, 63, 40, 447, 448],\n",
              " [162, 10, 63, 81, 139],\n",
              " [42, 449, 450],\n",
              " [196, 191, 176],\n",
              " [80, 451, 14, 452],\n",
              " [37, 247, 156, 453, 355, 39, 454],\n",
              " [17, 38, 313, 361, 455, 70, 456, 5, 457, 458],\n",
              " [25, 259, 5, 419, 459],\n",
              " [40, 62, 460, 461, 185, 462, 463, 93, 464],\n",
              " [17, 285, 465],\n",
              " [17, 80, 18, 5, 466, 53, 467],\n",
              " [468, 147, 120, 58, 249],\n",
              " [469, 470, 14, 471, 472, 473, 2, 39, 25, 474],\n",
              " [42, 360, 18, 5, 459],\n",
              " [475, 5, 14, 476, 477, 478, 230],\n",
              " [17, 479, 5, 480, 481],\n",
              " [75, 76, 482, 483, 70, 484, 39, 485, 285, 5, 380],\n",
              " [318, 10, 19, 116, 239, 138, 404, 12],\n",
              " [40, 486, 85, 139, 185],\n",
              " [487, 488, 404, 40, 489, 72],\n",
              " [10, 11, 284, 35, 115],\n",
              " [17, 80, 18, 5, 382, 5, 42],\n",
              " [42, 490, 51, 77, 491],\n",
              " [42, 83, 77, 492, 5, 14, 112],\n",
              " [42, 2, 481, 454],\n",
              " [160, 105, 10, 91, 42, 19, 35, 493],\n",
              " [14, 494, 472, 495],\n",
              " [323, 2, 496, 42, 497],\n",
              " [318, 14, 498, 2, 14, 499, 23, 14, 500, 2, 14, 499, 23, 501],\n",
              " [42, 273, 39],\n",
              " [17, 502, 50, 503, 504],\n",
              " [42, 2, 390, 505, 506, 507],\n",
              " [42, 163, 508, 509],\n",
              " [17, 34, 66, 63, 510, 168],\n",
              " [129, 85, 511, 512, 42],\n",
              " [513, 514, 14, 515, 91, 516, 29, 517],\n",
              " [75, 76, 482, 518, 519, 363, 241, 520],\n",
              " [17, 289, 8, 521],\n",
              " [42, 522, 5, 523, 185, 524],\n",
              " [25, 247, 525],\n",
              " [17, 80, 285, 526, 20],\n",
              " [42, 163, 40, 527, 460, 2, 40, 528, 529],\n",
              " [17, 426, 160, 185, 530, 2],\n",
              " [10, 191, 531, 84, 160, 10, 176],\n",
              " [42, 532, 87, 84],\n",
              " [111, 80, 10, 156, 162, 39, 343],\n",
              " [160, 2, 58, 530],\n",
              " [52, 2, 40, 26, 533, 534],\n",
              " [2, 75, 225, 72, 535],\n",
              " [17, 34, 5, 184, 72, 29, 536, 5, 537],\n",
              " [42, 538, 432],\n",
              " [539, 540, 10, 355],\n",
              " [160, 541, 10, 8, 442, 209],\n",
              " [17, 80, 18, 5, 444, 28, 160, 10, 105, 209],\n",
              " [10, 265, 84, 496, 361, 147, 315, 120, 542],\n",
              " [42, 2, 543, 278, 178],\n",
              " [14, 544, 10, 18, 5, 217, 5, 333, 144, 545, 546],\n",
              " [25, 547, 32, 548],\n",
              " [14, 549, 550, 551, 14, 61, 552],\n",
              " [88, 553, 157, 42, 554, 285, 115, 428],\n",
              " [17, 80, 38, 42, 2, 233, 555, 233, 178, 411, 5, 93],\n",
              " [17, 216, 108, 176, 160, 5, 378],\n",
              " [556, 557, 558],\n",
              " [17, 559, 115, 560],\n",
              " [42, 91, 52, 76, 26, 336],\n",
              " [42, 120, 265, 87, 14, 561, 562],\n",
              " [52, 2, 563, 458, 564],\n",
              " [76, 10, 565, 5, 566, 5, 293, 567],\n",
              " [25, 568, 1],\n",
              " [111, 80, 10, 378, 450],\n",
              " [42, 246, 569, 14, 119],\n",
              " [17, 161, 162, 159, 216, 5, 570, 10, 70, 29, 571],\n",
              " [42, 120, 572, 321, 68, 39, 168],\n",
              " [314, 197, 573, 131],\n",
              " [17, 396, 39],\n",
              " [197, 10, 459, 406],\n",
              " [111, 11, 10, 72, 14, 574, 575],\n",
              " [102, 105, 10, 573, 576],\n",
              " [17, 18, 10, 5, 577, 58, 100],\n",
              " [578, 35, 579],\n",
              " [42, 2, 580, 363, 52],\n",
              " [42, 384, 581, 5, 582, 366],\n",
              " [583, 247, 160, 42, 394],\n",
              " [17, 413, 19, 159, 315],\n",
              " [17, 584, 14, 585],\n",
              " [17, 419, 53, 586],\n",
              " [322, 20, 23, 587],\n",
              " [58, 588, 2, 589, 5, 590],\n",
              " [591, 592, 178, 509, 25, 295, 593],\n",
              " [305, 115, 110],\n",
              " [453, 247, 5, 93, 594, 230],\n",
              " [25, 542, 595, 5, 596, 42],\n",
              " [10, 76, 116, 597, 5, 598],\n",
              " [77, 599, 285, 39],\n",
              " [14, 412, 2, 384, 600, 601],\n",
              " [160, 161, 10, 602, 84, 5, 162],\n",
              " [196, 603],\n",
              " [173, 210, 10, 68, 604],\n",
              " [115, 2, 40, 605, 23, 14, 606, 17, 120, 72],\n",
              " [17, 607, 42, 39, 17, 608, 46, 70, 323, 35, 44, 363, 136, 137],\n",
              " [305, 187, 40, 609],\n",
              " [453, 526, 450, 610],\n",
              " [319, 10, 611, 406, 573, 612],\n",
              " [52, 2, 613],\n",
              " [241, 614, 242, 615, 40, 616, 72, 14, 617],\n",
              " [42, 618, 40, 619, 5, 620, 39, 178, 161, 553, 55, 14, 231, 621, 454],\n",
              " [42, 344, 17, 120, 622],\n",
              " [105, 42, 89],\n",
              " [238, 482, 623, 162, 10, 176, 238, 5, 122],\n",
              " [624, 84, 77, 154],\n",
              " [42, 214, 603, 40, 625, 44, 363, 178, 270, 131],\n",
              " [10, 626, 378, 39, 421, 23, 473, 102, 550, 76, 203],\n",
              " [10, 80, 63, 81, 312, 160, 5, 162, 162, 10],\n",
              " [627, 17, 628, 40, 629],\n",
              " [213, 630, 631, 115, 168],\n",
              " [42, 120, 632, 70, 633],\n",
              " [14, 634, 635, 136, 572, 636],\n",
              " [17, 265, 10],\n",
              " [10, 627, 637, 35, 40, 638, 318, 10, 639, 40, 640],\n",
              " [160, 105, 10, 18, 5, 641, 84],\n",
              " [17, 416, 14, 642, 23, 643],\n",
              " [42, 163, 644],\n",
              " [10, 262, 645],\n",
              " [42, 278, 526],\n",
              " [42, 319, 214, 93, 646],\n",
              " [111, 162, 10, 38, 42, 2, 555],\n",
              " [271, 17, 109, 450, 35, 50],\n",
              " [29, 647, 120, 648, 115, 71],\n",
              " [649, 650, 40, 625, 8, 42],\n",
              " [42, 2, 442, 304, 8, 651],\n",
              " [573],\n",
              " [592, 17, 120, 652, 17, 105, 29, 653],\n",
              " [80, 276, 72, 42],\n",
              " [14, 654, 2, 655],\n",
              " [1, 2, 656, 657, 5, 132, 40, 658, 659, 70, 40, 327, 168],\n",
              " [25, 542, 35, 40, 660],\n",
              " [24, 23, 218, 76, 610],\n",
              " [42, 2, 65, 87, 185, 206, 661],\n",
              " [17, 394, 17, 120, 662],\n",
              " [42, 2, 40, 663, 530, 91, 52, 2, 40, 664, 530],\n",
              " [178, 665, 666],\n",
              " [17, 419, 5, 184, 42, 667],\n",
              " [305, 53, 249],\n",
              " [42, 470, 178, 360, 668, 355, 39],\n",
              " [76, 10, 177, 23, 42],\n",
              " [66, 669, 670, 304, 87, 42],\n",
              " [25, 671, 672, 7, 661],\n",
              " [66, 322, 284],\n",
              " [42, 2, 147, 23, 14, 471, 673, 599, 17, 176],\n",
              " [305, 674, 5, 478, 21],\n",
              " [2, 39, 160, 42, 675],\n",
              " [305, 676, 107],\n",
              " [105, 10, 677, 678],\n",
              " [42, 360, 170, 52, 356],\n",
              " [48, 679, 143, 70, 14, 71],\n",
              " [406, 80, 435, 316],\n",
              " [42, 680, 681, 185, 493, 349],\n",
              " [42, 108, 89, 5, 14, 682],\n",
              " [66, 319, 683, 40, 684, 685, 252, 220],\n",
              " [686, 17, 108, 687, 39],\n",
              " [10, 270, 84, 39, 209],\n",
              " [185, 688, 659, 2, 244],\n",
              " [102, 105, 42, 6, 10, 39],\n",
              " [17, 689, 690, 691, 5, 692],\n",
              " [66, 197, 435],\n",
              " [2, 14, 112, 72, 14, 588, 693, 694, 14, 588],\n",
              " [361, 552, 304],\n",
              " [238, 239, 105, 10, 695, 72, 115],\n",
              " [17, 176, 496, 10, 696],\n",
              " [178, 67, 652, 567],\n",
              " [42, 108, 18, 5, 217, 5, 84],\n",
              " [17, 38, 39, 42, 243, 244, 245],\n",
              " [42, 2, 697],\n",
              " [698, 85, 93, 699, 700],\n",
              " [17, 63, 5, 162, 1],\n",
              " [10, 191, 701, 702, 703],\n",
              " [14, 144, 704, 705],\n",
              " [48, 120, 706, 503, 40, 707, 708],\n",
              " [42, 360, 285, 709, 710, 693, 691],\n",
              " [14, 711, 712, 713],\n",
              " [714, 125, 84],\n",
              " [17, 715, 75, 40, 716, 546],\n",
              " [1, 120, 116, 261, 35, 84],\n",
              " [178, 163, 717, 24, 185, 718, 5, 185, 527],\n",
              " [25, 247, 14, 231, 719, 17, 120, 720, 572, 546],\n",
              " [42, 108, 285, 14, 721],\n",
              " [129, 76, 722, 40, 165],\n",
              " [17, 306, 285, 115, 723],\n",
              " [66, 162, 160, 66, 18, 5, 162],\n",
              " [17, 724, 39, 17, 80, 725],\n",
              " [42, 603, 52, 488, 363, 195],\n",
              " [196, 2, 355, 159],\n",
              " [17, 306, 285, 726, 225],\n",
              " [25, 259, 5, 727],\n",
              " [591, 318, 1, 728, 17, 319, 729, 481, 230, 71],\n",
              " [160, 162, 10, 730, 70, 731, 460, 5, 732, 35],\n",
              " [115, 2, 42, 733, 485, 285, 5, 734, 5, 52],\n",
              " [42, 735, 736],\n",
              " [17, 150, 5, 737, 42],\n",
              " [185, 738, 739, 50, 5, 740],\n",
              " [245, 741],\n",
              " [42, 270, 84, 160, 150, 420],\n",
              " [25, 742, 25, 259, 5, 369, 188, 743],\n",
              " [75, 76, 482, 744, 70, 241, 560],\n",
              " [745, 14, 697, 147],\n",
              " [115, 2, 29, 653, 746],\n",
              " [1, 747, 285, 42, 120, 9],\n",
              " [48, 50, 5, 651, 748],\n",
              " [42, 163, 136, 749, 750, 70, 185, 751, 752],\n",
              " [17, 753, 754, 755],\n",
              " [25, 177, 23, 756],\n",
              " [460, 757, 172, 23, 10],\n",
              " [42, 394, 39, 178, 108, 758, 159],\n",
              " [160, 759, 2, 39, 760, 761],\n",
              " [63, 10, 156, 762, 70, 148, 258],\n",
              " [17, 176, 115, 278, 763],\n",
              " [247, 24, 764, 76, 765],\n",
              " [17, 80, 176, 318, 10, 758, 84],\n",
              " [173, 184, 10, 70, 75],\n",
              " [48, 150, 40, 766, 767],\n",
              " [768, 10, 769],\n",
              " [42, 770, 14, 771],\n",
              " [173, 356],\n",
              " [42, 278, 772],\n",
              " [773, 774, 775, 68],\n",
              " [160, 120, 14, 776],\n",
              " [14, 777, 419, 5, 93, 778],\n",
              " [42, 397, 64, 270, 247, 5, 162, 39, 343],\n",
              " [17, 191, 779, 5, 391, 14, 711],\n",
              " [458, 780, 2, 5, 781, 40, 242],\n",
              " [318, 32, 565, 5, 89, 5, 323, 37, 89, 782],\n",
              " [583, 211, 783],\n",
              " [39, 784, 2, 785, 35, 599, 23, 24, 786],\n",
              " [42, 2, 787],\n",
              " [485, 285, 10, 5, 93, 44, 788],\n",
              " [10, 197, 55, 40, 789, 87, 790, 492, 91, 211, 791],\n",
              " [238, 792],\n",
              " [42, 278, 793],\n",
              " [42, 108, 55, 1, 794],\n",
              " [17, 34, 245, 93, 795, 10, 203, 316, 567],\n",
              " [66, 295, 419, 5, 796],\n",
              " [460, 797, 115, 784],\n",
              " [66, 419, 58, 798],\n",
              " [76, 75, 482, 799, 800, 70, 293],\n",
              " [42, 270, 84, 17, 271, 228, 316],\n",
              " [42, 739, 14, 231, 473, 17, 105],\n",
              " [801, 246, 5, 802, 14, 803],\n",
              " [42, 120, 410, 5, 52],\n",
              " [23, 804, 173, 89],\n",
              " [14, 805, 806, 14, 233, 1, 246, 5, 103, 14, 807],\n",
              " [162, 10, 18, 5, 158],\n",
              " [238, 325, 63, 10, 64, 782],\n",
              " [42, 394, 39, 808, 89, 5, 293],\n",
              " [171, 172, 23, 809],\n",
              " [17, 108, 810, 6, 42, 14, 811],\n",
              " [42, 278, 513, 10, 271, 194],\n",
              " [162, 10, 176, 53, 267],\n",
              " [812, 214, 317],\n",
              " [160, 659, 162, 10, 38, 70],\n",
              " [17, 419, 5, 779, 51],\n",
              " [32, 321],\n",
              " [42, 51, 14, 813, 70, 14, 814],\n",
              " [42, 208, 40, 815, 816],\n",
              " [42, 2, 306, 817, 278, 178],\n",
              " [392, 14, 818, 5, 84],\n",
              " [42, 705, 819, 820],\n",
              " [17, 63, 216, 353, 211, 5, 42],\n",
              " [10, 753, 821, 84, 159],\n",
              " [42, 822, 5, 342, 5],\n",
              " [238, 317, 10, 176, 113, 239, 28, 133, 823],\n",
              " [102, 273, 14, 824, 825],\n",
              " [17, 18, 5, 184, 218],\n",
              " [1, 826, 247, 93, 233, 763, 5, 162, 233, 10, 38, 477, 93],\n",
              " [25, 827, 363, 42],\n",
              " [17, 828, 5, 730, 1],\n",
              " [111, 162, 10, 294, 244],\n",
              " [829, 58, 830, 2, 40, 188, 831, 5, 832, 833, 77, 834],\n",
              " [162, 10, 176, 58, 835],\n",
              " [25, 247, 233, 114, 40, 719, 233, 10, 38, 17, 289],\n",
              " [42],\n",
              " [129, 130, 274, 267, 209],\n",
              " [25, 247, 306, 24, 39, 321],\n",
              " [42, 411, 5, 696, 72, 40, 836],\n",
              " [42, 108, 837, 84, 5, 185, 279, 682],\n",
              " [42, 838, 63, 5, 162, 39, 454, 17, 839, 10],\n",
              " [2, 115, 56, 840],\n",
              " [17, 18, 5, 162, 450, 841, 35, 10],\n",
              " [317, 842],\n",
              " [17, 63, 136, 164],\n",
              " [17, 394, 578],\n",
              " [25, 216, 843, 5, 184, 10],\n",
              " [317, 91, 184],\n",
              " [197, 17, 317, 87, 10],\n",
              " [17, 18, 10, 5, 285, 42],\n",
              " [17, 419, 40, 690, 844, 845],\n",
              " [42, 319, 171, 172, 23, 736],\n",
              " [160, 2, 14, 530, 23, 115, 807],\n",
              " [17, 502, 458, 503, 504],\n",
              " [496, 105, 10, 184, 42],\n",
              " [17, 80, 38, 39, 42, 846, 70, 293, 343],\n",
              " [111, 76, 10, 847, 84, 24, 23, 115],\n",
              " [17, 86, 87, 50, 113, 162, 17],\n",
              " [2, 14, 112, 24, 7],\n",
              " [17, 38, 42, 319, 93, 848, 5, 162, 39],\n",
              " [111, 2, 58, 244, 113, 188],\n",
              " [105, 10, 176, 39, 116],\n",
              " [40, 443, 746, 849, 551, 84],\n",
              " [162, 10, 38, 25, 850],\n",
              " [76, 10, 383, 10, 80, 18, 5, 294, 68, 29, 165],\n",
              " [25, 247, 259, 5, 851, 10],\n",
              " [305, 247, 763, 5, 725, 185, 852],\n",
              " [10, 626, 63, 754, 39],\n",
              " [305, 295, 75],\n",
              " [66, 853, 47],\n",
              " [102, 319, 10, 93, 442, 5, 293],\n",
              " [460, 854, 40, 855, 23, 789],\n",
              " [115, 856, 2, 247, 244],\n",
              " [17, 80, 591, 172, 318, 129, 559, 84],\n",
              " [42, 367, 5, 38, 113],\n",
              " [17, 120, 857, 503, 53, 858],\n",
              " [17, 63, 859, 733, 244],\n",
              " [42, 860, 72, 40, 861, 39, 862, 40, 480],\n",
              " [115, 2, 450, 684],\n",
              " [42, 603, 39, 52, 479, 5, 293],\n",
              " [66, 80, 863, 42, 5, 864, 865, 302, 178, 866, 185, 206],\n",
              " [42, 867, 14, 119, 233, 178, 333, 14, 100],\n",
              " [17, 289, 204],\n",
              " [105, 195, 210, 84],\n",
              " [48, 868, 458, 869, 870, 178, 871],\n",
              " [53, 651, 2, 872],\n",
              " [42, 479, 862, 14, 100, 22],\n",
              " [320, 84, 40, 873, 23, 874, 349, 87, 42],\n",
              " [42, 120, 414, 5, 459, 52],\n",
              " [42, 2, 58, 527, 278, 178],\n",
              " [17, 191, 875, 39, 1, 120, 29, 876],\n",
              " [42, 360, 285, 526, 877],\n",
              " [460, 162, 10, 310, 5, 19, 878, 87],\n",
              " [63, 10, 157, 29, 879, 880, 305, 72, 14, 881],\n",
              " [42, 278, 882, 5, 641, 52, 35, 459],\n",
              " [10, 416, 39, 165, 80, 10],\n",
              " [10, 85, 883, 131, 5, 89],\n",
              " [48, 270, 50, 5, 185, 884],\n",
              " [37, 216, 46, 20, 23, 153, 154, 831],\n",
              " [17, 38, 17, 105, 14, 7, 473],\n",
              " [178, 197, 122, 14, 885],\n",
              " [322, 247, 886],\n",
              " [171, 887],\n",
              " [17, 80, 176, 160, 5, 162, 87, 115],\n",
              " [42, 271, 888, 620],\n",
              " [57, 42, 355, 51, 316],\n",
              " [57, 39, 35],\n",
              " [162, 10, 18, 84, 5, 825, 14, 889],\n",
              " [23, 804, 66, 403, 10],\n",
              " [42, 91, 52, 63, 551, 84, 40, 625],\n",
              " [17, 265, 20, 496, 48, 120],\n",
              " [66, 63, 361, 890],\n",
              " [111, 80, 10, 89, 90, 5, 480],\n",
              " [10, 197, 317, 87, 131],\n",
              " [891, 226],\n",
              " [14, 892, 360, 893, 239, 70, 894],\n",
              " [238, 105, 10, 668, 14, 682],\n",
              " [66, 895, 44, 586, 363, 120, 183],\n",
              " [17, 821, 42, 160, 185, 896, 35, 355, 39, 322],\n",
              " [17, 120, 897, 496, 10, 479],\n",
              " [178, 163, 144],\n",
              " [10, 826, 730, 29, 898, 318, 10, 18, 5],\n",
              " [17, 108, 176, 178, 150, 40, 899, 900],\n",
              " [42, 91, 52, 322, 70, 14, 231, 901, 33, 716],\n",
              " [42, 91, 52, 76, 355, 274, 206],\n",
              " [317, 91, 184, 84, 8, 168, 5, 168],\n",
              " [66, 902, 35, 903],\n",
              " [17, 80, 63, 233, 239, 586, 233, 10, 38],\n",
              " [42, 551, 40, 221],\n",
              " [319, 10, 904, 84],\n",
              " [17, 270, 10, 5, 392, 84, 349],\n",
              " [245, 162, 1],\n",
              " [185, 905, 906, 907, 50, 5, 696],\n",
              " [17, 479, 20, 87, 29, 440],\n",
              " [42, 108, 908, 5, 176, 111, 52, 105, 39],\n",
              " [17, 85, 459, 10, 909, 17, 289, 65],\n",
              " [66, 63, 5, 651, 782],\n",
              " [14, 33, 473, 66, 419, 2, 40, 634],\n",
              " [184, 10, 230, 68, 14, 910],\n",
              " [281, 14, 911],\n",
              " [160, 161, 55, 10, 378, 39],\n",
              " [42, 2, 216, 912, 913],\n",
              " [160, 258, 76, 10, 8],\n",
              " [178, 914, 645, 70, 458],\n",
              " [66, 419, 5, 55, 488, 495],\n",
              " [460, 2, 14, 182, 70, 915],\n",
              " [17, 176, 496, 10, 76],\n",
              " [14, 312, 2, 26, 533],\n",
              " [10, 449, 29, 916],\n",
              " [17, 917, 918],\n",
              " [76, 10, 295, 919],\n",
              " [17, 80, 18, 5, 89, 5, 702, 107],\n",
              " [162, 10, 63, 225, 920],\n",
              " [42, 2],\n",
              " [129, 322, 921],\n",
              " [76, 10, 295, 349],\n",
              " [48, 120, 922, 40, 690, 923],\n",
              " [24, 17, 18, 35, 557, 2, 40, 684, 924],\n",
              " [105, 10, 668, 14, 721],\n",
              " [2, 39, 40],\n",
              " [178, 191, 93, 925, 5, 926, 285, 39],\n",
              " [42, 14, 927],\n",
              " [42, 197, 122, 143, 26, 245],\n",
              " [17, 120, 928],\n",
              " [42, 479, 35, 40, 435, 33, 743],\n",
              " [42, 108, 55, 159],\n",
              " [17, 85, 281, 622, 5, 42],\n",
              " [573, 14, 711],\n",
              " [25, 247, 929, 28, 39],\n",
              " [930, 40, 931, 932, 2, 933, 1, 2, 4, 5, 404, 934, 23, 1],\n",
              " [178, 2, 177, 5, 935, 70, 211, 936],\n",
              " [42, 603, 25, 316],\n",
              " [48, 937, 29, 938],\n",
              " [42, 319, 404, 405, 70, 633],\n",
              " [10, 191, 553, 205, 39],\n",
              " [17, 38, 583, 40, 939],\n",
              " [10, 262, 285, 213, 216, 940, 58, 653, 746],\n",
              " [17, 80, 176, 434, 305, 259, 5, 651],\n",
              " [17, 80, 18, 5, 217, 5, 42],\n",
              " [10, 941, 18, 5, 942, 47],\n",
              " [42, 91, 52, 76, 26, 321, 440],\n",
              " [14, 943, 120, 699],\n",
              " [42, 944, 316, 136, 693, 69, 945, 40, 946],\n",
              " [32, 947, 29, 900],\n",
              " [197, 17, 63, 115, 948],\n",
              " [17, 949, 14, 122, 8, 950, 5, 951],\n",
              " [14, 685, 952, 7],\n",
              " [115, 2, 40, 188, 953],\n",
              " [150, 17, 713, 954, 17, 627, 63, 157],\n",
              " [42, 955, 52, 956],\n",
              " [42, 85, 122, 143],\n",
              " [42, 2, 147, 23, 957],\n",
              " [32, 247, 155, 510],\n",
              " [17, 411, 5, 356, 40, 958],\n",
              " [115, 110, 2, 590, 496, 2, 959],\n",
              " [105, 10, 63, 81, 960],\n",
              " [17, 108, 162, 29, 206],\n",
              " [17, 80, 961],\n",
              " [66, 63, 5, 89],\n",
              " [42, 914, 5, 93, 962, 450, 5, 338],\n",
              " [42, 67, 963],\n",
              " [238, 482, 964, 105, 10, 19, 107],\n",
              " [25, 247, 542, 35, 40, 965],\n",
              " [17, 966, 10, 40, 967],\n",
              " [75, 120, 40, 968, 969, 70, 970, 33, 716],\n",
              " [58, 971, 2, 40, 972],\n",
              " [115, 347, 163, 348, 699],\n",
              " [17, 80, 38, 173, 156, 725],\n",
              " [42, 973, 52, 5, 122, 185, 885],\n",
              " [14, 974, 76, 794],\n",
              " [17, 413, 162, 39, 709],\n",
              " [42, 975, 29, 976],\n",
              " [42, 163, 977],\n",
              " [17, 288, 10, 314],\n",
              " [76, 10, 144, 65, 7, 661],\n",
              " [1, 2, 295, 40, 221, 978],\n",
              " [42, 108, 6, 84, 5, 162, 39],\n",
              " [979, 260, 14, 980],\n",
              " [17, 85, 758, 458, 981, 361, 982, 238, 239, 17, 453],\n",
              " [29, 277, 2, 580, 363, 10],\n",
              " [319, 10, 320, 84, 40, 74],\n",
              " [52, 747, 164, 70, 458, 684, 983],\n",
              " [17, 38, 1, 227, 42],\n",
              " [57, 58, 984, 530],\n",
              " [25, 247, 772],\n",
              " [25, 247, 259, 5, 641, 218, 5, 392],\n",
              " [238, 105, 129, 317, 316],\n",
              " [162, 10, 176, 160, 17, 985],\n",
              " [32],\n",
              " [42, 108, 908, 5, 93, 113, 65],\n",
              " [48, 464, 84],\n",
              " [173, 453, 5, 404, 51, 481, 230],\n",
              " [111, 2, 14, 335, 594],\n",
              " [42, 986, 710],\n",
              " [17, 987, 274, 988, 91, 989, 87, 218],\n",
              " [17, 108, 38, 990, 93, 645, 70, 355, 39],\n",
              " [17, 38, 42, 91, 52, 285, 153, 73],\n",
              " [627, 10, 991, 14, 992, 40, 221],\n",
              " [25, 247, 233, 993, 233, 10, 38, 17, 289],\n",
              " [115, 2, 211, 994],\n",
              " [14, 995, 996],\n",
              " [17, 734, 244, 26, 245],\n",
              " [17, 85, 997, 755],\n",
              " [42, 120, 998, 503, 14, 312],\n",
              " [14, 999, 42, 1000],\n",
              " [66, 419, 5, 281, 612],\n",
              " [468, 23, 1001, 282, 2, 959],\n",
              " [25, 843, 5, 184, 10],\n",
              " [170, 84, 523, 21],\n",
              " [17, 18, 5, 93, 44, 1002],\n",
              " [10, 941, 1003, 42],\n",
              " [1004, 144, 572, 61, 363, 84],\n",
              " [17, 453],\n",
              " [17, 176, 39, 305, 261],\n",
              " [5, 93, 1005, 17, 80, 285, 10, 68, 24],\n",
              " [1006, 14, 412, 72, 14, 1007],\n",
              " [76, 129, 1008],\n",
              " [66, 322, 27, 450, 150, 420],\n",
              " [178, 120, 1009, 937, 503, 14, 351],\n",
              " [17, 680, 89, 5, 480, 428, 1010],\n",
              " [863, 84, 5, 176, 70, 1011, 102, 10, 76, 442, 51, 5, 1012],\n",
              " [25, 216, 40, 221, 1013],\n",
              " [262, 68, 115, 1014],\n",
              " [17, 108, 6, 42, 111, 178, 150, 5, 651, 594],\n",
              " [57, 58, 1015, 1016],\n",
              " [458, 1017, 2, 149, 1018],\n",
              " [17, 120, 1019],\n",
              " [162, 10, 63, 40, 264],\n",
              " [322, 247, 259, 5, 162, 1],\n",
              " [42, 438, 14, 1020],\n",
              " [1021, 2, 211, 23, 1012],\n",
              " [583, 26, 1022],\n",
              " [42, 319, 345, 77, 73, 831, 5, 162, 39],\n",
              " [42, 278, 26, 245],\n",
              " [42, 1023, 5, 1024, 29, 112, 222, 17, 120, 20, 23, 560],\n",
              " [171, 1],\n",
              " [42, 826, 317, 316],\n",
              " [1004, 67, 40, 1025],\n",
              " [826, 17, 184, 29, 1026, 661],\n",
              " [313, 40, 1027, 1028, 29, 165],\n",
              " [42, 1029, 14, 1030],\n",
              " [322, 10, 70, 1031, 33, 946],\n",
              " [281, 211, 1032, 72, 29, 1033, 35, 40, 222],\n",
              " [42, 705, 33, 716],\n",
              " [25, 1034, 211, 1035],\n",
              " [42, 278, 26, 1036],\n",
              " [75, 826, 93, 148, 831, 5, 162, 115],\n",
              " [28, 238, 482, 545, 162, 10, 369, 339, 743],\n",
              " [10, 191, 59, 1037],\n",
              " [42, 470, 178, 1038, 14, 1039, 473],\n",
              " [238, 1040],\n",
              " [17, 344, 42, 120, 40, 385],\n",
              " [245, 727],\n",
              " [14, 1041, 319, 567, 794],\n",
              " [216, 6, 84, 32, 1042],\n",
              " [42, 160, 162, 10, 38],\n",
              " [76, 10, 383, 32, 247, 652],\n",
              " [768, 10, 259, 5, 162],\n",
              " [17, 675, 5, 1043, 77, 586, 113, 17, 292, 224, 168, 136, 137, 40, 220],\n",
              " [322, 10, 542, 68, 50],\n",
              " [558, 1044, 410, 68, 930],\n",
              " [129, 1045, 1046],\n",
              " [74, 84, 14, 1047],\n",
              " [25, 383, 39, 241, 575, 319, 1048],\n",
              " [627, 10, 6, 84, 460, 105, 115],\n",
              " [42, 1049, 5, 1050, 203, 5, 184, 160, 1051],\n",
              " [17, 1052, 39, 42, 603, 115, 508],\n",
              " [305, 1053, 40, 1054],\n",
              " [115, 421, 23, 651, 494, 84, 662],\n",
              " [485, 285, 5, 696, 70, 484, 1055],\n",
              " [496, 76, 10, 1056],\n",
              " [10, 197, 194, 50],\n",
              " [115, 2, 29, 1057],\n",
              " [162, 10, 18, 44, 760],\n",
              " [105, 1058, 404, 1059],\n",
              " [111, 2, 42, 922, 40, 530, 1060],\n",
              " [42, 360, 285, 505, 143, 87, 52],\n",
              " [48, 1061, 1062, 862, 14, 1063, 72, 14, 881],\n",
              " [42, 757, 172, 23, 131],\n",
              " [17, 108, 1064, 10, 322, 645, 70, 1],\n",
              " [262, 1065, 1066],\n",
              " [42, 120, 87, 84, 24, 1067],\n",
              " [42, 319, 93, 1068, 503, 14, 168, 66, 404, 75],\n",
              " [42, 1069, 14, 1070],\n",
              " [115, 251, 660, 2, 26, 671],\n",
              " [14, 760, 70, 14, 1071, 2],\n",
              " [42, 306, 360, 908, 645],\n",
              " [138, 93, 1072, 318, 10, 1073, 14, 943],\n",
              " [138, 419, 147],\n",
              " [273, 178, 294, 186, 339, 1067],\n",
              " [17, 416, 244, 1074],\n",
              " [37, 392, 481],\n",
              " [238, 1075, 162, 10, 19, 1076],\n",
              " [66, 63, 5, 63, 115],\n",
              " [42, 2, 125, 40, 784],\n",
              " [42, 854, 5, 132, 238, 5, 356, 40, 1077],\n",
              " [17, 18, 5, 93, 285, 1078],\n",
              " [17, 419, 40, 1079],\n",
              " [171, 115, 1080, 91, 138, 1081, 40, 625, 488],\n",
              " [178, 270, 84, 5, 93, 421, 5, 154],\n",
              " [173, 142, 736],\n",
              " [29, 1082, 120, 40, 1083],\n",
              " [319, 1084, 567],\n",
              " [1004, 963],\n",
              " [42, 197, 979, 91, 997],\n",
              " [460, 902],\n",
              " [115, 2, 40, 164, 1085],\n",
              " [17, 85, 320, 10, 39, 45],\n",
              " [25, 247, 427, 755],\n",
              " [11, 10, 1086],\n",
              " [10, 63, 736, 10, 419, 661],\n",
              " [322, 70, 1087],\n",
              " [115, 85, 93, 443],\n",
              " [17, 67, 40, 221, 652],\n",
              " [66, 63, 5, 651, 1088],\n",
              " [42, 360, 38, 388, 244, 1089, 2, 26, 188],\n",
              " [17, 176, 39, 178, 120, 65],\n",
              " [42, 2, 26, 1036, 278, 178],\n",
              " [17, 762, 1090, 35, 1010, 572],\n",
              " [42, 675, 5, 444, 8, 10],\n",
              " [42, 278, 65, 107],\n",
              " [17, 80, 18, 5, 466, 10],\n",
              " [17, 306, 285, 726, 225],\n",
              " [583, 50],\n",
              " [583, 1091],\n",
              " [42, 394, 178, 854, 5, 1092],\n",
              " [160, 992, 105, 10, 63, 5, 523, 35, 39],\n",
              " [42, 553, 1093, 28, 39],\n",
              " [17, 1094, 5, 294, 70, 293],\n",
              " [485, 488, 184, 57, 259, 72],\n",
              " [460, 739, 39],\n",
              " [14, 1095, 2, 295, 1096],\n",
              " [53, 684, 1026, 2, 26, 1097],\n",
              " [305, 1098, 278, 1],\n",
              " [197, 10, 6, 14, 1099, 1100, 1001, 144, 437],\n",
              " [42, 479, 47, 14, 807, 70, 40],\n",
              " [115, 1101, 497, 5, 29, 425],\n",
              " [185, 1102, 705, 69, 572, 636],\n",
              " [17, 63, 1103, 1104],\n",
              " [42, 1105, 383, 238, 5, 1106],\n",
              " [779, 51, 91, 1107, 84, 450, 5, 961],\n",
              " [42, 1108],\n",
              " [105, 10, 508, 176, 39],\n",
              " [160, 273, 42, 18, 5, 217, 5, 52, 28],\n",
              " [48, 2, 9],\n",
              " [48, 774, 141, 458, 1102],\n",
              " [42, 413, 758, 185, 1109],\n",
              " [313, 450, 17, 18, 5, 320, 10],\n",
              " [24, 14, 1110, 322, 70, 14, 493, 100],\n",
              " [102, 2, 115, 1111, 156, 259, 5, 637],\n",
              " [42, 120, 177, 23, 10],\n",
              " [558, 1112],\n",
              " [17, 828, 5, 392, 481],\n",
              " [17, 1113, 10, 76, 410, 28, 42],\n",
              " [17, 285, 14, 831, 42, 1114],\n",
              " [25, 14, 384, 147, 460, 1115, 42],\n",
              " [52, 470, 812, 1116, 14, 251, 983],\n",
              " [42, 397, 407, 755],\n",
              " [406, 6, 84, 238, 5, 162, 115],\n",
              " [17, 176, 10, 63, 1, 87, 10],\n",
              " [129, 1117],\n",
              " [17, 63, 5, 404, 115, 119, 1118],\n",
              " [29, 1119, 871, 5, 651, 503, 517],\n",
              " [42, 821, 52, 496, 458, 1102, 120],\n",
              " [245, 641, 42],\n",
              " [42, 360, 63, 5, 6, 84, 160, 5, 162],\n",
              " [13, 29, 422],\n",
              " [57, 14, 250, 23, 53, 564],\n",
              " [147, 23, 14, 145, 120, 1120],\n",
              " [42, 411, 321, 1121, 5, 1122, 14, 1123],\n",
              " [42, 1124, 29, 1125],\n",
              " [17, 319, 553, 381, 70, 416, 454],\n",
              " [185, 1082, 2, 379, 23, 50],\n",
              " [42, 2, 70, 14, 1126, 100, 87, 52],\n",
              " [24, 23, 14, 789, 2, 1068],\n",
              " [42, 85, 162, 1],\n",
              " [42, 838, 1127, 446, 39, 1128, 21],\n",
              " [17, 413, 345, 1],\n",
              " [406, 573, 622],\n",
              " [80, 10, 18, 147, 23, 1001],\n",
              " [178, 1129, 233, 241, 1130],\n",
              " [318, 29, 165, 322, 40, 1131, 17, 161, 837, 801, 17, 176, 5, 29, 279, 682],\n",
              " [25, 247, 233, 555, 233, 10, 38, 17, 289],\n",
              " [10, 63, 5, 1132],\n",
              " [1004, 1096],\n",
              " [558, 1133],\n",
              " [477, 93, 40, 1134, 1067],\n",
              " [147, 1135, 572, 2, 407, 40, 1136],\n",
              " [322, 14, 231, 835],\n",
              " [14, 473, 25, 565, 5, 162, 2, 294, 244],\n",
              " [17, 80, 63, 482, 1137, 5, 162, 39],\n",
              " [17, 63, 361, 586, 107],\n",
              " [14, 62, 1138, 185, 1139, 5, 14],\n",
              " [42, 319, 453, 5, 573, 10],\n",
              " [25, 247, 26, 1140],\n",
              " [173, 390, 758, 39],\n",
              " [48, 1141, 14, 789, 1100, 14, 144],\n",
              " [17, 18, 10, 5, 281, 51, 87, 84],\n",
              " [17, 63, 1142],\n",
              " [339, 1143, 1144, 561],\n",
              " [17, 80, 176, 709],\n",
              " [317, 380, 131, 567],\n",
              " [42, 150, 482, 440],\n",
              " [14, 663, 1145, 1146],\n",
              " [42, 1044, 5, 404, 1147],\n",
              " [17, 426, 111, 42, 108, 162, 39, 14, 831, 17, 821, 50, 5],\n",
              " [42, 163, 482, 188],\n",
              " [17, 63, 5, 93, 304, 21, 428, 1, 303, 1148],\n",
              " [42, 603, 238, 5, 741, 1149],\n",
              " [42, 2, 14, 653, 244, 242, 17, 176],\n",
              " [185, 530, 2, 72, 14, 1150, 23, 29, 1151],\n",
              " [25, 42, 91, 115, 2, 52],\n",
              " [17, 416, 125, 501],\n",
              " [111, 76, 10, 1152, 84],\n",
              " [17, 949, 14, 1153, 696],\n",
              " [339, 702, 1154, 163, 1155, 1156, 68, 147, 168, 693, 148],\n",
              " [42, 2, 14, 653, 1157, 649, 156, 150],\n",
              " [17, 34, 42, 360, 404, 1158, 1159],\n",
              " [1001, 76, 684],\n",
              " [178, 120, 40, 188, 499],\n",
              " [178, 161, 93, 547, 5, 444, 39],\n",
              " [42, 57, 1160],\n",
              " [48, 120, 922, 40, 1161, 1162],\n",
              " [25, 259, 5, 228, 302],\n",
              " [2, 1, 4, 5, 132, 244],\n",
              " [111, 80, 10, 979, 40, 110],\n",
              " [76, 10, 40, 1163, 361, 111, 162, 10, 641],\n",
              " [17, 285, 42, 1164, 1004, 1165],\n",
              " [14, 23, 76, 26, 671],\n",
              " [52, 278, 405, 5, 42, 2, 48],\n",
              " [37, 404, 1, 1166, 87],\n",
              " [111, 753, 10, 407],\n",
              " [17, 559, 771],\n",
              " [17, 80, 345, 39, 1167],\n",
              " [88, 64, 1168],\n",
              " [17, 319, 228],\n",
              " [160, 224, 23, 293, 273, 42, 696, 70],\n",
              " [66, 80, 176, 496, 42, 2, 1164, 66, 419, 5, 345, 50, 233, 567, 233, 66, 197],\n",
              " [173, 55, 383, 42, 1169, 5, 10],\n",
              " [14, 1170, 23, 14, 881, 120, 766],\n",
              " [17, 43, 14, 586],\n",
              " [318, 42, 161, 19, 1171, 808, 93, 1172],\n",
              " [42, 757, 52, 5, 14, 1173],\n",
              " [178, 1174, 90, 144, 137, 636],\n",
              " [10, 826, 46],\n",
              " [1175, 583, 160, 485, 162],\n",
              " [25, 247, 65, 68, 24],\n",
              " [25, 1176, 14, 634],\n",
              " [14, 384, 147, 316, 460, 197, 214, 89, 87, 131, 2, 42],\n",
              " [80, 1177, 51],\n",
              " [42, 675, 558, 5, 392],\n",
              " [25, 40, 625, 285, 42],\n",
              " [42, 163, 508, 1178, 1004, 247, 259, 5, 109, 147],\n",
              " [17, 80, 63, 159, 5, 320, 10],\n",
              " [178, 2, 1179],\n",
              " [80, 205, 66, 63, 5, 162, 241, 206],\n",
              " [496, 42, 105, 39, 2, 1180],\n",
              " [17, 38, 10, 271, 734, 40, 855, 44, 1181],\n",
              " [115, 278, 1182],\n",
              " [1183, 14, 147, 17, 522],\n",
              " [178, 120, 1184, 5, 223],\n",
              " [17, 979, 14, 110],\n",
              " [392, 14, 1185, 233, 129, 76],\n",
              " [42, 394, 39, 808, 93, 90, 72, 633],\n",
              " [17, 38, 25, 259, 5, 93, 316, 72, 1186],\n",
              " [42, 1187, 775, 14, 1188],\n",
              " [89, 1189, 513, 315],\n",
              " [66, 76, 70, 14, 1190, 23, 1191, 1192],\n",
              " [48, 1044, 1010, 874, 546],\n",
              " [42, 394, 52, 2, 1147],\n",
              " [17, 67, 405, 572, 546],\n",
              " [17, 1174, 5, 1193, 35, 160, 420, 209],\n",
              " [63, 10, 966, 84, 160, 10, 394, 10, 161],\n",
              " [468, 1032, 2, 1194, 10],\n",
              " [160, 420, 313, 1195, 24, 1166, 14, 1196],\n",
              " [42, 120, 27, 28, 39],\n",
              " [42, 2, 177, 23, 282],\n",
              " [17, 80, 18, 10, 5, 38, 25, 1197],\n",
              " [42, 197, 1198, 122, 1198, 1199, 91, 143, 187, 245],\n",
              " [170, 84, 997, 39, 47],\n",
              " [42, 1200, 620, 70, 14, 1201],\n",
              " [178, 306, 822, 366, 40, 625],\n",
              " [105, 10, 55, 1062],\n",
              " [185, 165, 120, 330, 862, 33, 743],\n",
              " [313, 361, 419, 5, 1193],\n",
              " [17, 120, 40, 221, 843],\n",
              " [25, 247, 662],\n",
              " [14, 322, 7],\n",
              " [160, 105, 10, 38, 42, 161, 162],\n",
              " [17, 38, 129, 162, 39, 72, 1016],\n",
              " [278, 14, 1202, 1203],\n",
              " [42, 246, 5, 1204, 620, 33, 220],\n",
              " [63, 129, 1205],\n",
              " [482, 1206, 1207, 677, 274, 564, 909, 23, 1208],\n",
              " [17, 80, 18, 5, 93, 349, 87, 42],\n",
              " [80, 170, 599, 171, 1209, 23, 10],\n",
              " [14, 1210, 14, 599],\n",
              " [2, 1, 443, 39, 32, 1211, 5, 323],\n",
              " [2, 115, 1162, 959],\n",
              " [29, 469, 2, 65],\n",
              " [25, 756, 23, 1212],\n",
              " [76, 10, 27],\n",
              " [102, 162, 10, 1213],\n",
              " [115, 702, 120, 1214, 70],\n",
              " [17, 108, 176, 10, 413, 446],\n",
              " [178, 436, 458, 14, 831],\n",
              " [42, 1215, 1028, 185, 165],\n",
              " [1004, 321, 91, 925],\n",
              " [17, 176, 39, 32, 40, 242],\n",
              " [17, 38, 42, 161, 285, 39],\n",
              " [63, 10, 156, 344, 28, 355, 39],\n",
              " [29, 550, 838, 342, 5, 84],\n",
              " [162, 10, 18, 5, 217, 28, 160, 420],\n",
              " [1216, 2, 40, 1217, 258],\n",
              " [138, 162, 1],\n",
              " [115, 147, 2, 1218],\n",
              " [162, 10, 176, 39],\n",
              " [46, 956, 8, 131],\n",
              " [42, 1219, 1220],\n",
              " [42, 270, 84, 14, 1221, 120],\n",
              " [25, 26, 1222],\n",
              " [129, 150, 40, 188, 1223, 5, 93, 336, 28, 1],\n",
              " [17, 396, 50, 70, 14, 1224],\n",
              " [42, 2, 1225, 40],\n",
              " [238, 482, 704, 162, 10, 63],\n",
              " [10, 271, 132, 1226],\n",
              " [25, 694, 116],\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGLbuqDwYAtA",
        "colab_type": "text"
      },
      "source": [
        "Para evitar que una palabra poco frecuente, que no posea una etiqueta se aparezca, la solución que se nos ocurre es \"limpiar\" nuestro dataset al momento de rear el vocabulario, eliminando los input (palabras ofrases) que contienen palabras con una ocurrencia menor al número elegido para construir el vocabulario, en este caso, 3. Así, todas las oraciones disponibles en el dataset no contendrían palabras ignoradas.   \n",
        "\n",
        "Para lo que sigue, no se realizará la estrategia propuesta debido al costo computacional que requiere (recorrer secuencialmente el dataset que es de gran longitud varias veces)  y los buenos resultados obtenidos a continuación.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h48WyFNbcUAW"
      },
      "source": [
        "###  d) Debido al largo variable de los textos de entrada y salida será necesario estandarizar ésto para poder trabajar de manera más cómoda en Keras, *cada texto (entrada y salida) pueden tener distinto largo máximo*. Comente sobre la decisión del tipo de *padding*, *pre o post* ¿Qué sucede al variar el largo máximo de instantes de tiempo para procesar en cada parte del modelo (entrada y salida)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cnegBHnPcWtf",
        "outputId": "1b52d5bb-20ea-417c-af02-ef629463840f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\"\"\" INPUT DATA (Origin language) \"\"\"\n",
        "max_inp_length = max(map(len,dataX_train))\n",
        "print(\"Largo max inp: \",max_inp_length)\n",
        "word2idx_s[\"*\"] = 0 #padding symbol\n",
        "idx2word_s[0] = \"*\"\n",
        "n_words_s += 1  \n",
        "X_train = sequence.pad_sequences(dataX_train, maxlen=max_inp_length, padding='pre', value=word2idx_s[\"*\"])\n",
        "X_val = sequence.pad_sequences(dataX_valid, maxlen=max_inp_length, padding='pre', value=word2idx_s[\"*\"])\n",
        "X_test = sequence.pad_sequences(dataX_test, maxlen=max_inp_length, padding='pre', value=word2idx_s[\"*\"])\n",
        "\n",
        "\n",
        "\"\"\" OUTPUT DATA (Destination language) \"\"\"\n",
        "max_out_length = max(map(len,dataY_train)) \n",
        "print(\"Largo max out: \",max_out_length)\n",
        "word2idx_t[\"*\"] = 0 #padding symbol\n",
        "idx2word_t[0] = \"*\"\n",
        "n_words_t += 1  \n",
        "Y_train = sequence.pad_sequences(dataY_train, maxlen=max_out_length, padding='post', value=word2idx_t[\"*\"])\n",
        "Y_val = sequence.pad_sequences(dataY_valid, maxlen=max_out_length, padding='post', value=word2idx_t[\"*\"])\n",
        "Y_test = sequence.pad_sequences(dataY_test, maxlen=max_out_length, padding='post', value=word2idx_t[\"*\"])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Largo max inp:  35\n",
            "Largo max out:  34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4751PUqtYAtX",
        "colab_type": "code",
        "outputId": "a740a0a8-3279-421a-8262-206a27b1f89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    7,    8,    9],\n",
              "       [   0,    0,    0, ...,   10,   11,   12],\n",
              "       [   0,    0,    0, ...,   14,   15,   16],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,  351,   35,   10],\n",
              "       [   0,    0,    0, ...,   89,  245,   89],\n",
              "       [   0,    0,    0, ...,  285, 1058,  315]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OJf__Ga-7J2",
        "colab_type": "code",
        "outputId": "5eea9b4a-b91e-49b2-c809-3e90de9d6149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "Y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,    2,    3, ...,    0,    0,    0],\n",
              "       [  11,   12,   13, ...,    0,    0,    0],\n",
              "       [  15,    3,   16, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 335,   13,   55, ...,    0,    0,    0],\n",
              "       [ 150,   11, 1012, ...,    0,    0,    0],\n",
              "       [  76,  223,  701, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX7E31SJYAtc",
        "colab_type": "text"
      },
      "source": [
        "El tipo de Padding realizado es de \"pre\" en el conjunto de input y \"post\"  en el conjunto de output, esta decisión se debe a la estuctura de la red neuronal con la que se trabajará. Como se trabajará con Encoder-Decoder,  es recomendable que las paabras \"útiles\" (las que no son 0 en el) estén juntas, lo que se logra con el padding anterioremente de descrito.\n",
        "\n",
        "El largo máximo de instantes de tiempo para procesar debe ser fijo, ya que si fuese variable fallarán las conexiones entre las capas al procesar la red neuronal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S2lHnQ2YcaEc"
      },
      "source": [
        "###  e) Para evitar que la red obtenga una ganancia por imitar/predecir el símbolo de *padding* que está bastante presente en los datos coloque un peso sobre éste clase, con valor 0, así se evita que tenga impacto en la función objetivo. Ya que *keras* no soporta directamente ésto en series de tiempo coloque el peso a cada instante de tiempo de cada dato de entrenamiento dependiendo de su clase. Comente sobre alguna otra forma en que se podría manejar el evitar que la red prediga en mayoría el símbolo de *padding*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mffwCzB7ccgw",
        "colab": {}
      },
      "source": [
        "c_weights = np.ones(n_words_t)\n",
        "c_weights[0] = 0 #padding class masked\n",
        "sample_weight = np.zeros(Y_train.shape)\n",
        "for i in range(sample_weight.shape[0]):\n",
        "    sample_weight[i] = c_weights[Y_train[i,:]]\n",
        "#Crea la matriz de pesos asociada a Y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhV1qxFcLgjd",
        "colab_type": "text"
      },
      "source": [
        "A continuación se ve un ejemplo donde, efectivamente, el peso del símbolo de padding es 0 y el de las demás palabras codificadas es 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh3UmhmKYAti",
        "colab_type": "code",
        "outputId": "c39b77f5-ab43-4d96-bb33-d0d9d53c492b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "Y_train[9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([50,  6, 51, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3_vhkUGGcegk",
        "outputId": "b1790b22-b4e7-4741-a0fa-bc97b30ea875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sample_weight[9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6sDjCBwOaOP",
        "colab_type": "text"
      },
      "source": [
        "Otra forma en que se nos ocurre que se podria evitar la predicción del símbolo de padding por parte de la red podria ser considerar una función de pérdida que este construida para \"evitar\" de cierta forma que los símbolos codificados con 0 (que corresponden al padding) mejoren el entrenamiento. Esta función podría construirse a mano y el resultado debiese ser similar a la estrategia de los pesos que se propone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_zWv9hrtcemN"
      },
      "source": [
        "### f) Para lograr la tarea defina una red recurrente del tipo *encoder*-*decoder* como la que se presenta en la siguiente imágen. <img src=\"https://chunml.github.io/ChunML.github.io/images/projects/sequence-to-sequence/repeated_vector.png\" width=\"60%\" />\n",
        "###En primer lugar defina el *Encoder* que procesara el texto de entrada y retornará un solo vector final, haciendo uso de las capas ya conocidas de *Embedding* para generar un vector denso de palabra y *GRU*, pero en su versión acelerada para GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BGYi9MzAcm4q"
      },
      "source": [
        "### Luego defina la sección que conecta el largo (*timesteps*) de entrada *vs* el de salida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AGsvPosNctNe"
      },
      "source": [
        "### Finalmente defina el *Decoder* para generar la secuencia de salida en texto de palabras en otro idioma, a través de la función *softmax* sobre cada instante de tiempo (*timestep*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6DjPc-Rdc6Vu"
      },
      "source": [
        "### Entrene la red entre 1 a 5 *epochs*, agregando los pesos definidos sobre cada ejemplo de entrenamiento. Además de utilizar una función de pérdida que evita generar explícitamente los *one hot vector*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DMhfe3BQvi3",
        "colab_type": "text"
      },
      "source": [
        "Se define el Encoder formado por una capa de Embedding y dos capas de GRU (Gated Recurrent Unit), la sección que conecta el Encoder con el Decoder ser forma por una capa de RepeatVector, que repite el input de dicha capa tantas veces como el largo de salida.Luego, se define el Decoder se forma de dos capas de GRU y una capa de salida TimeDistributed  de capa Densa (se le aplica una capa densa a cada segmento temporal del input con función de activación softmax). \n",
        "\n",
        "Se considera la función de pérdida 'sparse_categorical_crossentropy', que se porta como la ya conocida 'categorical_crossentropy' pero permite trabajar con salidas que estan codificadas como números enteros y no en una representación one-hot-vector. (Efectivamente es nuestro caso, dado que cada coordenada de salida corresponde a un número entero no negativo)\n",
        "\n",
        "Finalmente, se entrena la red para 3 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDsA9i8GYAt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train=Y_train[:,:,None]\n",
        "Y_val=Y_val[:,:,None]\n",
        "Y_test=Y_test[:,:,None]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLo70OMHYAuB",
        "colab_type": "code",
        "outputId": "aee47121-643b-477d-d0ba-edb908bd9c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "\n",
        "EMBEDDING_DIM = 100\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=n_words_s, output_dim=EMBEDDING_DIM, input_length=max_inp_length))\n",
        "model.add(CuDNNGRU(64, return_sequences=True))\n",
        "model.add(CuDNNGRU(128, return_sequences=False))\n",
        "model.add(RepeatVector(max_out_length))\n",
        "model.add(CuDNNGRU(128, return_sequences=True))\n",
        "model.add(CuDNNGRU(64, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(n_words_t,activation='softmax')))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', sample_weight_mode='temporal')\n",
        "model.fit(X_train, Y_train, epochs=3, batch_size=256, validation_data=(X_val, Y_val), sample_weight = sample_weight) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0804 15:09:33.448425 140589869713280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0804 15:09:33.474615 140589869713280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0804 15:09:33.477839 140589869713280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0804 15:09:35.037471 140589869713280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0804 15:09:35.062474 140589869713280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0804 15:09:35.155846 140589869713280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 35, 100)           616200    \n",
            "_________________________________________________________________\n",
            "cu_dnngru_1 (CuDNNGRU)       (None, 35, 64)            31872     \n",
            "_________________________________________________________________\n",
            "cu_dnngru_2 (CuDNNGRU)       (None, 128)               74496     \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 34, 128)           0         \n",
            "_________________________________________________________________\n",
            "cu_dnngru_3 (CuDNNGRU)       (None, 34, 128)           99072     \n",
            "_________________________________________________________________\n",
            "cu_dnngru_4 (CuDNNGRU)       (None, 34, 64)            37248     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 34, 9107)          591955    \n",
            "=================================================================\n",
            "Total params: 1,450,843\n",
            "Trainable params: 1,450,843\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0804 15:09:35.654662 140589869713280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 125693 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "125693/125693 [==============================] - 55s 439us/step - loss: 5.9784 - val_loss: 12.5771\n",
            "Epoch 2/3\n",
            "125693/125693 [==============================] - 50s 395us/step - loss: 5.7710 - val_loss: 13.4363\n",
            "Epoch 3/3\n",
            "125693/125693 [==============================] - 49s 392us/step - loss: 5.7187 - val_loss: 13.9702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdd38566e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2xb6faGXfqI",
        "colab_type": "text"
      },
      "source": [
        "Se observa una disminución de la función de pérdida durante el paso de las epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VHnjIjO_c-dz"
      },
      "source": [
        "### g) Debido a lo costoso de tener una red completamente recurrente para entrenar y poder experimentar, cambie el modelo que procesa el *Encoder* por una red convolucional, reduciendo el número de capas pero aumentando las neuronas. Utilice tamaños de *kernel*  igual a 5 y funciones de activaciones relu. Se agregan capas de *BatchNormalization* debido a que en el *Decoder* contamos con redes recurrentes que tienen capa activación distinta a la usada por las convoluciones. La capa de *GlobalMaxPooling1d* es lo que permite reducir toda la información extraída a un único vector, como se realizó anteriormente con *return_sequences=False*, comente sobre la ganancia o desventaja de ésto *vs* la red neuronal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mHssLjsadBWA",
        "outputId": "a8d0e8f9-bd43-4e38-8a0d-c70e008bc704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Embedding(input_dim=n_words_s, output_dim=EMBEDDING_DIM, input_length=max_inp_length))\n",
        "model1.add(Conv1D(256, 5, padding='same', activation='relu', strides=1))\n",
        "model1.add(BatchNormalization()) #for stability\n",
        "model1.add(Conv1D(256, 5, padding='same', activation='relu', strides=1))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(GlobalMaxPooling1D()) #aka to return_sequences=False\n",
        "model1.add(RepeatVector(max_out_length)) #conection\n",
        "model1.add(CuDNNGRU(256, return_sequences=True))\n",
        "model1.add(TimeDistributed(Dense(n_words_t, activation='softmax')))\n",
        "model1.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 35, 100)           616200    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 35, 256)           128256    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 35, 256)           1024      \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 35, 256)           1024      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_2 (RepeatVecto (None, 34, 256)           0         \n",
            "_________________________________________________________________\n",
            "cu_dnngru_5 (CuDNNGRU)       (None, 34, 256)           394752    \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 34, 9107)          2340499   \n",
            "=================================================================\n",
            "Total params: 3,809,691\n",
            "Trainable params: 3,808,667\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "blbsX3MJdDw0"
      },
      "source": [
        "### Entrene el modelo igual a lo presentado anteriormente pero ahora por 20 *epochs* ¿Cambian los tiempos de procesamiento y la cantidad de parámetros?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zEWx5YFYdGBA",
        "colab": {}
      },
      "source": [
        "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', sample_weight_mode='temporal')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ2t8K9aYAue",
        "colab_type": "code",
        "outputId": "9dc523d2-e8cd-4686-ecf5-48de1360da84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "model1.fit(X_train, Y_train, epochs=20, batch_size=256,validation_data=(X_val, Y_val), sample_weight = sample_weight) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 125693 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "125693/125693 [==============================] - 64s 512us/step - loss: 5.0818 - val_loss: 13.6940\n",
            "Epoch 2/20\n",
            "125693/125693 [==============================] - 62s 495us/step - loss: 3.8197 - val_loss: 13.5998\n",
            "Epoch 3/20\n",
            "125693/125693 [==============================] - 62s 497us/step - loss: 3.2029 - val_loss: 13.5234\n",
            "Epoch 4/20\n",
            "125693/125693 [==============================] - 62s 497us/step - loss: 2.8118 - val_loss: 13.4666\n",
            "Epoch 5/20\n",
            "125693/125693 [==============================] - 63s 498us/step - loss: 2.5392 - val_loss: 13.4342\n",
            "Epoch 6/20\n",
            "125693/125693 [==============================] - 63s 499us/step - loss: 2.3287 - val_loss: 13.4138\n",
            "Epoch 7/20\n",
            "125693/125693 [==============================] - 62s 497us/step - loss: 2.1763 - val_loss: 13.4002\n",
            "Epoch 8/20\n",
            "125693/125693 [==============================] - 62s 496us/step - loss: 2.0440 - val_loss: 13.3870\n",
            "Epoch 9/20\n",
            "125693/125693 [==============================] - 62s 496us/step - loss: 1.9390 - val_loss: 13.3825\n",
            "Epoch 10/20\n",
            "125693/125693 [==============================] - 62s 497us/step - loss: 1.8562 - val_loss: 13.3762\n",
            "Epoch 11/20\n",
            "125693/125693 [==============================] - 63s 497us/step - loss: 1.7756 - val_loss: 13.3813\n",
            "Epoch 12/20\n",
            "125693/125693 [==============================] - 62s 496us/step - loss: 1.7139 - val_loss: 13.3706\n",
            "Epoch 13/20\n",
            "125693/125693 [==============================] - 62s 496us/step - loss: 1.6523 - val_loss: 13.3760\n",
            "Epoch 14/20\n",
            "125693/125693 [==============================] - 62s 496us/step - loss: 1.6040 - val_loss: 13.3717\n",
            "Epoch 15/20\n",
            "125693/125693 [==============================] - 62s 495us/step - loss: 1.5551 - val_loss: 13.3718\n",
            "Epoch 16/20\n",
            "125693/125693 [==============================] - 62s 495us/step - loss: 1.5130 - val_loss: 13.3716\n",
            "Epoch 17/20\n",
            "125693/125693 [==============================] - 62s 496us/step - loss: 1.4790 - val_loss: 13.3747\n",
            "Epoch 18/20\n",
            "125693/125693 [==============================] - 62s 495us/step - loss: 1.4428 - val_loss: 13.3762\n",
            "Epoch 19/20\n",
            "125693/125693 [==============================] - 62s 495us/step - loss: 1.4077 - val_loss: 13.3793\n",
            "Epoch 20/20\n",
            "125693/125693 [==============================] - 62s 495us/step - loss: 1.3761 - val_loss: 13.3807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdd4278ce80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfHeNpHAcm6D",
        "colab_type": "text"
      },
      "source": [
        "Para el primero modelo se tenian 1.407.653 parámetros entrenables y para el segundo modelo 3.699.045 parámetros entrenables (2,5 veces la cantidad de parámetros del primer modelo) y aún así, los tiempos de entrenamiento de cada epoch son similares.  Esto último se debe a la disminución de las capas recurrentes en el segundo modelo respecto al primero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EEAmME4pdGxy"
      },
      "source": [
        "### h) Visualice lo aprendido por el modelo sobre algunos datos del conjunto de entrenamiento y validación, comente lo observado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nupbmTrWdI9g",
        "colab": {}
      },
      "source": [
        "def predict_words(y_indexs, data=\"target\"):\n",
        "    \"\"\" Predict until '-#end-' is seen \"\"\"\n",
        "    return_val = []\n",
        "    for indx_word in y_indexs:\n",
        "        if indx_word != 0: #start to predict\n",
        "            return_val.append(np.squeeze(indx_word))\n",
        "            if data == \"target\": #if target is predicting\n",
        "                if indx_word == word2idx_t[\"#end\"]:\n",
        "                    return return_val                \n",
        "    return return_val\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA1rq3Ywf5IR",
        "colab_type": "text"
      },
      "source": [
        "Visualizamos lo aprendido par el primer modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pj5q9NG8dLwY",
        "outputId": "a257e132-b4a3-423b-d15b-78ff24a92d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_s = 50\n",
        "Y_set=Y_train\n",
        "X_set=X_train\n",
        "idx = np.random.choice(np.arange(Y_set.shape[0]), size=n_s, replace=False)\n",
        "Y_set_pred = model.predict_classes(X_set[idx] )\n",
        "for i, n_sampled in enumerate(idx):\n",
        "    text_input = [idx2word_s[p] for p in predict_words(X_set[n_sampled], data=\"source\")]\n",
        "    print(\"Texto source: \", ' '.join(text_input))\n",
        "    text_real = [idx2word_t[p] for p in predict_words(Y_set[n_sampled,:,0], data=\"target\")]\n",
        "    print(\"Texto target real: \", ' '.join( text_real))\n",
        "    text_sampled = [idx2word_t[p] for p in predict_words(Y_set_pred[i], data=\"target\")]\n",
        "    print(\"Texto target predicho del modelo 0: \", ' '.join(text_sampled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto source:  the price is low but the quality isnt very good\n",
            "Texto target real:  o preço é baixo mas a qualidade não é muito alta #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  owls hunt at night\n",
            "Texto target real:  as corujas caçam à noite #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i dedicate this song to you\n",
            "Texto target real:  dedico esta música a você #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i can only pay dollars at most\n",
            "Texto target real:  eu posso pagar dólares no máximo #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  please close the door\n",
            "Texto target real:  fechem a porta por favor #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom pointed toward the ceiling\n",
            "Texto target real:  tom apontou em direção ao teto #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  youre way taller than tom\n",
            "Texto target real:  você é mais alta que o tom #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  im going to tell tom what happened\n",
            "Texto target real:  eu vou contar ao tom o que aconteceu #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  our country is running short of energy resources\n",
            "Texto target real:  os recursos de nosso país estão se esgotando #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  the doctor told tom to lower the amount of red meat that he ate\n",
            "Texto target real:  o médico disse a tom para diminuir a quantidade de carne vermelha que ele comia #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  how did you guys meet\n",
            "Texto target real:  como vocês se conheceram #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom married marys daughter\n",
            "Texto target real:  tom casouse com a filha de maria #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  this stone has a hole in the center\n",
            "Texto target real:  esta pedra tem um buraco no centro #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  youre behaving like a spoiled brat\n",
            "Texto target real:  você está se comportando como um mimado #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  it looks perfect\n",
            "Texto target real:  parece perfeita #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  im not the one who should go\n",
            "Texto target real:  não sou eu quem deveria ir embora #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  im sorry to trouble you but could you tell me the way to the station\n",
            "Texto target real:  desculpe incomodála mas a senhora poderia me indicar o caminho à estação #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i believe in this method of teaching\n",
            "Texto target real:  eu acredito neste método de ensino #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  im not going to go there\n",
            "Texto target real:  não vou para lá #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  this fits perfectly\n",
            "Texto target real:  isto cabe perfeitamente #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i was in a bad mood\n",
            "Texto target real:  eu estava de mau humor #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom didnt have much food to eat\n",
            "Texto target real:  tom não tinha muito para comer #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  im a journalist\n",
            "Texto target real:  sou jornalista #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  you will have a new sister\n",
            "Texto target real:  vocês vão ganhar uma nova irmã #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  how much rent do you pay for the apartment\n",
            "Texto target real:  quanto você paga pelo aluguel do apartamento #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  youre planning something arent you\n",
            "Texto target real:  você está tramando algo não está #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  theyre digging a hole\n",
            "Texto target real:  eles um buraco #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom was one of us\n",
            "Texto target real:  o tom era um de nós #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  im going to toms house to study\n",
            "Texto target real:  vou à casa do tom estudar #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  ignore them\n",
            "Texto target real:  #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i think youre an idiot\n",
            "Texto target real:  eu acho que você é um idiota #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i still dont trust you\n",
            "Texto target real:  eu ainda não confio em você #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  why dont you go to school\n",
            "Texto target real:  por que você não vai à escola #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  were going to boston for a week\n",
            "Texto target real:  nós vamos para boston uma semana #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom does all his work at night\n",
            "Texto target real:  tom faz todo o seu trabalho à noite #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i felt like god\n",
            "Texto target real:  eu me senti como deus #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  thats the law\n",
            "Texto target real:  é a lei #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  lets eat lunch outside\n",
            "Texto target real:  vamos almoçar lá fora #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  who won the game\n",
            "Texto target real:  quem ganhou o jogo #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  were going upstairs\n",
            "Texto target real:  nós vamos para o andar de cima #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  please give me a cup of milk\n",
            "Texto target real:  por favor dáme um copo de leite #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom seemed a bit surprised\n",
            "Texto target real:  tom parecia um pouco surpreso #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  im responsible for this\n",
            "Texto target real:  sou responsável por isto #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  you are incorrect\n",
            "Texto target real:  você está equivocado #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  you must be thirsty\n",
            "Texto target real:  você deve estar com sede #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i have a handkerchief in my pocket\n",
            "Texto target real:  tenho um lenço no bolso #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  what are you reading\n",
            "Texto target real:  o que vós estais lendo #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  why do you hate tom so much\n",
            "Texto target real:  por que você odeia tanto o tom #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  the last time i saw tom he was with mary\n",
            "Texto target real:  a última vez em que vi o tom ele estava com a mary #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  im not from boston\n",
            "Texto target real:  eu não sou de boston #end\n",
            "Texto target predicho del modelo 0:  #end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6dYK0wBjYAuw",
        "outputId": "62ba8520-45d9-41ba-bf72-13c2986f4215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_s = 50\n",
        "Y_set=Y_val\n",
        "X_set=X_val\n",
        "idx = np.random.choice(np.arange(Y_set.shape[0]), size=n_s, replace=False)\n",
        "Y_set_pred = model.predict_classes(X_set[idx] )\n",
        "for i, n_sampled in enumerate(idx):\n",
        "    text_input = [idx2word_s[p] for p in predict_words(X_set[n_sampled], data=\"source\")]\n",
        "    print(\"Texto source: \", ' '.join(text_input))\n",
        "    text_real = [idx2word_t[p] for p in predict_words(Y_set[n_sampled,:,0], data=\"target\")]\n",
        "    print(\"Texto target real: \", ' '.join( text_real))\n",
        "    text_sampled = [idx2word_t[p] for p in predict_words(Y_set_pred[i], data=\"target\")]\n",
        "    print(\"Texto target predicho del modelo 0: \", ' '.join(text_sampled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto source:  tell tom im hungry\n",
            "Texto target real:  diga ao tom que estou com fome #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  youre cute\n",
            "Texto target real:  vocês são bonitos #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  id like to see your father\n",
            "Texto target real:  gostaria de ver o teu pai #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  didnt you use to have a car\n",
            "Texto target real:  a senhora não tinha um carro #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  it doesnt matter anymore\n",
            "Texto target real:  não importa mais #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  is tom lost\n",
            "Texto target real:  o tom está perdido #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  what are they doing\n",
            "Texto target real:  o que eles estão fazendo #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i knew that it wouldnt be easy\n",
            "Texto target real:  eu sabia que não seria fácil #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  youre\n",
            "Texto target real:  você é #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom waited for three hours\n",
            "Texto target real:  tom esperou por três horas #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom is not in prison at the moment\n",
            "Texto target real:  tom não está na prisão atualmente #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom has collected a great many butterflies\n",
            "Texto target real:  tom possui uma grande coleção de borboletas #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i have three chickens in my house\n",
            "Texto target real:  eu tenho três galinhas na minha casa #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom didnt want to be a lawyer or a doctor\n",
            "Texto target real:  tom não queria ser nem advogado nem médico #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  why didnt you help tom escape\n",
            "Texto target real:  por que você não ajudou o tom a escapar #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  close the door when you leave\n",
            "Texto target real:  feche a porta quando sair #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom bought a gift for his daughter\n",
            "Texto target real:  tom comprou um presente para a filha #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  in what month were you born\n",
            "Texto target real:  em que mês você nasceu #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  what are you interested in\n",
            "Texto target real:  em que você se interessa #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i can speak a little french\n",
            "Texto target real:  eu posso falar um pouco de francês #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom said hell do that\n",
            "Texto target real:  o tom disse que vai fazer isso #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  hell be there in ten minutes\n",
            "Texto target real:  estará aí em dez minutos #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  you wont believe what i just saw\n",
            "Texto target real:  você não vai acreditar no que eu acabei de ver #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  the photographs are the same\n",
            "Texto target real:  as fotografias são iguais #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  one of the greatest facing middle school students learning english is\n",
            "Texto target real:  uma das maiores por estudantes de ensino médio aprendendo inglês são os #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  weve been friends for thirty years\n",
            "Texto target real:  nós fomos amigos por trinta anos #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  put the key in the mailbox\n",
            "Texto target real:  coloque a chave na caixa de correio #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  nothing will happen\n",
            "Texto target real:  nada acontecerá #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  can we smoke here\n",
            "Texto target real:  podemos fumar aqui #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  dont let tom drink any more\n",
            "Texto target real:  nunca mais deixe o tom beber #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom says he didnt cry\n",
            "Texto target real:  tom diz que ele não chorou #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom showed us a few pictures\n",
            "Texto target real:  o tom nos mostrou algumas fotos #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  that man cant have committed suicide\n",
            "Texto target real:  esse homem não pode ter se #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  is it true that youre moving to australia\n",
            "Texto target real:  é verdade que vocês estão se mudando para a austrália #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  were all unique\n",
            "Texto target real:  todos nós somos únicos #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  it looks like you had a rough night\n",
            "Texto target real:  parece que você teve uma noite difícil #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  we had no alternative but to fight\n",
            "Texto target real:  não temos escolha senão lutar #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  hi my name is tom\n",
            "Texto target real:  oi o meu nome é tom #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i am glad to hear of your success\n",
            "Texto target real:  deixame feliz saber do sucesso da senhora #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  it was cold\n",
            "Texto target real:  estava frio #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i went to bed after eating\n",
            "Texto target real:  fui para a cama depois de comer #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  im not sure when hell come\n",
            "Texto target real:  não tenho certeza de quando ele virá #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  thirteen is a lucky number in the brazilian lottery\n",
            "Texto target real:  o treze é um número de sorte na loteria brasileira #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  i cant stay here\n",
            "Texto target real:  não posso ficar aqui #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  what else do you have\n",
            "Texto target real:  o que mais você tem #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  why wont you answer\n",
            "Texto target real:  por que você não responde #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  may i help you\n",
            "Texto target real:  quer ajuda #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  theres a on the jar\n",
            "Texto target real:  há uma no pote #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  tom said mary was canadian\n",
            "Texto target real:  o tom disse que a mary é canadense #end\n",
            "Texto target predicho del modelo 0:  #end\n",
            "Texto source:  he is crazy about baseball\n",
            "Texto target real:  ele é louco por beisebol #end\n",
            "Texto target predicho del modelo 0:  #end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQE7ZP8if-Ff",
        "colab_type": "text"
      },
      "source": [
        "Visualizamos lo aprendido para el segundo modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HGFIq1oOYAu1",
        "outputId": "65871d1d-710c-443f-c5c0-61a71da09b30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_s = 50\n",
        "Y_set=Y_train\n",
        "X_set=X_train\n",
        "idx = np.random.choice(np.arange(Y_set.shape[0]), size=n_s, replace=False)\n",
        "Y_set_pred = model1.predict_classes(X_set[idx] )\n",
        "for i, n_sampled in enumerate(idx):\n",
        "    text_input = [idx2word_s[p] for p in predict_words(X_set[n_sampled], data=\"source\")]\n",
        "    print(\"Texto source: \", ' '.join(text_input))\n",
        "    text_real = [idx2word_t[p] for p in predict_words(Y_set[n_sampled,:,0], data=\"target\")]\n",
        "    print(\"Texto target real: \", ' '.join( text_real))\n",
        "    text_sampled = [idx2word_t[p] for p in predict_words(Y_set_pred[i], data=\"target\")]\n",
        "    print(\"Texto target predicho del modelo 1: \", ' '.join(text_sampled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto source:  tom learned to skate when he was thirteen\n",
            "Texto target real:  tom aprendeu a patinar quando tinha treze anos #end\n",
            "Texto target predicho del modelo 1:  tom aprendeu a a quando quando treze treze #end\n",
            "Texto source:  everyone should know that\n",
            "Texto target real:  todos devem saber disso #end\n",
            "Texto target predicho del modelo 1:  todos devem saber disso #end\n",
            "Texto source:  who are you im tom\n",
            "Texto target real:  quem é você sou o tom #end\n",
            "Texto target predicho del modelo 1:  quem você você eu sou tom #end\n",
            "Texto source:  im sure that your parents are very proud of you\n",
            "Texto target real:  tenho certeza de que seus pais têm muito orgulho de vocês #end\n",
            "Texto target predicho del modelo 1:  tenho certeza de que que de orgulhosos de de de de de #end\n",
            "Texto source:  give this copy to tom\n",
            "Texto target real:  dê esta cópia ao tom #end\n",
            "Texto target predicho del modelo 1:  dê a cópia ao tom tom #end\n",
            "Texto source:  its making me nervous\n",
            "Texto target real:  está me deixando nervoso #end\n",
            "Texto target predicho del modelo 1:  está está deixando nervoso #end\n",
            "Texto source:  i prefer traveling by train to flying\n",
            "Texto target real:  gosto mais de viajar de comboio que de avião #end\n",
            "Texto target predicho del modelo 1:  eu de de de de de de avião de #end\n",
            "Texto source:  dont worry about the baby\n",
            "Texto target real:  não se preocupe com o bebê #end\n",
            "Texto target predicho del modelo 1:  não se preocupe o o bebê #end\n",
            "Texto source:  dont you all agree\n",
            "Texto target real:  vocês não concordam #end\n",
            "Texto target predicho del modelo 1:  você não concordam #end\n",
            "Texto source:  i come in peace\n",
            "Texto target real:  venho em paz #end\n",
            "Texto target predicho del modelo 1:  eu em paz #end\n",
            "Texto source:  where is the bus terminal\n",
            "Texto target real:  onde fica a #end\n",
            "Texto target predicho del modelo 1:  onde é a de ônibus #end\n",
            "Texto source:  how long have you been home\n",
            "Texto target real:  há quanto tempo você está em casa #end\n",
            "Texto target predicho del modelo 1:  há quanto tempo você você em em #end\n",
            "Texto source:  he took his wallet out of his pocket\n",
            "Texto target real:  ele tirou a carteira do bolso #end\n",
            "Texto target predicho del modelo 1:  ele tirou a carteira bolso bolso bolso #end\n",
            "Texto source:  i have no more than three thousand yen\n",
            "Texto target real:  não tenho mais que três mil ienes #end\n",
            "Texto target predicho del modelo 1:  eu tenho mais que que mil #end\n",
            "Texto source:  im late for dinner\n",
            "Texto target real:  estou atrasada para o jantar #end\n",
            "Texto target predicho del modelo 1:  estou atrasado para o jantar #end\n",
            "Texto source:  can you swim\n",
            "Texto target real:  você sabe nadar #end\n",
            "Texto target predicho del modelo 1:  você nadar #end\n",
            "Texto source:  hes probably sleeping\n",
            "Texto target real:  provavelmente ele está dormindo #end\n",
            "Texto target predicho del modelo 1:  ele provavelmente está dormindo #end\n",
            "Texto source:  id suggest you look for another place\n",
            "Texto target real:  sugiro que procure outro lugar #end\n",
            "Texto target predicho del modelo 1:  sugiro que que você #end\n",
            "Texto source:  i believe that tom is not guilty\n",
            "Texto target real:  eu acredito que tom não é culpado #end\n",
            "Texto target predicho del modelo 1:  eu que que tom não é culpado #end\n",
            "Texto source:  who is the current from france\n",
            "Texto target real:  quem é o atual da frança #end\n",
            "Texto target predicho del modelo 1:  quem é a atual da frança #end\n",
            "Texto source:  dont forget to bring a pen\n",
            "Texto target real:  não se esqueça de trazer uma caneta #end\n",
            "Texto target predicho del modelo 1:  não se esqueça de trazer trazer caneta #end\n",
            "Texto source:  its sweet\n",
            "Texto target real:  está doce #end\n",
            "Texto target predicho del modelo 1:  é doce #end\n",
            "Texto source:  tom is astonished\n",
            "Texto target real:  tom está surpreso #end\n",
            "Texto target predicho del modelo 1:  tom está surpreso #end\n",
            "Texto source:  how big is your school\n",
            "Texto target real:  qual é o tamanho da sua escola #end\n",
            "Texto target predicho del modelo 1:  qual é o é sua sua sua sua #end\n",
            "Texto source:  im trying to get in touch with my sister\n",
            "Texto target real:  estou tentando entrar em contato com a minha irmã #end\n",
            "Texto target predicho del modelo 1:  estou estou em contato contato com minha minha #end\n",
            "Texto source:  everybody agrees with you\n",
            "Texto target real:  todos estão de acordo com você #end\n",
            "Texto target predicho del modelo 1:  todo estão de com você #end\n",
            "Texto source:  i have a lawyer\n",
            "Texto target real:  eu tenho um advogado #end\n",
            "Texto target predicho del modelo 1:  eu tenho um advogado #end\n",
            "Texto source:  it is difficult for me to answer the question\n",
            "Texto target real:  é difícil para eu responder a pergunta #end\n",
            "Texto target predicho del modelo 1:  é difícil para para responder a a #end\n",
            "Texto source:  they already got married\n",
            "Texto target real:  já se casaram #end\n",
            "Texto target predicho del modelo 1:  eles já casaram #end\n",
            "Texto source:  she intends to play tennis\n",
            "Texto target real:  ela pretende jogar tênis #end\n",
            "Texto target predicho del modelo 1:  ela pretende jogar tênis #end\n",
            "Texto source:  tom said something to mary that made her cry\n",
            "Texto target real:  tom disse alguma coisa para a mary que a fez chorar #end\n",
            "Texto target predicho del modelo 1:  tom disse disse a a mary que que que que #end\n",
            "Texto source:  tom is doing that now\n",
            "Texto target real:  tom está fazendo isso agora #end\n",
            "Texto target predicho del modelo 1:  tom está fazendo isso isso #end\n",
            "Texto source:  i am just a nobody\n",
            "Texto target real:  sou apenas um ninguém #end\n",
            "Texto target predicho del modelo 1:  eu só um ninguém #end\n",
            "Texto source:  he will tell me everything sooner or later\n",
            "Texto target real:  cedo ou tarde ele irá me contar tudo #end\n",
            "Texto target predicho del modelo 1:  ele me que ou ou ou tarde tarde tarde tarde tarde #end\n",
            "Texto source:  tom bought a ticket\n",
            "Texto target real:  tom comprou um ingresso #end\n",
            "Texto target predicho del modelo 1:  tom comprou um bilhete #end\n",
            "Texto source:  i have a plan\n",
            "Texto target real:  eu tenho um plano #end\n",
            "Texto target predicho del modelo 1:  tenho um plano #end\n",
            "Texto source:  you guys are hilarious\n",
            "Texto target real:  vocês são engraçados #end\n",
            "Texto target predicho del modelo 1:  vocês são engraçados #end\n",
            "Texto source:  theyre in danger\n",
            "Texto target real:  eles estão em perigo #end\n",
            "Texto target predicho del modelo 1:  eles estão em perigo #end\n",
            "Texto source:  i asked her if she had been to mexico\n",
            "Texto target real:  eu perguntei para ela se ela tinha estado no méxico #end\n",
            "Texto target predicho del modelo 1:  perguntei perguntei perguntei ela ela ela ela ela ela #end\n",
            "Texto source:  the world is full of fools\n",
            "Texto target real:  o mundo está cheio de idiotas #end\n",
            "Texto target predicho del modelo 1:  o mundo está cheio de tolos #end\n",
            "Texto source:  i dont like it when people ask me to do things for them\n",
            "Texto target real:  não gosto quando as pessoas me pedem para fazer coisas para elas #end\n",
            "Texto target predicho del modelo 1:  eu não gosto de que as as os os para para para #end\n",
            "Texto source:  please feel free to ask me any question\n",
            "Texto target real:  por favor fique à vontade para me perguntar qualquer coisa #end\n",
            "Texto target predicho del modelo 1:  por favor para para para para para perguntar perguntar perguntar #end\n",
            "Texto source:  as soon as i got home it began to rain\n",
            "Texto target real:  assim que eu cheguei em casa começou a chover #end\n",
            "Texto target predicho del modelo 1:  assim que eu chover chegar começou começou chegar #end\n",
            "Texto source:  tom slept in the car\n",
            "Texto target real:  tom dormiu no carro #end\n",
            "Texto target predicho del modelo 1:  tom dormiu no carro #end\n",
            "Texto source:  i thought we were going to go somewhere\n",
            "Texto target real:  eu achei que iríamos para algum lugar #end\n",
            "Texto target predicho del modelo 1:  eu pensei que iríamos para para lugar lugar #end\n",
            "Texto source:  we have to warn them\n",
            "Texto target real:  nós temos que #end\n",
            "Texto target predicho del modelo 1:  temos que #end\n",
            "Texto source:  he will play golf next sunday\n",
            "Texto target real:  ele jogará golfe domingo próximo #end\n",
            "Texto target predicho del modelo 1:  ele jogará jogar domingo domingo domingo domingo #end\n",
            "Texto source:  this is good meat\n",
            "Texto target real:  isto é carne boa #end\n",
            "Texto target predicho del modelo 1:  isto é boa boa #end\n",
            "Texto source:  he is a born artist\n",
            "Texto target real:  ele é um artista nato #end\n",
            "Texto target predicho del modelo 1:  ele é um artista nato #end\n",
            "Texto source:  we stayed at home all day\n",
            "Texto target real:  ficamos em casa o dia todo #end\n",
            "Texto target predicho del modelo 1:  ficamos em em em o todo dia #end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FTce29VYYAu4",
        "outputId": "799702d1-7f29-498c-f3d6-d5c8f631f9e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_s = 50\n",
        "Y_set=Y_val\n",
        "X_set=X_val\n",
        "idx = np.random.choice(np.arange(Y_set.shape[0]), size=n_s, replace=False)\n",
        "Y_set_pred = model1.predict_classes(X_set[idx] )\n",
        "for i, n_sampled in enumerate(idx):\n",
        "    text_input = [idx2word_s[p] for p in predict_words(X_set[n_sampled], data=\"source\")]\n",
        "    print(\"Texto source: \", ' '.join(text_input))\n",
        "    text_real = [idx2word_t[p] for p in predict_words(Y_set[n_sampled,:,0], data=\"target\")]\n",
        "    print(\"Texto target real: \", ' '.join( text_real))\n",
        "    text_sampled = [idx2word_t[p] for p in predict_words(Y_set_pred[i], data=\"target\")]\n",
        "    print(\"Texto target predicho del modelo 1: \", ' '.join(text_sampled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto source:  i dont feel like joking\n",
            "Texto target real:  eu não estou com vontade de brincar #end\n",
            "Texto target predicho del modelo 1:  eu não estou com de de de #end\n",
            "Texto source:  im starting to get bored\n",
            "Texto target real:  estou começando a ficar entediado #end\n",
            "Texto target predicho del modelo 1:  estou começando a estudar ficar #end\n",
            "Texto source:  you should be more of your safety\n",
            "Texto target real:  você deveria estar mais preocupado com sua segurança #end\n",
            "Texto target predicho del modelo 1:  você deveria ser mais mais de sua sua #end\n",
            "Texto source:  dont worry well find tom\n",
            "Texto target real:  não se preocupe nós vamos achar o tom #end\n",
            "Texto target predicho del modelo 1:  não se preocupe com encontrar o o #end\n",
            "Texto source:  she divided the cake between the two\n",
            "Texto target real:  ela repartiu o bolo entre os dois #end\n",
            "Texto target predicho del modelo 1:  ela dividiu o bolo entre entre dois #end\n",
            "Texto source:  tom sat down on a rock\n",
            "Texto target real:  tom sentouse em uma rocha #end\n",
            "Texto target predicho del modelo 1:  tom sentouse em em pedra pedra #end\n",
            "Texto source:  tom told me hed rather not go\n",
            "Texto target real:  tom disseme que preferiria não ir #end\n",
            "Texto target predicho del modelo 1:  tom me disse que ele não não ir #end\n",
            "Texto source:  tom knows what we did\n",
            "Texto target real:  o tom sabe o que fizemos #end\n",
            "Texto target predicho del modelo 1:  tom sabe o o fizemos fizemos #end\n",
            "Texto source:  tom has already explained the rules to me\n",
            "Texto target real:  tom já me explicou as regras #end\n",
            "Texto target predicho del modelo 1:  tom já esqueceu as regras para #end\n",
            "Texto source:  tom can play the flute\n",
            "Texto target real:  tom sabe tocar flauta #end\n",
            "Texto target predicho del modelo 1:  tom sabe tocar flauta #end\n",
            "Texto source:  write your name in\n",
            "Texto target real:  escreva seu nome em letras #end\n",
            "Texto target predicho del modelo 1:  escreva seu seu teu #end\n",
            "Texto source:  i know the person you are talking about\n",
            "Texto target real:  eu sei de quem você está falando #end\n",
            "Texto target predicho del modelo 1:  eu a que pessoa que você você você #end\n",
            "Texto source:  everyone is talking about it\n",
            "Texto target real:  todos estão falando sobre isso #end\n",
            "Texto target predicho del modelo 1:  todos mundo estão falando sobre #end\n",
            "Texto source:  is one thousand yen enough\n",
            "Texto target real:  mil ienes é o bastante #end\n",
            "Texto target predicho del modelo 1:  mil mil ienes #end\n",
            "Texto source:  youre good at that\n",
            "Texto target real:  você é bom nisso #end\n",
            "Texto target predicho del modelo 1:  você é bom nisto #end\n",
            "Texto source:  he told me the story of his life\n",
            "Texto target real:  ele me contou a história da vida dele #end\n",
            "Texto target predicho del modelo 1:  ele me contou a sua da da vida #end\n",
            "Texto source:  every little boy needs a hero\n",
            "Texto target real:  todo menino pequeno precisa de um herói #end\n",
            "Texto target predicho del modelo 1:  todo conselho precisa de herói #end\n",
            "Texto source:  this is just amazing\n",
            "Texto target real:  isto é incrível #end\n",
            "Texto target predicho del modelo 1:  isto é incrível incrível #end\n",
            "Texto source:  ive asked you this question before\n",
            "Texto target real:  eu havia te perguntado isso antes #end\n",
            "Texto target predicho del modelo 1:  eu pedi você isso esta antes antes #end\n",
            "Texto source:  we shouldnt even consider doing that\n",
            "Texto target real:  não devemos nem pensar em fazer isso #end\n",
            "Texto target predicho del modelo 1:  nós não deveríamos deveríamos fazer fazer fazer isso #end\n",
            "Texto source:  tom didnt smile\n",
            "Texto target real:  tom não sorriu #end\n",
            "Texto target predicho del modelo 1:  tom não não #end\n",
            "Texto source:  would you like some orange juice\n",
            "Texto target real:  a senhora quer suco de laranja #end\n",
            "Texto target predicho del modelo 1:  você quer de suco de de #end\n",
            "Texto source:  thats how we first met\n",
            "Texto target real:  foi assim que nos conhecemos #end\n",
            "Texto target predicho del modelo 1:  foi conseguimos pela encontramos nós a #end\n",
            "Texto source:  im here to stay\n",
            "Texto target real:  eu estou aqui para ficar #end\n",
            "Texto target predicho del modelo 1:  estou estou aqui para #end\n",
            "Texto source:  tom didnt want to go to the hospital\n",
            "Texto target real:  tom não queria ir ao hospital #end\n",
            "Texto target predicho del modelo 1:  tom não queria ir para hospital #end\n",
            "Texto source:  i saw an opportunity and i took it\n",
            "Texto target real:  eu vi uma oportunidade e eu #end\n",
            "Texto target predicho del modelo 1:  vi vi filme e e e vi #end\n",
            "Texto source:  i dont know if its going to work\n",
            "Texto target real:  eu não sei se funcionará #end\n",
            "Texto target predicho del modelo 1:  eu não sei se vai funcionar #end\n",
            "Texto source:  hundred british soldiers the border\n",
            "Texto target real:  cento e vinte e cinco soldados a fronteira #end\n",
            "Texto target predicho del modelo 1:  os os fronteira a fronteira #end\n",
            "Texto source:  can you hold on a sec\n",
            "Texto target real:  você pode esperar um segundo #end\n",
            "Texto target predicho del modelo 1:  você poderia ficar um #end\n",
            "Texto source:  you look bored\n",
            "Texto target real:  pareces aborrecido #end\n",
            "Texto target predicho del modelo 1:  pareces parece entediado #end\n",
            "Texto source:  tokyo is a very big city\n",
            "Texto target real:  tóquio é uma cidade muito grande #end\n",
            "Texto target predicho del modelo 1:  tóquio uma uma grande cidade grande #end\n",
            "Texto source:  neither of them seemed old\n",
            "Texto target real:  nenhum dos dois parecia velho #end\n",
            "Texto target predicho del modelo 1:  nenhum estudantes deles não tinham #end\n",
            "Texto source:  be prepared for\n",
            "Texto target real:  esteja preparado para #end\n",
            "Texto target predicho del modelo 1:  seja preparado #end\n",
            "Texto source:  would you mind speaking a little louder\n",
            "Texto target real:  você se importaria de falar um pouco mais alto #end\n",
            "Texto target predicho del modelo 1:  você se de em em pouco pouco pouco alto alto alto alto #end\n",
            "Texto source:  my daughter came to see me from time to time\n",
            "Texto target real:  minha filha vinha me ver de vez em quando #end\n",
            "Texto target predicho del modelo 1:  minha minha me me me me em em #end\n",
            "Texto source:  did anybody see what happened\n",
            "Texto target real:  alguém viu o que aconteceu #end\n",
            "Texto target predicho del modelo 1:  alguém viu o o aconteceu #end\n",
            "Texto source:  all i found are pictures of you\n",
            "Texto target real:  tudo que encontrei foram fotos suas #end\n",
            "Texto target predicho del modelo 1:  tudo a que que fotos fotos fotos fotos #end\n",
            "Texto source:  do you know what toms plans are\n",
            "Texto target real:  você sabe quais são os planos do tom #end\n",
            "Texto target predicho del modelo 1:  você sabe o os planos planos de tom #end\n",
            "Texto source:  tom finally got caught\n",
            "Texto target real:  tom finalmente foi pego #end\n",
            "Texto target predicho del modelo 1:  o tom finalmente pego pego #end\n",
            "Texto source:  this is my fault\n",
            "Texto target real:  isto é culpa minha #end\n",
            "Texto target predicho del modelo 1:  esta é minha minha #end\n",
            "Texto source:  i know you were proud of me\n",
            "Texto target real:  eu sei que você estava orgulhoso de mim #end\n",
            "Texto target predicho del modelo 1:  eu sei que você estava de mim #end\n",
            "Texto source:  it seems to me that things would be better this way\n",
            "Texto target real:  pareceme que as coisas seriam melhor assim #end\n",
            "Texto target predicho del modelo 1:  me que que que que que a #end\n",
            "Texto source:  are you thinking about tom\n",
            "Texto target real:  a senhora está pensando no tom #end\n",
            "Texto target predicho del modelo 1:  você está pensando pensando tom tom #end\n",
            "Texto source:  what is tom eating\n",
            "Texto target real:  o que tom está comendo #end\n",
            "Texto target predicho del modelo 1:  o que o tom está #end\n",
            "Texto source:  im not guilty\n",
            "Texto target real:  eu não sou culpado #end\n",
            "Texto target predicho del modelo 1:  eu não sou culpada #end\n",
            "Texto source:  i congratulated him on the birth of his son\n",
            "Texto target real:  eu o parabenizei pelo nascimento do filho dele #end\n",
            "Texto target predicho del modelo 1:  eu o parabenizei o filho de filho do filho #end\n",
            "Texto source:  is tom still asleep\n",
            "Texto target real:  o tom ainda está dormindo #end\n",
            "Texto target predicho del modelo 1:  o tom está dormindo dormindo #end\n",
            "Texto source:  i asked for toms help\n",
            "Texto target real:  eu pedi a ajuda do tom #end\n",
            "Texto target predicho del modelo 1:  eu pedi ajuda de tom #end\n",
            "Texto source:  you shouldnt have read toms letter\n",
            "Texto target real:  vocês não deveriam ter lido a carta de tom #end\n",
            "Texto target predicho del modelo 1:  você não deveria ter a a carta de tom #end\n",
            "Texto source:  i need to charge my cell phone\n",
            "Texto target real:  preciso carregar meu celular #end\n",
            "Texto target predicho del modelo 1:  eu preciso o meu celular #end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYkCEaTogK4M",
        "colab_type": "text"
      },
      "source": [
        "Como se esperaba al comparar los valores de las funciones de pérdida, el segundo modelo (no puramente recurrente)  tiene un rendimiento mucho mejor tanto en el conjunto de entrenamiendo como en el de validación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8al2xtZVdL41"
      },
      "source": [
        "### i) Realice algún cambio esperando que mejore el modelo entrenado, luego vuelva a visualizar lo predicho por la red *vs* lo real. *Debido a lo costoso en entrenar puede optar por realizar solo un cambio pero que sea significativo*.  Se comentan algunas opciones para utilizar y combinar:\n",
        "* Cambiar  el *embedding* por alguno pre-entrenado\n",
        "* Agregar regularizadores\n",
        "* Asignar peso a las clases/palabras de salida\n",
        "* Cambiar *Global max pooling* por *Average max pooling*\n",
        "* Aumentar o reducir capas\n",
        "* Aumentar o reducir neuronas/unidades  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl1kXJQbhEOd",
        "colab_type": "text"
      },
      "source": [
        "Para mejorar el rendimiento del modelo, tomamos el segundo modelo de los dos anteriores y modificamos Global Max pooling por Global Average pooling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Kfw6mUhzHf",
        "colab_type": "code",
        "outputId": "62e163f9-d814-4e12-a55c-632ab2785848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Embedding(input_dim=n_words_s, output_dim=EMBEDDING_DIM, input_length=max_inp_length))\n",
        "model2.add(Conv1D(256, 5, padding='same', activation='relu', strides=1))\n",
        "model2.add(BatchNormalization()) #for stability\n",
        "model2.add(Conv1D(256, 5, padding='same', activation='relu', strides=1))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(GlobalAveragePooling1D()) #aka to return_sequences=False\n",
        "model2.add(RepeatVector(max_out_length)) #conection\n",
        "model2.add(CuDNNGRU(256, return_sequences=True))\n",
        "model2.add(TimeDistributed(Dense(n_words_t, activation='softmax')))\n",
        "model2.summary() \n",
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', sample_weight_mode='temporal')\n",
        "model2.fit(X_train, Y_train, epochs=20, batch_size=256, validation_data=(X_val, Y_val), sample_weight = sample_weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 35, 100)           616200    \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 35, 256)           128256    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 35, 256)           1024      \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 35, 256)           327936    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 35, 256)           1024      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_3 ( (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_6 (RepeatVecto (None, 34, 256)           0         \n",
            "_________________________________________________________________\n",
            "cu_dnngru_9 (CuDNNGRU)       (None, 34, 256)           394752    \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 34, 9107)          2340499   \n",
            "=================================================================\n",
            "Total params: 3,809,691\n",
            "Trainable params: 3,808,667\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n",
            "Train on 125693 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "125693/125693 [==============================] - 66s 523us/step - loss: 5.2425 - val_loss: 14.0066\n",
            "Epoch 2/20\n",
            "125693/125693 [==============================] - 63s 497us/step - loss: 3.9787 - val_loss: 13.8953\n",
            "Epoch 3/20\n",
            "125693/125693 [==============================] - 63s 499us/step - loss: 3.1977 - val_loss: 13.6642\n",
            "Epoch 4/20\n",
            "125693/125693 [==============================] - 63s 499us/step - loss: 2.7097 - val_loss: 13.5306\n",
            "Epoch 5/20\n",
            "125693/125693 [==============================] - 63s 500us/step - loss: 2.3963 - val_loss: 13.5417\n",
            "Epoch 6/20\n",
            "125693/125693 [==============================] - 63s 500us/step - loss: 2.1754 - val_loss: 13.5307\n",
            "Epoch 7/20\n",
            "125693/125693 [==============================] - 63s 498us/step - loss: 2.0130 - val_loss: 13.4632\n",
            "Epoch 8/20\n",
            "125693/125693 [==============================] - 63s 498us/step - loss: 1.8893 - val_loss: 13.4740\n",
            "Epoch 9/20\n",
            "125693/125693 [==============================] - 63s 500us/step - loss: 1.7846 - val_loss: 13.4912\n",
            "Epoch 10/20\n",
            "125693/125693 [==============================] - 63s 499us/step - loss: 1.6989 - val_loss: 13.4913\n",
            "Epoch 11/20\n",
            "125693/125693 [==============================] - 63s 497us/step - loss: 1.6236 - val_loss: 13.5186\n",
            "Epoch 12/20\n",
            "125693/125693 [==============================] - 62s 497us/step - loss: 1.5578 - val_loss: 13.5263\n",
            "Epoch 13/20\n",
            "125693/125693 [==============================] - 62s 496us/step - loss: 1.5012 - val_loss: 13.4451\n",
            "Epoch 14/20\n",
            "125693/125693 [==============================] - 63s 497us/step - loss: 1.4502 - val_loss: 13.5100\n",
            "Epoch 15/20\n",
            "125693/125693 [==============================] - 62s 495us/step - loss: 1.4039 - val_loss: 13.4676\n",
            "Epoch 16/20\n",
            "125693/125693 [==============================] - 62s 496us/step - loss: 1.3609 - val_loss: 13.5368\n",
            "Epoch 17/20\n",
            "125693/125693 [==============================] - 63s 498us/step - loss: 1.3244 - val_loss: 13.5324\n",
            "Epoch 18/20\n",
            "125693/125693 [==============================] - 62s 496us/step - loss: 1.2845 - val_loss: 13.4858\n",
            "Epoch 19/20\n",
            "125693/125693 [==============================] - 62s 497us/step - loss: 1.2548 - val_loss: 13.5223\n",
            "Epoch 20/20\n",
            "125693/125693 [==============================] - 62s 497us/step - loss: 1.2247 - val_loss: 13.4948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda6ac70fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZb_sx3li6vo",
        "colab_type": "code",
        "outputId": "887f1158-bfeb-43e4-bae7-df2e21cb84e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_s = 50\n",
        "Y_set=Y_train\n",
        "X_set=X_train\n",
        "idx = np.random.choice(np.arange(Y_set.shape[0]), size=n_s, replace=False)\n",
        "Y_set_pred = model2.predict_classes(X_set[idx] )\n",
        "for i, n_sampled in enumerate(idx):\n",
        "    text_input = [idx2word_s[p] for p in predict_words(X_set[n_sampled], data=\"source\")]\n",
        "    print(\"Texto source: \", ' '.join(text_input))\n",
        "    text_real = [idx2word_t[p] for p in predict_words(Y_set[n_sampled,:,0], data=\"target\")]\n",
        "    print(\"Texto target real: \", ' '.join( text_real))\n",
        "    text_sampled = [idx2word_t[p] for p in predict_words(Y_set_pred[i], data=\"target\")]\n",
        "    print(\"Texto target predicho: \", ' '.join(text_sampled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto source:  tom needs to do something\n",
            "Texto target real:  tom precisa fazer alguma coisa #end\n",
            "Texto target predicho:  tom precisa precisa algo algo coisa #end\n",
            "Texto source:  ive given up eating meat\n",
            "Texto target real:  eu parei de comer carne #end\n",
            "Texto target predicho:  eu parei de comer comer #end\n",
            "Texto source:  tom needs water\n",
            "Texto target real:  tom precisa de água #end\n",
            "Texto target predicho:  tom precisa de de água #end\n",
            "Texto source:  does it snow in boston\n",
            "Texto target real:  está nevando em boston #end\n",
            "Texto target predicho:  está nevando em em boston #end\n",
            "Texto source:  tom is not going to do it\n",
            "Texto target real:  tom não vai fazer isso #end\n",
            "Texto target predicho:  tom não vai vai isso isso #end\n",
            "Texto source:  how are you going to pay me\n",
            "Texto target real:  como você vai me pagar #end\n",
            "Texto target predicho:  você vai você vai me #end\n",
            "Texto source:  tom seems to be a bit taller than mary\n",
            "Texto target real:  tom parece ser um pouco mais alto do que mary #end\n",
            "Texto target predicho:  tom parece parece ser um alto alto do do do #end\n",
            "Texto source:  hes already a man\n",
            "Texto target real:  ele já é um homem #end\n",
            "Texto target predicho:  você ainda está um um #end\n",
            "Texto source:  i received a telegram saying that my uncle had arrived\n",
            "Texto target real:  recebi um telegrama dizendo que meu tio tinha chegado #end\n",
            "Texto target predicho:  recebi dei um telegrama dizendo que que que estava #end\n",
            "Texto source:  i love talking to people\n",
            "Texto target real:  eu adoro conversar com as pessoas #end\n",
            "Texto target predicho:  eu sempre sempre de com pessoas #end\n",
            "Texto source:  i didnt tell him you were coming\n",
            "Texto target real:  eu não disse a ele que você estava vindo #end\n",
            "Texto target predicho:  eu não disse disse que estava estava #end\n",
            "Texto source:  i hate cleaning the bathroom\n",
            "Texto target real:  eu odeio limpar o banheiro #end\n",
            "Texto target predicho:  eu adoro limpar o o banheiro #end\n",
            "Texto source:  why didnt i think of that\n",
            "Texto target real:  por que eu não pensei nisso #end\n",
            "Texto target predicho:  por que não não de isso #end\n",
            "Texto source:  i dont know if tom can help us\n",
            "Texto target real:  eu não sei se tom pode nos ajudar #end\n",
            "Texto target predicho:  eu não sei se tom tom pode ajudar #end\n",
            "Texto source:  i like neither of them\n",
            "Texto target real:  não gosto de nenhum deles #end\n",
            "Texto target predicho:  eu não de de nenhum deles #end\n",
            "Texto source:  she gave birth to twins\n",
            "Texto target real:  ela deu à luz gêmeos #end\n",
            "Texto target predicho:  ela deu para luz de #end\n",
            "Texto source:  i think we should go\n",
            "Texto target real:  eu acho que deveríamos ir #end\n",
            "Texto target predicho:  eu acho que deveríamos deveríamos ir #end\n",
            "Texto source:  it simply doesnt add up\n",
            "Texto target real:  não faz o menor sentido #end\n",
            "Texto target predicho:  só simplesmente só o da #end\n",
            "Texto source:  help us\n",
            "Texto target real:  ajude a gente #end\n",
            "Texto target predicho:  ajude ajudam #end\n",
            "Texto source:  i dont drink alcohol\n",
            "Texto target real:  eu não tomo álcool #end\n",
            "Texto target predicho:  eu não bebo álcool #end\n",
            "Texto source:  tom said hed be back on october\n",
            "Texto target real:  tom disse que voltaria no dia de outubro #end\n",
            "Texto target predicho:  tom disse que voltaria no no no outubro #end\n",
            "Texto source:  theres a big storm on way\n",
            "Texto target real:  há uma grande tempestade a caminho #end\n",
            "Texto target predicho:  há é uma há caminho do caminho #end\n",
            "Texto source:  you drink coffee dont you\n",
            "Texto target real:  você bebe café não bebe #end\n",
            "Texto target predicho:  você bebe bebe café não é #end\n",
            "Texto source:  i believe thats all we need to do\n",
            "Texto target real:  eu acredito que isso é tudo o que nós precisamos fazer #end\n",
            "Texto target predicho:  eu sempre de que é tudo tudo que precisamos precisamos #end\n",
            "Texto source:  i think its time for me to buy a new car\n",
            "Texto target real:  eu acho que é hora de eu comprar um carro novo #end\n",
            "Texto target predicho:  eu acho que é é de de comprar um carro #end\n",
            "Texto source:  could you please wait a minute\n",
            "Texto target real:  vocês esperar um minuto #end\n",
            "Texto target predicho:  você esperar por por um minuto por #end\n",
            "Texto source:  if toms not happy im not happy\n",
            "Texto target real:  se o tom não está feliz não estou feliz #end\n",
            "Texto target predicho:  o tom o tom não está estou estou estou #end\n",
            "Texto source:  i have an opinion\n",
            "Texto target real:  eu tenho uma ideia #end\n",
            "Texto target predicho:  eu tenho a #end\n",
            "Texto source:  i may have hurt his feelings\n",
            "Texto target real:  pode ser que tenha ferido seus sentimentos #end\n",
            "Texto target predicho:  você pode pode machucar machucar com sentimentos #end\n",
            "Texto source:  i can teach you how to read\n",
            "Texto target real:  eu posso te ensinar a ler #end\n",
            "Texto target predicho:  eu posso te te a a #end\n",
            "Texto source:  i guess i was a little too hard on you\n",
            "Texto target real:  eu acho que eu fui um pouco duro com você #end\n",
            "Texto target predicho:  eu acho que estava um um um para para #end\n",
            "Texto source:  tom knows me very well\n",
            "Texto target real:  tom me conhece muito bem #end\n",
            "Texto target predicho:  tom tom conhece muito muito muito #end\n",
            "Texto source:  you said you needed more time\n",
            "Texto target real:  você disse que precisava de mais tempo #end\n",
            "Texto target predicho:  você você que de mais mais mais #end\n",
            "Texto source:  im sure youve heard about the fire\n",
            "Texto target real:  certamente os senhores ouviram falar do incêndio #end\n",
            "Texto target predicho:  você tem de de que você sobre sobre o #end\n",
            "Texto source:  beautiful night isnt it\n",
            "Texto target real:  a noite está linda não está #end\n",
            "Texto target predicho:  hoje está está está é #end\n",
            "Texto source:  tom said he wanted a picture of me\n",
            "Texto target real:  o tom disse que queria uma fotografia minha #end\n",
            "Texto target predicho:  tom disse que queria queria uma fotografia #end\n",
            "Texto source:  he is preparing for the test\n",
            "Texto target real:  ele está a para o teste #end\n",
            "Texto target predicho:  você está está preparando a o #end\n",
            "Texto source:  tom learned how to swim from his father\n",
            "Texto target real:  tom aprendeu a nadar com o pai #end\n",
            "Texto target predicho:  o tom a nadar a o o pai #end\n",
            "Texto source:  i know that tom is obstinate\n",
            "Texto target real:  sei que o tom é obstinado #end\n",
            "Texto target predicho:  eu que que o é é #end\n",
            "Texto source:  tom wanted to be like mary\n",
            "Texto target real:  tom queria ser como maria #end\n",
            "Texto target predicho:  tom tom queria de maria maria #end\n",
            "Texto source:  i dont know what this word means ill look it up in the dictionary\n",
            "Texto target real:  não sei o que significa esta palavra vou no dicionário #end\n",
            "Texto target predicho:  eu não sei que que palavra palavra dicionário dicionário dicionário dicionário #end\n",
            "Texto source:  dont forget your promise\n",
            "Texto target real:  não esqueça sua promessa #end\n",
            "Texto target predicho:  não esqueça esqueça sua sua #end\n",
            "Texto source:  was it a nice trip\n",
            "Texto target real:  foi uma boa viagem #end\n",
            "Texto target predicho:  estava foi uma viagem #end\n",
            "Texto source:  tom went out\n",
            "Texto target real:  tom saiu #end\n",
            "Texto target predicho:  tom tom saiu fora #end\n",
            "Texto source:  tom brushes his teeth at least three times a day\n",
            "Texto target real:  tom escova os dentes pelo menos três vezes ao dia #end\n",
            "Texto target predicho:  tom escova escova os os menos vezes vezes vezes vezes ao #end\n",
            "Texto source:  everybodys dead\n",
            "Texto target real:  todo mundo está morto #end\n",
            "Texto target predicho:  todos estão está está #end\n",
            "Texto source:  i have to find it\n",
            "Texto target real:  devo encontrálo #end\n",
            "Texto target predicho:  eu de que isso #end\n",
            "Texto source:  i want an ice cream\n",
            "Texto target real:  eu quero um sorvete #end\n",
            "Texto target predicho:  eu quero um sorvete sorvete #end\n",
            "Texto source:  i didnt think we could help you\n",
            "Texto target real:  não achei que podíamos ajudar você #end\n",
            "Texto target predicho:  não não achava que te te #end\n",
            "Texto source:  tom will have to be replaced\n",
            "Texto target real:  tom terá que ser substituído #end\n",
            "Texto target predicho:  tom terá de de substituído substituído #end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOIwgbW9iXDm",
        "colab_type": "text"
      },
      "source": [
        "Notamos que el modelo predice muchas veces \"tom\" y en algunos ejemplos predice \"tom\" en lugares que no corresponde. Esto es porque muchos ejemplos tienen \"tom\", es decir aparece bastante y esto hace que la palabra tenga una mayor probabilidad de aparecer. Proponemos para solucionar este problema tener un dataset sin un pronombre personal fijo como \"tom\" o setear los pesos de la red para que reconozca este tipo de palabras.\n",
        "\n",
        "El modelo tiende a repetir conectores como \"e\" y \"que\" porque al ser conectores aparecen con bastante frecuencia lo que las hace mas probable de aparecer. Es por eso que el modelo que tiene la capa de GlobalMaxPooling tiende a predecir mas palabras como conectores, pues elige exactamente la de mayor valor mientras que GlobalAveragePooling tiende a predecir menos palabras como conectores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nHmFQ_CCdO7v"
      },
      "source": [
        "###  j) A pesar de que la tarea de medir qué tan similar es un texto a otro ya es un área de investigación propia [[6]](#refs), usted deberá utilizar alguna métrica de desempeño para ver qué tan buena es la traducción del texto *versus* el texto real entregado. Debido a que la métrica de *Exact Matching* (EM) puede ser muy drástica, mida *f1 score* por texto además de proponer alguna otra técnica de evaluación para medir sobre el conjunto de pruebas y los otros conjuntos si estima conveniente. Puede basarse en otros trabajos como *Image captioning* o *Text summary*. \n",
        "*Hint: Debido a los problemas de memoria al realizar un forward-pass, solo seleccione un subconjunto $N_{sub}$ del conjunto de pruebas para realizar ésta evaluación, se aconseja entre 1000 y 5000.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bvf_0P9ldViu"
      },
      "source": [
        "###  La función de *f1 score* en este extracto se calcula en base al *precision* y *recall* de que aparezca cada una de las palabras predichas dentro de las palabras reales (como si cada palabra fuera una clase de \"aparece\" o no), **sin importar el orden ni la ocurrencia**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AT1SpSm3dSHY",
        "colab": {}
      },
      "source": [
        "m = MultiLabelBinarizer().fit([np.arange(n_words_t)]) \n",
        "def calculate_f1(true, pred):\n",
        "    true = np.squeeze(true)\n",
        "    pred = np.squeeze(pred)\n",
        "    binarized_true = m.transform([predict_words(true)])[0] #onehot of words appear\n",
        "    binarized_pred = m.transform([predict_words(pred)])[0] #onehot of words appear\n",
        "    return f1_score(binarized_true, binarized_pred, average='binary') #only on appearing words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7zjSIxukkAg",
        "colab_type": "text"
      },
      "source": [
        "Consideraremos un subconjunto del conjunto de pruebas de 2000 ejemplos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R_K29-Lk8JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_s = 2000\n",
        "Y_set=Y_test\n",
        "X_set=X_test\n",
        "idx = np.random.choice(np.arange(Y_set.shape[0]), size=n_s, replace=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQGEbAkLlnhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_set_pred = model.predict_classes(X_set[idx] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXJ-sG0XnOO3",
        "colab_type": "code",
        "outputId": "57e2afd4-db7d-4574-8742-3caaf6ec3474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1_final = np.mean([calculate_f1(true_words,pred_words) for true_words,pred_words in zip(Y_set[idx],Y_set_pred)])\n",
        "#porcentaje\n",
        "print(\"Para el primer modelo, f1 score es: \", f1_final*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Para el primer modelo, f1 score es:  28.22751078556806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37HerwpqoPAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_set_pred = model1.predict_classes(X_set[idx] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rClCChCvoPh0",
        "colab_type": "code",
        "outputId": "17593806-5811-4941-9d4e-b9e3efea1443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1_final = np.mean([calculate_f1(true_words,pred_words) for true_words,pred_words in zip(Y_set[idx],Y_set_pred)])\n",
        "#porcentaje\n",
        "print(\"Para el segundo modelo, f1 score es: \", f1_final*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Para el segundo modelo, f1 score es:  70.9569720619427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ogXqAjHoP16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_set_pred = model2.predict_classes(X_set[idx] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMEiFLYFoZ8q",
        "colab_type": "code",
        "outputId": "ed864888-2b49-4d7a-8cdf-158bff1f5b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1_final = np.mean([calculate_f1(true_words,pred_words) for true_words,pred_words in zip(Y_set[idx],Y_set_pred)])\n",
        "#porcentaje\n",
        "print(\"Para el tercer modelo, f1 score es: \", f1_final*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Para el tercer modelo, f1 score es:  56.498547070827996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK1ONDQtpG_2",
        "colab_type": "text"
      },
      "source": [
        "Como se esperaba, el primer modelo presenta una f1-score mucho más baja que los demás, sin embargo, el tercer modelo presenta una f1-score más baja que la del segundo modelo pese a tener un valor final de la función de pérdida mejor (más bajo). Esta diferencia se la atribuimos a que el modelo entrena para disminuir una función de pérdida y no para aumentar un score. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhfS3SKhJ8XZ",
        "colab_type": "text"
      },
      "source": [
        "En trabajos de Image captioning usan métricas como CIDEr, METEOR, ROUGE and BLEU,.\n",
        "ROUGE o Recall-Oriented Understudy for Gisting Evaluation es un paquete de metricas que evaluan la traducción automática en el procesamiento del lenguaje natural.  \n",
        "BLEU o Bilingual Evaluation Understudy es una métrica de evaluación de la calidad de una traducción."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUgpgFFrNpkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHO11QhURdZI",
        "colab_type": "code",
        "outputId": "2a2149d4-329b-451a-8181-59817f585663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "n_s = 2000\n",
        "Y_set=Y_test\n",
        "X_set=X_test\n",
        "idx = np.random.choice(np.arange(Y_set.shape[0]), size=n_s, replace=False)\n",
        "Y_set_pred = model.predict_classes(X_set[idx])\n",
        "a=list()\n",
        "b=list()\n",
        "for i, n_sampled in enumerate(idx):\n",
        "\n",
        "    text_real = [idx2word_t[p] for p in predict_words(Y_set[n_sampled,:,0], data=\"target\")]\n",
        "    a.append(text_real)\n",
        "    text_sampled = [idx2word_t[p] for p in predict_words(Y_set_pred[i], data=\"target\")]\n",
        "    b.append(text_sampled)\n",
        "    \n",
        "suma=0\n",
        "for i in range(2000):\n",
        "  sumando = sentence_bleu(b[i],a[i])\n",
        "  suma=suma+sumando\n",
        "  \n",
        "print(\"BLEU de modelo 1: \", suma/2000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU de modelo 1:  0.018800887776109106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7txthut0SNkt",
        "colab_type": "code",
        "outputId": "2dc5a969-757d-45ef-c363-681dbec06d52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "Y_set_pred = model1.predict_classes(X_set[idx])\n",
        "a=list()\n",
        "b=list()\n",
        "for i, n_sampled in enumerate(idx):\n",
        "\n",
        "    text_real = [idx2word_t[p] for p in predict_words(Y_set[n_sampled,:,0], data=\"target\")]\n",
        "    a.append(text_real)\n",
        "    text_sampled = [idx2word_t[p] for p in predict_words(Y_set_pred[i], data=\"target\")]\n",
        "    b.append(text_sampled)\n",
        "    \n",
        "suma=0\n",
        "for i in range(2000):\n",
        "  sumando = sentence_bleu(b[i],a[i])\n",
        "  suma=suma+sumando\n",
        "  \n",
        "print(\"BLEU de modelo 2: \", suma/2000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU de modelo 2:  0.21366775433567084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSZd7FFASbaG",
        "colab_type": "code",
        "outputId": "f2297aa5-59bd-4eb5-d138-cd37e2d67590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "Y_set_pred = model2.predict_classes(X_set[idx])\n",
        "a=list()\n",
        "b=list()\n",
        "for i, n_sampled in enumerate(idx):\n",
        "\n",
        "    text_real = [idx2word_t[p] for p in predict_words(Y_set[n_sampled,:,0], data=\"target\")]\n",
        "    a.append(text_real)\n",
        "    text_sampled = [idx2word_t[p] for p in predict_words(Y_set_pred[i], data=\"target\")]\n",
        "    b.append(text_sampled)\n",
        "    \n",
        "suma=0\n",
        "for i in range(2000):\n",
        "  sumando = sentence_bleu(b[i],a[i])\n",
        "  suma=suma+sumando\n",
        "  \n",
        "print(\"BLEU de modelo 3: \", suma/2000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU de modelo 3:  0.216696293442618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BGh48LzB3is",
        "colab_type": "text"
      },
      "source": [
        "Al usar la métrica BLEU (promedio) notamos una mejora (leve) en el rendimiento del tercer modelo en relación al segundo que era lo que se esperaba al cambiar la capa de GlobalMaxPooling por GlobalAveragePooling  y no se pudo apreciar en la f1-score por als razones mencionadas antes. Esta mejora en el rendimiento de BLEU se debe a que BLEU es una métrica diseñada para medir la efectividad de traducciones (que es justamente el problema que estamos tratando)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-umfshRDdZF4"
      },
      "source": [
        "###  k) En ves de volver a variar el modelo de *Encoder*, dejaremos una representación manual explícita (*no entrenable*) a través de extraer características manuales de los textos *source*, como por ejemplo representaciones *term frequency* (TF) o TF-IDF, proporcionadas a través de __[sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text)__. Luego, con esto generado, defina y entrene el modelo *Decoder* neuronal como el presentado en las preguntas anteriores, ésto es comenzar desde la capa *RepeatVector* hasta llegar a la clasificación sobre el texto *target*. Compare el desempeño con lo presentado en (j) y lo visualizado en (h)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35-zaGIxJDvk",
        "colab_type": "text"
      },
      "source": [
        "Term frequency **(TF)** o **TF-IDF** es  un valor numérico que representa la importancia de una palabra para un documento de una colección, el valor de esta medida va aumentando a medida que la palabra aparece más veces en el texto.  \n",
        "\n",
        "Matemáticamente, *TF* es una medida obtenida por el producto de otras dos medidas la frecuencia de término y la frecuencia inversa del documento. La primera se refiere a las veces que aparece un término (palabra) y la segunda a la cantidad de documentos de la colección donde está presente la palabra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UF-iO3XHdcBX",
        "colab": {}
      },
      "source": [
        "def dummy_fun(doc):\n",
        "    return doc\n",
        "tf_idf = TfidfVectorizer(analyzer='word',tokenizer=dummy_fun,preprocessor=dummy_fun,\n",
        "                         token_pattern=None,use_idf= True, smooth_idf=True, norm='l2')   \n",
        "X_train_tfidf = tf_idf.fit_transform(dataX_train).astype('float32').todense()\n",
        "X_test_tfidf = tf_idf.transform(dataX_test)\n",
        "X_val_tfidf= tf_idf.transform(dataX_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hExRoy7Tdeil",
        "outputId": "b023a7bf-8e00-4e77-813a-9854eaaf15ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "EMBEDDING_DIM = 100\n",
        "model3 = Sequential()\n",
        "model3.add(InputLayer( input_shape=(6161,),batch_size=256))\n",
        "model3.add(RepeatVector(max_out_length)) #conection\n",
        "model3.add(CuDNNGRU(256, return_sequences=True))\n",
        "model3.add(TimeDistributed(Dense(n_words_t, activation='softmax')))\n",
        "model3.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0805 00:50:09.394988 139921068345216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0805 00:50:09.436244 139921068345216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0805 00:50:10.467472 139921068345216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "repeat_vector_1 (RepeatVecto (256, 34, 6161)           0         \n",
            "_________________________________________________________________\n",
            "cu_dnngru_1 (CuDNNGRU)       (256, 34, 256)            4929792   \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (256, 34, 9107)           2340499   \n",
            "=================================================================\n",
            "Total params: 7,270,291\n",
            "Trainable params: 7,270,291\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1MI59A34fmw",
        "colab_type": "code",
        "outputId": "f3ba34c1-7ce5-4093-fbc2-067b93348a2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', sample_weight_mode='temporal')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0805 00:50:16.337696 139921068345216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0805 00:50:16.365552 139921068345216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw9BmYf5S7LO",
        "colab_type": "text"
      },
      "source": [
        "### Por alguna razón misteriosa, la red no entrena y no queremos molestar con más mails en esta pregunta, si se ejecutan los comandos necesarios para que compile el modelo, con el código que se fdeja a continuación se puede calcular la f1 score y la BLEU promedio, para luego comparar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zpyiw-zLP6E",
        "colab_type": "code",
        "outputId": "28747c85-7fe0-418e-cb2d-d20f35df4306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model3.fit(X_train_tfidf, Y_train, epochs=5, batch_size=256, validation_data=(X_val_tfidf, Y_val), sample_weight = sample_weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0805 00:50:25.107889 139921068345216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0805 00:50:25.257143 139921068345216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 125693 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "125440/125693 [============================>.] - ETA: 0s - loss: 6.0743"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-b95f53e739d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: Invalid input_h shape: [1,256,256] [1,253,256]\n\t [[{{node cu_dnngru_1/CudnnRNN}}]]\n  (1) Invalid argument: Invalid input_h shape: [1,256,256] [1,253,256]\n\t [[{{node cu_dnngru_1/CudnnRNN}}]]\n\t [[loss/mul/_73]]\n0 successful operations.\n0 derived errors ignored."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fRft7zWSde8i",
        "colab": {}
      },
      "source": [
        "m = MultiLabelBinarizer().fit([np.arange(n_words_t)]) \n",
        "def calculate_f1(true, pred):\n",
        "    true = np.squeeze(true)\n",
        "    pred = np.squeeze(pred)\n",
        "    binarized_true = m.transform([predict_words(true)])[0] #onehot of words appear\n",
        "    binarized_pred = m.transform([predict_words(pred)])[0] #onehot of words appear\n",
        "    return f1_score(binarized_true, binarized_pred, average='binary') #only on appearing words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GjaDmQwfde_D",
        "colab": {}
      },
      "source": [
        "n_s = 2000\n",
        "Y_set=Y_test\n",
        "X_set=X_test_tfidf\n",
        "idx = np.random.choice(np.arange(Y_set.shape[0]), size=n_s, replace=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hb4OfUdEdefl",
        "colab": {}
      },
      "source": [
        "Y_set_pred = model3.predict_classes(X_set[idx] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xhW2SH4JdedB",
        "colab": {}
      },
      "source": [
        "f1_final = np.mean([calculate_f1(true_words,pred_words) for true_words,pred_words in zip(Y_set[idx],Y_set_pred)])\n",
        "#porcentaje\n",
        "print(\"Para el último modelo, f1 score es: \", f1_final*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WhIfwcdOdebj",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vTK_hBPgdeaL",
        "colab": {}
      },
      "source": [
        "n_s = 2000\n",
        "Y_set=Y_test\n",
        "X_set=X_test\n",
        "idx = np.random.choice(np.arange(Y_set.shape[0]), size=n_s, replace=False)\n",
        "Y_set_pred = model.predict_classes(X_set[idx])\n",
        "a=list()\n",
        "b=list()\n",
        "for i, n_sampled in enumerate(idx):\n",
        "\n",
        "    text_real = [idx2word_t[p] for p in predict_words(Y_set[n_sampled,:,0], data=\"target\")]\n",
        "    a.append(text_real)\n",
        "    text_sampled = [idx2word_t[p] for p in predict_words(Y_set_pred[i], data=\"target\")]\n",
        "    b.append(text_sampled)\n",
        "    \n",
        "suma=0\n",
        "for i in range(2000):\n",
        "  sumando = sentence_bleu(b[i],a[i])\n",
        "  suma=suma+sumando\n",
        "  \n",
        "print(\"BLEU del último modelo: \", suma/2000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xWIWIKU2deVI",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iKfVlbEbdeS9",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qM1L-vtpdf1S"
      },
      "source": [
        "<a id=\"refs\"></a>\n",
        "## Referencias\n",
        "[1] https://es.wikipedia.org/wiki/Ley_de_Zipf    \n",
        "[2] Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). *Efficient estimation of word representations in vector space*. arXiv preprint arXiv:1301.3781.    \n",
        "[3] Cho, K., Van Merriënboer, B., Bahdanau, D., & Bengio, Y. (2014). *On the properties of neural machine translation: Encoder-decoder approaches*. arXiv preprint arXiv:1409.1259.  \n",
        "[4] Pal, N. R., & Pal, S. K. (1993). *A review on image segmentation techniques*. Pattern recognition, 26(9), 1277-1294.  \n",
        "[5] Badrinarayanan, V., Kendall, A., & Cipolla, R. (2017). *Segnet: A deep convolutional encoder-decoder architecture for image segmentation*. IEEE transactions on pattern analysis and machine intelligence, 39(12), 2481-2495.  \n",
        "[6] Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002, July). *BLEU: a method for automatic evaluation of machine translation*. In Proceedings of the 40th annual meeting on association for computational linguistics (pp. 311-318). Association for Computational Linguistics.  \n",
        "[7] Kingma, D. P., & Welling, M. (2013). *Auto-encoding variational bayes*. arXiv preprint arXiv:1312.6114.  \n",
        "[8] https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence     \n",
        "[9] Dumoulin, V., & Visin, F. (2016). *A guide to convolution arithmetic for deep learning*. arXiv preprint arXiv:1603.07285.  also: https://github.com/vdumoulin/conv_arithmetic  \n",
        "[10] Jang, E., Gu, S., & Poole, B. (2016). *Categorical reparameterization with gumbel-softmax*. arXiv preprint arXiv:1611.01144.  \n",
        "[11] https://en.wikipedia.org/wiki/Cluster_analysis  "
      ]
    }
  ]
}